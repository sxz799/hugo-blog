<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>Github拉取代码时提示kex_exchange_identification解决方案</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-05-12-github%E6%8B%89%E5%8F%96%E4%BB%A3%E7%A0%81%E6%97%B6%E6%8F%90%E7%A4%BAkex_exchange_identification%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url><categories><category>技巧</category></categories><tags><tag>github</tag></tags><content type="html">最近在github上拉取和推送代码时经常报kex_exchange_identification的错误,但是更换手机热点后就可以正常推代码,查了一下发现可能是梯子的问题，这里记录一下搜到的解决方案。
解决方案 在.ssh目录下创建一个config文件,内容如下
Host github.com HostName ssh.github.com User git Port 443 如果这个文件已经存在,添加或修改对应内容即可。主要目的是使用443端口。</content></entry><entry><title>GithubAction自动编译项目学习笔记</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-05-09-githubaction%E8%87%AA%E5%8A%A8%E7%BC%96%E8%AF%91%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>技巧</category></categories><tags><tag>github</tag><tag>自动化</tag></tags><content type="html"><![CDATA[最近项目上线要将旧系统的数据导入新系统，旧系统的数据导出到excel文件，然后将文件整理后导入新系统。但是整理文件的时候总是会出现一些简单的错误，每次都有人工校对或者导入时提示太麻烦，于是写了一个小工具让整理数据的门店人员整理数据后自行检测一次。由于数据库使用的是sqlite，我本地的开发环境又是mac，这就导致golang交叉编译时要配置gcc,试了一下，感觉太麻烦了。也尝试过开个虚拟机进行编译，发现效果也不满意。后来发现github action可以在推送项目后自动构建项目，于是实现了项目推到github后,由Github自动编译并打包项目。
在github仓库的Action页面创建workflow 可以在这里根据你项目类型选择一个现有的模板进行创建(这里创建后会在项目根目录创建一个.github隐藏目录，目录内有一个workflows文件夹,文件夹里面就是一个yml格式的CI配置文件，所以记得在本地 git pull一下把这个目录拉到本地)
一个脚本的注释说明 name: CI # 标识在推送 main 分支时执行 on: push: branches: [main] # 任务列表 jobs: # 任务名称 build: # 策略 和后面用到的编译环境相关 strategy: matrix: node-version: [16.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ # 运行环境 支持 ubunutu Windows macos runs-on: ubuntu-latest # 容器 我这里使用容器是因为项目要部署到centos系统 而且用到了sqlite 编译是需要gcc环境 container: docker.io/centos:7 # 步骤 steps: # 使用checkout切换到指定分支 - uses: actions/checkout@v3 # 安装依赖 针对上面提到的gcc 非必要 - name: intall deps run: | yum install -y wget tar gcc automake autoconf libtool make # 配置go 编译环境 - name: Set up Go uses: actions/setup-go@v3 with: go-version: 1.19 # 执行编译任务 工作目录在当前目录的server目录内 编译后的app文件在 server/bin 内 后面任务会用到这个文件 - name: Build Server run: go build -ldflags=&#34;-s -w&#34; -o bin/app . working-directory: ./server # 配置前端node 编译环境 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} # 执行编译任务 工作目录在当前目录的web目录内 编译后的app文件在 web/dist 内 后面任务会用到这个文件 - name: Build Web run: npm install &amp;&amp; npm run build working-directory: ./web # 移动编译好的文到 gsCheck 目录内 - name: Move Files run: | mkdir gsCheck mv server/bin/app gsCheck/ mv web/dist gsCheck/dist/ # 指定上传任务 将编译环境内的gsCheck目录内的文件打包为 gscheck-artifact.zip 进行上传 - name: Upload artifact uses: actions/upload-artifact@v2 with: name: gscheck-artifact path: ${{ github.workspace }}/gsCheck # 指定下载任务 将gscheck-artifact.zip下载 方便你下载编译后的文件 - name: Download a Build Artifact uses: actions/download-artifact@v2.1.1 with: name: gscheck-artifact 下载自动编译后打包的文件 ]]></content></entry><entry><title>使用Vercel部署托管在github上的前端项目</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-04-06-%E4%BD%BF%E7%94%A8vercel%E9%83%A8%E7%BD%B2%E6%89%98%E7%AE%A1%E5%9C%A8github%E4%B8%8A%E7%9A%84%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE/</url><categories><category>技巧</category></categories><tags><tag>技巧</tag><tag>Vercel</tag><tag>Vue</tag><tag>前端</tag></tags><content type="html">之前写了一个便携剪切板小工具，部署在家里的群晖上面，方便工作时随时写日报。前段时间发现可以用Vercel部署前端项目，还可以自定义域名，这样就不用每次都输入端口信息了。
申请Vercel账号 官网链接 建议直接使用github登录。
导入github上的前端项目 导入很简单，点几下鼠标就可以。
导入完成后页面大概这个样子，可以直接点击预览图进入
配置域名 根据提示操作即可，刚导入的项目，绿框那里应该是有一个默认的域名的。
添加域名后，会提示让你在你的域名控制台添加一条CNAME的解析记录，按照提示添加即可。
解析记录添加完成后,vercel会自动帮你申请并配置SSL证书。</content></entry><entry><title>Openwrt去除小米电视广告</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-03-24-openwrt%E5%8E%BB%E9%99%A4%E5%B0%8F%E7%B1%B3%E7%94%B5%E8%A7%86%E5%B9%BF%E5%91%8A/</url><categories><category>技巧</category></categories><tags><tag>技巧</tag></tags><content type="html"><![CDATA[小米电视去除开机广告及视频开头广告
创建mihosts文件 echo -e &#39;127.0.0.1 ad.mi.com 127.0.0.1 api.ad.xiaomi.com 127.0.0.1 t7z.cupid.ptqy.gitv.tv 127.0.0.1 sdkconfig.ad.xiaomi.com 127.0.0.1 stat.pandora.xiaomi.com 127.0.0.1 upgrade.mishop.pandora.xiaomi.com 127.0.0.1 logonext.tv.kuyun.com 127.0.0.1 config.kuyun.com 127.0.0.1 mishop.pandora.xiaomi.com 127.0.0.1 dvb.pandora.xiaomi.com 127.0.0.1 de.pandora.xiaomi.com 127.0.0.1 data.mistat.xiaomi.com 127.0.0.1 jellyfish.pandora.xiaomi.com 127.0.0.1 gallery.pandora.xiaomi.com 127.0.0.1 bss.pandora.xiaomi.com 127.0.0.1 gvod.aiseejapp.atianqi.com 127.0.0.1 sdkauth.hpplay.cn 127.0.0.1 adeng.hpplay.cn 127.0.0.1 ad.hpplay.cn 127.0.0.1 conf.hpplay.cn 127.0.0.1 fix.hpplay.cn&#39; &gt; /etc/mihosts 应用自定义的hosts文件 后台页面-&gt;网络-&gt;DHCP/DNS-&gt;HOSTS和解析文件-&gt;额外的 HOSTS 文件 内容填写/etc/mihosts
保存并应用
电视系统设置进行深度清理 重启电视查看效果]]></content></entry><entry><title>Map底层原理学习笔记</title><url>/posts/golang/2023-03-01-goang-map%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[golang Map底层原理学习笔记
课程来源 map的简单使用 package main import &#34;fmt&#34; func f1(key string, mp map[string]int) { value, ok := mp[key] if ok { fmt.Println(value) } else { fmt.Println(key, &#34;不存在&#34;) } } func main() { //创建一个map用来存储姓名和年龄 当然 姓名不可重复 mp := make(map[string]int) mp[&#34;xiaoming&#34;] = 12 mp[&#34;xiaohong&#34;] = 13 f1(&#34;xiaoming&#34;, mp) f1(&#34;xiaoming1&#34;, mp) delete(mp, &#34;xiaohong&#34;) fmt.Println(mp[&#34;xiaohong3&#34;]) //0 } func delete(m map[Type]Type1, key Type)
The delete built-in function deletes the element with the specified key (m[key]) from the map. If m is nil or there is no such element, delete is a no-op.
delete是针对map的内建函数，如果map为空或者没有对应的元素，则是一个空操作
delete无返回值
map的底层原理 map最大的特点就是查找速度非常快，因为他的底层存储是基于哈希表的
Map的特点：
键不能重复 键必须可哈希（目前我们已学的数据类型中，可哈希的有：int/bool/float/string/array） 无序 map初始化 // 初始化一个可容纳10个元素的map info = make(map[string]string,10) 第一步：创建一个hmap结构体对象。
第二步：生成一个哈希因子hash0 并赋值到hmap对象中（用于后续为key创建哈希值）。
第三步：根据hint=10，并根据算法规则来创建 B，当前B应该为1。
hint B 0~8 0 9~13 1 14~26 2 ... 计算B的算法(go1.20源码 具体算法暂不管，以后有时间了再研究)：
B := uint8(0) for overLoadFactor(hint, B) { B++ } // overLoadFactor reports whether count items placed in 1&lt;&lt;B buckets is over loadFactor. func overLoadFactor(count int, B uint8) bool { return count &gt; bucketCnt &amp;&amp; uintptr(count) &gt; loadFactorNum*(bucketShift(B)/loadFactorDen) } 第四步：根据B去创建去创建桶（bmap对象）并存放在buckets数组中，当前bmap的数量应为2.
当B&lt;4时，根据B创建桶的个数的规则为：2B（标准桶） 当B&gt;=4时，根据B创建桶的个数的规则为：2B + 2B-4（标准桶+溢出桶） 注意：每个bmap中可以存储8个键值对，当不够存储时需要使用溢出桶，并将当前bmap中的overflow字段指向溢出桶的位置。
写入数据 info[&#34;name&#34;] = &#34;武沛齐&#34; 在map中写入数据时，内部的执行流程为：
第一步：结合哈希因子和键 name生成哈希值。
第二步：获取哈希值的后B位，并根据后B位的值来决定将此键值对存放到哪个桶中（bmap）。将哈希值和桶掩码（长度为B，值全为1的二进制）进行 &amp; 运算，最终得到哈希值的后B位的值。
假设当B为1时 共2个桶 哈希值：011011100011111110111011111 桶掩码：000000000000000000000000001 结果： 000000000000000000000000001 = 1 (确定桶数组的下标为1) 哈希值：011011100011111110111011100 桶掩码：000000000000000000000000001 结果： 000000000000000000000000000 = 0 (确定桶数组的下标为0) 假设当B为2时 共4个桶 哈希值：011011100011111110111011111 桶掩码：000000000000000000000000011 结果： 000000000000000000000000011 = 3 (确定桶数组的下标为3) 哈希值：011011100011111110111011100 桶掩码：000000000000000000000000011 结果： 000000000000000000000000000 = 0 (确定桶数组的下标为0) 通过示例你会发现，找桶的原则实际上是根据后B为的位运算计算出索引位置，然后再去buckets数组中根据索引找到目标桶（bmap)。
第三步：在上一步确定桶之后，接下来就在桶中写入数据。
获取哈希值的tophash（即：哈希值的`高8位`），将tophash、key、value分别写入到桶中的三个数组中。 如果桶已满，则通过overflow找到溢出桶，并在溢出桶中继续写入。 注意：以后在桶中查找数据时，会基于tophash来找（tophash相同则再去比较key）。 第四步：hmap的个数count++（map中的元素个数+1）
读取数据 value := info[&#34;name&#34;] 在map中读取数据时，内部的执行流程为：
第一步：结合哈希因子和键 name生成哈希值。
第二步：获取哈希值的后B位，并根据后B为的值来决定将此键值对存放到那个桶中（bmap）。
第三步：确定桶之后，再根据key的哈希值计算出tophash（高8位），根据tophash和key去桶中查找数据。当前桶如果没找到，则根据overflow再去溢出桶中找，均未找到则表示key不存在。
扩容 在向map中添加数据时，当达到某个条件，则会引发字典扩容。
扩容条件：
map中 数据总个数 / 桶个数 &gt; 6.5 ，引发翻倍扩容。 使用了太多的溢出桶时（溢出桶使用的太多会导致map处理速度降低）。 B &lt;=15，已使用的溢出桶个数 &gt;= 2B 时，引发等量扩容。 B &gt; 15，已使用的溢出桶个数 &gt;= 215 时，引发等量扩容。 func hashGrow(t *maptype, h *hmap) { // If we&#39;ve hit the load factor, get bigger. // Otherwise, there are too many overflow buckets, // so keep the same number of buckets and &#34;grow&#34; laterally. bigger := uint8(1) if !overLoadFactor(h.count+1, h.B) { bigger = 0 h.flags |= sameSizeGrow } oldbuckets := h.buckets newbuckets, nextOverflow := makeBucketArray(t, h.B+bigger, nil) ... } 当扩容之后：
第一步：B会根据扩容后新桶的个数进行增加（翻倍扩容新B=旧B+1，等量扩容 新B=旧B）。 第二步：oldbuckets指向原来的桶（旧桶）。 第三步：buckets指向新创建的桶（新桶中暂时还没有数据）。 第四步：nevacuate设置为0，表示如果数据迁移的话，应该从原桶（旧桶）中的第0个位置开始迁移。 第五步：noverflow设置为0，扩容后新桶中已使用的溢出桶为0。 第六步：extra.oldoverflow设置为原桶（旧桶）已使用的所有溢出桶。即：h.extra.oldoverflow = h.extra.overflow 第七步：extra.overflow设置为nil，因为新桶中还未使用溢出桶。 第八步：extra.nextOverflow设置为新创建的桶中的第一个溢出桶的位置。 翻倍扩容 如果是翻倍扩容，那么迁移规就是将旧桶中的数据分流至新的两个桶中（比例不定），并且桶编号的位置为：同编号位置 和 翻倍后对应编号位置。
首先，我们要知道如果翻倍扩容（数据总个数 / 桶个数 &gt; 6.5），则新桶个数是旧桶的2倍，即：map中的B的值要+1（因为桶的个数等于2B，而翻倍之后新桶的个数就是2B * 2 ，也就是2B+1，所以 新桶的B的值=原桶B的值 + 1 ）。
迁移时会遍历某个旧桶中所有的key（包括溢出桶），并根据key重新生成哈希值，根据哈希值的 低B位 来决定将此键值对分流道那个新桶中。
扩容后，B的值在原来的基础上已加1，也就意味着通过多1位来计算此键值对要分流到新桶位置，如上图：
当新增的位（红色）的值为 0，则数据会迁移到与旧桶编号一致的位置。 当新增的位（红色）的值为 1，则数据会迁移到翻倍后对应编号位置。 例如：
旧桶个数为4个(B为2)，翻倍后新桶的个数为8(B为3)。
假设某个key进行哈希后3为001
旧桶index：001 &amp; 011 = 001 = 1
新桶index：001 &amp; 111 = 001 = 1
假设某个key进行哈希后3为101
旧桶index：101 &amp; 011 = 001 = 1
新桶index：101 &amp; 111 = 101 = 5 正好是(1+4)
通过上面示例可以发现，翻倍扩容后桶的位置只会是旧位置或旧位置+旧桶长度
等量扩容 如果是等量扩容（溢出桶太多引发的扩容），那么数据迁移机制就会比较简单，就是将旧桶（含溢出桶）中的值迁移到新桶中。
这种扩容和迁移的意义在于：当溢出桶比较多而每个桶中的数据又不多时，可以通过等量扩容和迁移让数据更紧凑，从而减少溢出桶。
]]></content></entry><entry><title>Golang切片扩容学习笔记</title><url>/posts/golang/2023-02-28-golang%E5%88%87%E7%89%87%E6%89%A9%E5%AE%B9%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[在学习golang切片时看到说golang的扩容机制是小于1024时进行double,超过1024后每次增加1/4，但是自己尝试后并非如此，于是扒了下golang的源码研究一番。
代码演示 package main import &#34;fmt&#34; func main() { arr := []int{0} lastCap := cap(arr) fmt.Println(&#34;cap：&#34;, lastCap) for i := 0; i &lt; 10000; i++ { arr = append(arr, i) if lastCap != cap(arr) { fmt.Println(&#34;cap：&#34;, cap(arr)) lastCap = cap(arr) } } } cap： 1 cap： 2 cap： 4 cap： 8 cap： 16 cap： 32 cap： 64 cap： 128 cap： 256 cap： 512 cap： 848 cap： 1280 cap： 1792 cap： 2560 cap： 3408 cap： 5120 cap： 7168 cap： 9216 cap： 12288 一开始确实成指数上涨，每次double，但是512以后变不是1024，而变成了848。
看一下slice.go的更新日志 发现在2021年9月8日有一个更新记录
此处可以发现扩容机制发生了变化
源码 // growslice allocates new backing store for a slice. // // arguments: // //	oldPtr = pointer to the slice&#39;s backing array //	newLen = new length (= oldLen + num) //	oldCap = original slice&#39;s capacity. //	num = number of elements being added //	et = element type // // return values: // //	newPtr = pointer to the new backing store //	newLen = same value as the argument //	newCap = capacity of the new backing store // // Requires that uint(newLen) &gt; uint(oldCap). // Assumes the original slice length is newLen - num // // A new backing store is allocated with space for at least newLen elements. // Existing entries [0, oldLen) are copied over to the new backing store. // Added entries [oldLen, newLen) are not initialized by growslice // (although for pointer-containing element types, they are zeroed). They // must be initialized by the caller. // Trailing entries [newLen, newCap) are zeroed. // // growslice&#39;s odd calling convention makes the generated code that calls // this function simpler. In particular, it accepts and returns the // new length so that the old length is not live (does not need to be // spilled/restored) and the new length is returned (also does not need // to be spilled/restored). func growslice(oldPtr unsafe.Pointer, newLen, oldCap, num int, et *_type) slice { oldLen := newLen - num if raceenabled { callerpc := getcallerpc() racereadrangepc(oldPtr, uintptr(oldLen*int(et.size)), callerpc, abi.FuncPCABIInternal(growslice)) } if msanenabled { msanread(oldPtr, uintptr(oldLen*int(et.size))) } if asanenabled { asanread(oldPtr, uintptr(oldLen*int(et.size))) } if newLen &lt; 0 { panic(errorString(&#34;growslice: len out of range&#34;)) } if et.size == 0 { // append should not create a slice with nil pointer but non-zero len. // We assume that append doesn&#39;t need to preserve oldPtr in this case. return slice{unsafe.Pointer(&amp;zerobase), newLen, newLen} } newcap := oldCap doublecap := newcap + newcap if newLen &gt; doublecap { newcap = newLen } else { const threshold = 256 if oldCap &lt; threshold { newcap = doublecap } else { // Check 0 &lt; newcap to detect overflow // and prevent an infinite loop. for 0 &lt; newcap &amp;&amp; newcap &lt; newLen { // Transition from growing 2x for small slices // to growing 1.25x for large slices. This formula // gives a smooth-ish transition between the two. newcap += (newcap + 3*threshold) / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 { newcap = newLen } } } var overflow bool var lenmem, newlenmem, capmem uintptr // Specialize for common values of et.size. // For 1 we don&#39;t need any division/multiplication. // For goarch.PtrSize, compiler will optimize division/multiplication into a shift by a constant. // For powers of 2, use a variable shift. switch { case et.size == 1: lenmem = uintptr(oldLen) newlenmem = uintptr(newLen) capmem = roundupsize(uintptr(newcap)) overflow = uintptr(newcap) &gt; maxAlloc newcap = int(capmem) case et.size == goarch.PtrSize: lenmem = uintptr(oldLen) * goarch.PtrSize newlenmem = uintptr(newLen) * goarch.PtrSize capmem = roundupsize(uintptr(newcap) * goarch.PtrSize) overflow = uintptr(newcap) &gt; maxAlloc/goarch.PtrSize newcap = int(capmem / goarch.PtrSize) case isPowerOfTwo(et.size): var shift uintptr if goarch.PtrSize == 8 { // Mask shift for better code generation. shift = uintptr(sys.TrailingZeros64(uint64(et.size))) &amp; 63 } else { shift = uintptr(sys.TrailingZeros32(uint32(et.size))) &amp; 31 } lenmem = uintptr(oldLen) &lt;&lt; shift newlenmem = uintptr(newLen) &lt;&lt; shift capmem = roundupsize(uintptr(newcap) &lt;&lt; shift) overflow = uintptr(newcap) &gt; (maxAlloc &gt;&gt; shift) newcap = int(capmem &gt;&gt; shift) capmem = uintptr(newcap) &lt;&lt; shift default: lenmem = uintptr(oldLen) * et.size newlenmem = uintptr(newLen) * et.size capmem, overflow = math.MulUintptr(et.size, uintptr(newcap)) capmem = roundupsize(capmem) newcap = int(capmem / et.size) capmem = uintptr(newcap) * et.size } // The check of overflow in addition to capmem &gt; maxAlloc is needed // to prevent an overflow which can be used to trigger a segfault // on 32bit architectures with this example program: // // type T [1&lt;&lt;27 + 1]int64 // // var d T // var s []T // // func main() { // s = append(s, d, d, d, d) // print(len(s), &#34;\n&#34;) // } if overflow || capmem &gt; maxAlloc { panic(errorString(&#34;growslice: len out of range&#34;)) } var p unsafe.Pointer if et.ptrdata == 0 { p = mallocgc(capmem, nil, false) // The append() that calls growslice is going to overwrite from oldLen to newLen. // Only clear the part that will not be overwritten. // The reflect_growslice() that calls growslice will manually clear // the region not cleared here. memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) } else { // Note: can&#39;t use rawmem (which avoids zeroing of memory), because then GC can scan uninitialized memory. p = mallocgc(capmem, et, true) if lenmem &gt; 0 &amp;&amp; writeBarrier.enabled { // Only shade the pointers in oldPtr since we know the destination slice p // only contains nil pointers because it has been cleared during alloc. bulkBarrierPreWriteSrcOnly(uintptr(p), uintptr(oldPtr), lenmem-et.size+et.ptrdata) } } memmove(p, oldPtr, lenmem) return slice{p, newLen, newcap} } 由于我们每次都是append 1个元素进入，所以后面不会出现newLen &gt; doublecap的情况，都会走进下面的分支
const threshold = 256 if oldCap &lt; threshold { newcap = doublecap } else { // Check 0 &lt; newcap to detect overflow // and prevent an infinite loop. for 0 &lt; newcap &amp;&amp; newcap &lt; newLen { // Transition from growing 2x for small slices // to growing 1.25x for large slices. This formula // gives a smooth-ish transition between the two. newcap += (newcap + 3*threshold) / 4 } // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 { newcap = newLen } } threshold中文的意思是门槛,此处也是很贴切了。
当oldcap是256时带入分支，可以得到newcap值为512。 当oldcap是512时带入分支，通过计算可知newcap=512+(512+256*3)/4=832 但是前面的结果是848，和计算的结果并不一致，那是什么原因导致的呢？
内存对齐 继续看后面的代码，可以发现，在确定最后的newcap值前要进行内存对齐。
不同类型的切片其内存对齐的代码是不同的。
// Returns size of the memory block that mallocgc will allocate if you ask for the size. func roundupsize(size uintptr) uintptr { if size &lt; _MaxSmallSize { if size &lt;= smallSizeMax-8 { return uintptr(class_to_size[size_to_class8[divRoundUp(size, smallSizeDiv)]]) } else { return uintptr(class_to_size[size_to_class128[divRoundUp(size-smallSizeMax, largeSizeDiv)]]) } } if size+_PageSize &lt; size { return size } return alignUp(size, _PageSize) } var class_to_size = [_NumSizeClasses]uint16{0, 8, 16, 24, 32, 48, 64, 80, 96, 112, 128, 144, 160, 176, 192, 208, 224, 240, 256, 288, 320, 352, 384, 416, 448, 480, 512, 576, 640, 704, 768, 896, 1024, 1152, 1280, 1408, 1536, 1792, 2048, 2304, 2688, 3072, 3200, 3456, 4096, 4864, 5376, 6144, 6528, 6784, 6912, 8192, 9472, 9728, 10240, 10880, 12288, 13568, 14336, 16384, 18432, 19072, 20480, 21760, 24576, 27264, 28672, 32768} 之前我们计算出来的长度是832 换算成bit后是 6656 在class_to_size向上取整后为 6784 6784/8= 848
这就解释了为什么新的cap是848
其他类型切片扩容容量(append步长为1) string int64 float64 package main import &#34;fmt&#34; func main() { arr := []string{&#34;0&#34;} lastCap := cap(arr) fmt.Println(&#34;cap：&#34;, lastCap) for i := 0; i &lt; 5000; i++ { arr = append(arr, &#34;0&#34;) if lastCap != cap(arr) { fmt.Println(&#34;cap：&#34;, cap(arr)) lastCap = cap(arr) } } } cap： 1 cap： 2 cap： 4 cap： 8 cap： 16 cap： 32 cap： 64 cap： 128 cap： 256 cap： 512 cap： 848 cap： 1280 cap： 1792 cap： 2560 cap： 3584 cap： 5120 int32 float32 package main import &#34;fmt&#34; func main() { arr := []int32{0} lastCap := cap(arr) fmt.Println(&#34;cap：&#34;, lastCap) for i := 0; i &lt; 5000; i++ { arr = append(arr, 0) if lastCap != cap(arr) { fmt.Println(&#34;cap：&#34;, cap(arr)) lastCap = cap(arr) } } } cap： 1 cap： 2 cap： 4 cap： 8 cap： 16 cap： 32 cap： 64 cap： 128 cap： 256 cap： 512 cap： 864 cap： 1344 cap： 2048 cap： 3072 cap： 4096 cap： 5440 bool package main import &#34;fmt&#34; func main() { arr := []bool{true} lastCap := cap(arr) fmt.Println(&#34;cap：&#34;, lastCap) for i := 0; i &lt; 5000; i++ { arr = append(arr, true) if lastCap != cap(arr) { fmt.Println(&#34;cap：&#34;, cap(arr)) lastCap = cap(arr) } } } cap： 1 cap： 8 cap： 16 cap： 32 cap： 64 cap： 128 cap： 256 cap： 512 cap： 896 cap： 1408 cap： 2048 cap： 3072 cap： 4096 cap： 5376 ]]></content></entry><entry><title>Mysql索引</title><url>/posts/mysql/2023-02-20-mysql%E7%B4%A2%E5%BC%95/</url><categories><category>mysql</category></categories><tags><tag>mysql</tag></tags><content type="html"><![CDATA[在关系数据库中，索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。索引的作用相当于图书的目录，可以根据目录中的页码快速找到所需的内容。
myslq索引 普通索引 -- 创建索引的基本语法 CREATE INDEX indexName ON table(column(length)); -- 例子 length默认我们可以忽略 CREATE INDEX idx_name ON user(name); 主键索引 我们知道每张表一般都会有自己的主键，mysql会在主键上建立一个索引，这就是主键索引。主键是具有唯一性并且不允许为NULL，所以他是一种特殊的唯一索引。一般在建立表的时候选定。
复合索引 复合索引也叫组合索引，指的是我们在建立索引的时候使用多个字段，例如同时使用身份证和手机号建立索引，同样的可以建立为普通索引或者是唯一索引。
-- 创建索引的基本语法 CREATE INDEX indexName ON table(column1(length),column2(length)); -- 例子 CREATE INDEX idx_phone_name ON user(phone,name); SELECT * FROM user_innodb where name = &#39;程冯冯&#39;; SELECT * FROM user_innodb where phone = &#39;15100046637&#39;; SELECT * FROM user_innodb where phone = &#39;15100046637&#39; and name = &#39;程冯冯&#39;; SELECT * FROM user_innodb where name = &#39;程冯冯&#39; and phone = &#39;15100046637&#39;; 只有 2 、 3、4能使用的到索引idx_phone_name,因为条件里面必须包含索引前面的字段才能够进行匹配。而3和4相比where条件的顺序不一样，为什么4可以用到索引呢？是因为mysql本身就有一层sql优化，他会根据sql来识别出来该用哪个索引，我们可以理解为3和4在mysql眼中是等价的。
全文索引 全文索引主要用来查找文本中的关键字，而不是直接与索引中的值相比较。fulltext索引跟其它索引大不相同，它更像是一个搜索引擎，而不是简单的where语句的参数匹配。fulltext索引配合match against操作使用，而不是一般的where语句加like。
它可以在create table，alter table ，create index使用，不过目前只有char、varchar，text 列上可以创建全文索引。正常情况下我们也不会使用到全文索引，因为这不是mysql的专长。
空间索引 空间索引是对空间数据类型的字段建立的索引，MYSQL中的空间数据类型有4种，分别是GEOMETRY、POINT、LINESTRING、POLYGON。MYSQL使用SPATIAL关键字进行扩展，使得能够用于创建正规索引类型的语法创建空间索引。
创建空间索引的列，必须将其声明为NOT NULL，空间索引只能在存储引擎为MYISAM的表中创建。空间索引一般是用不到了，了解即可。
索引的数据结构 innodb默认索引数据结构是B+Tree，什么是B+Tree呢，它的全名叫做平衡多路查找树PLUS。他是由平衡二叉树查找树（AVL树）演化而来。
关于平衡二叉树，B树 B+树不再记录
Hash索引 Hash索引就是将索引字段进行hash存储，整个hash索引的结构是Hash表+链表（因为会存在hash冲突）。
Hash索引的优缺点 由于Hash是基于内存的索引，那么他的检索效率是非常快的，那既然Hash索引效率这个高，我们是不是都需用Hash索引啊。
我觉得hash索引的优点只有一个，那就是快，不需要磁盘io，直接内存一次性搞定。但是要说他的缺点可真的是太多了。
Hash索引仅仅能满足&quot;=&quot;,“IN&quot;和”&lt;=&gt;&ldquo;查询，不能使用范围查询。 哈希索引只支持等值比较查询，包括＝、 IN 、&lt;=&gt; (注意&lt;&gt;和＜＝＞是不同的操作）。也不支持任何范围查询，例如WHERE price &gt; 100。 由于Hash索引比较的是进行Hash运算之后的Hash值 ，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的Hash算法处理之后的Hash值的大小关系，并不能保证和Hash运算前完全一样。 Hash索引无法被用来避免数据的排序操作。 由于Hash索引中存放的是经过Hash计算之后的Hash值，而且Hash值的大小关系并不一定和Hash运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算; Hash索引不能利用部分索引键查询。 对于组合索引，Hash索引在计算Hash值的时候是组合索引键合并后再一起计算Hash值，而不是单独计算Hash值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash索引也无法被利用。 Hash索引在任何时候都不能避免表扫描。 前面已经知道，Hash索引是将索引键通过Hash运算之后，将 Hash运算结果的Hash值和所对应的行指针信息存放于一个Hash表中，由于不同索引键存在相同Hash值，所以即使取满足某个Hash键值的数据的记录条数，也无法从Hash索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。 Hash索引遇到大量Hash值相等的情况后性能并不一定就会比BTree索引高。 对于选择性比较低的索引键，如果创建Hash索引，那么将会存在大量记录指针信息存于同一个Hash值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下。 &lt; &gt; 运算符 不等于
&lt;=&gt; 运算符 安全等于
]]></content></entry><entry><title>使用hugo和next主题搭建静态博客</title><url>/posts/blog/2023-02-20-%E4%BD%BF%E7%94%A8hugo%E5%92%8Cnext%E4%B8%BB%E9%A2%98%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/</url><categories><category>blog</category></categories><tags><tag>blog</tag><tag>hugo</tag></tags><content type="html"><![CDATA[前两年一直在用hexo写博客，hexo构建需要node环境，且文章数量多了以后构建速度慢了许多，且部署起来比较复杂，所以改用hugo。
在Mac系统使用hugo推荐使用homebrew安装hugo。homebrew的安装不再介绍，可参考 知乎文章 安装hugo brew install hugo 生成站点 hugo new site /path/to/site 创建文章 hugo new about.md
使用next主题 链接 部署到github page 修改hugo配置文件，使生成的前端文件放到docs目录
# =============================================================== # 根据如下的配置说明完善自己的站点配置，建议另外拷贝进行调整避免冲突 # Improve your site configuration according to the following # configuration instructions. It is recommended to make # additional copies for adjustment to avoid conflicts # =============================================================== # --------------------------------------------------------------- # Hugo 引擎的基础配置 # Basic configure for Hugo engine # --------------------------------------------------------------- # 使生成的前端文件放到doc目录 publishDir : docs # 站点域名，比如： https://hugo-next.eu.org # Website domain, eg: https://hugo-next.eu.org baseURL: / # 站点标题 # Website title github创建一个仓库 username.github.io username为你的用户名
将hugo生成的站点推送到新建的仓库
配置域名解析 在docs目录中创建一个CNAME文件内容为你的域名
rm -rf docs/ # 删除旧的文件 hugo #编译出新文件 echo &#39;b.sxz799.fun&#39; &gt; docs/CNAME ## 如果配置的域名就加上这个 git add . git commit -m &#34;update blog&#34; git push ]]></content></entry><entry><title>Redis基础</title><url>/posts/redis/redis%E5%9F%BA%E7%A1%80/</url><categories><category>redis</category></categories><tags><tag>redis</tag></tags><content type="html"><![CDATA[Redis常用数据结构 字符串（String）、哈希(Hash)、列表（list）、集合（set）、有序集合（ZSET）。
字符串（String） 字符串类型是Redis最基础的数据结构。键都是字符串类型。值最大不能超过512MB。
命令 SET set key value set abc 123
常用参数 set key value [NX|XX] [GET] [EX seconds|PX milliseconds|EXAT unix-time-seconds|PXAT unix-time-milliseconds|KEEPTTL]
NX : 键不存在才可以设置成功
XX : 键存在才可以设置成功
EX|PX|EXAT|PXAT : 设置过期时间 秒 毫秒 秒时间戳 毫秒时间戳
KEEPTTL：保留设置前指定键的生存时间 (6.0版本添加的可选参数) GET：返回指定键原本的值，若键不存在时返回nil
GET get key get abc
GETSET GETSET命令用于设置键值对的值并返回旧值，若键值对不存在则返回nil。若键存在但不为字符串类型，则返回错误。
getset key value getset abc 123
DEL命令被用于删除指定的一个或多个键值对，当其中某个键值对不存在时将被忽略。DEL命令可被用于所有数据类型，不仅限于字符串。
EXPIRE / PEXPIRE EXPIRE key seconds [NX|XX|GT|LT]
NX：只有当key没有设置过期时间，才会执行命令（已经设置过的，不能再设置） XX ：只有当key有过期时间，才会执行命令设置（没有设置过的，不能设置） GT ：只有当新的过期时间大于当前过期时间时，才会设置（只会增加过期时间） LT ：只有当新的过期时间小于当前过期时间时，才会设置（只会减少过期时间） EXPIRE/PEXPIRE命令被用于设置某个键的过期时间，其值以秒作为单位。当设置过期时间后使用SET（不使用KEEPTTL参数）、GETSET等命令，所设置的过期时间将被覆盖。EXPIRE可被用于所有数据类型，不仅限于字符串。
TTL / PTTL TTL命令用于获取指定键的剩余生存时间（time to live, TTL），其值以秒作为生存时间的单位。TTL命令可被用于所有数据类型，不仅限于字符串。
TTL key
PTTL命令同样用于获取指定键的剩余生存时间，与TTL区别为其以毫秒作为单位。
PTTL key
MSET mset key value [key value &hellip;]
MSET命令用于设置一个或多个键值对，该命令永远返回OK。MSET与SET命令相同，都会替代存在的键的值。
MGET mget key [key &hellip;]
MGET用于获取所有指定的键值。当某个键不存在时，将返回一个特殊的值nil。
MSETNX MSETNX key value [key value &hellip;]
MSETNX命令用于设置一个或多个键值对，仅当所有键都不存在时才会执行。同样，MSETNX也具备原子性，所有的键会被一起被设置。
当所有的键被设置，则返回1
当所有的键都没有被设置，即至少一个键已存在的情况，则返回0
GETDEL GETDEL key
GETDEL命令是Redis 6.2.0中新增的命令，它用于获取指定键值对的值，并在获取后将其删除（仅限于该键值对类型为字符串时）。
GETEX GETEX key [EX seconds|PX milliseconds|EXAT timestamp|PXAT milliseconds-timestamp|PERSIST]
GETEX命令支持EX、PX、EXAT、PXAT以及PERSIST，分别为：
EX：设置以秒为单位的过期时间 PX：设置以毫秒为单位的过期时间 EXAT：设置以秒为单位的UNIX时间戳所对应的时间为过期时间 PXAT：设置以毫秒为单位的UNIX时间戳所对应的时间为过期时间 PERSIST：移除键值对关联的过期时间 INCR incr命令用于对值做自增操作,返回结果分为三种情况：
值不是整数,返回错误。
值是整数，返回自增后的结果。
键不存在，按照值为0自增,返回结果为1。（会设置键）
除了incr命令，Redis提供了decr(自减)、 incrby(自增指定数字)、decrby(自减指定数字)、incrbyfloat（自增浮点数)
append 追加
127.0.0.1:6379&gt; set a aa OK 127.0.0.1:6379&gt; append a bb (integer) 4 127.0.0.1:6379&gt; get a &#34;aabb&#34; strlen 127.0.0.1:6379&gt; strlen a (integer) 4 setrange 设置指定位置的字符
127.0.0.1:6379&gt; get a &#34;aabb&#34; 127.0.0.1:6379&gt; setrange a 2 c (integer) 4 127.0.0.1:6379&gt; set a (error) ERR wrong number of arguments for &#39;set&#39; command 127.0.0.1:6379&gt; get a &#34;aacb&#34; getrange 截取字符串
127.0.0.1:6379&gt; get a &#34;aacb&#34; 127.0.0.1:6379&gt; getrange a 2 3 &#34;cb&#34; ]]></content></entry><entry><title>Golang逃逸分析</title><url>/posts/golang/2023-02-09-golang%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[案例 先看一段C语言代码
#include &lt;stdio.h&gt; int *foo(int arg_val) { int foo_val = 11; return &amp;foo_val; } int main() { int *main_val = foo(666); printf(&#34;%d\n&#34;, *main_val); } ➜ Desktop gcc cDemo.c cDemo.c:7:13: warning: address of stack memory associated with local variable &#39;foo_val&#39; returned [-Wreturn-stack-address] return &amp;foo_val; ^~~~~~~ 1 warning generated. 如上C/C++编译器明确给出了警告，foo把一个局部变量的地址返回了
在Go语言下代码如下
package main func foo(arg_val int)(*int) { var foo_val int = 11; return &amp;foo_val; } func main() { main_val := foo(666) println(*main_val) } ➜ goDemo go run main.go 11 在Go语言下却正常运行
分析 go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做逃逸分析(escape analysis)，当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。
逃逸规则 如果变量需要使用堆空间，那么他就应该进行逃逸。但是实际上Golang并不仅仅把逃逸的规则如此泛泛。Golang会有很多场景具备出现逃逸的现象。 一般我们给一个引用类对象中的引用类成员进行赋值，可能出现逃逸现象。可以理解为访问一个引用对象实际上底层就是通过一个指针来间接的访问了，但如果再访问里面的引用成员就会有第二次间接访问，这样操作这部分对象的话，极大可能会出现逃逸的现象。
Go语言中的引用类型有func（函数类型），interface（接口类型），slice（切片类型），map（字典类型），channel（管道类型），*（指针类型）等。
Golang中一个函数内局部变量，不管是不是动态new出来的，它会被分配在堆还是栈，是由编译器做逃逸分析之后做出的决定。
]]></content></entry><entry><title>Golang Select</title><url>/posts/golang/2023-02-09-golang-select/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[go select用处 select是一种go可以处理多个通道之间的机制，看起来和switch语句很相似，但是select其实和IO机制中的select一样，多路复用通道，随机选取一个进行执行，如果说通道(channel)实现了多个goroutine之前的同步或者通信，那么select则实现了多个通道(channel)的同步或者通信，并且select具有阻塞的特性。
select 是 Go 中的一个控制结构，类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。
select 随机执行一个可运行的 case。如果没有 case 可运行，它将阻塞，直到有 case 可运行。一个默认的子句应该总是可运行的。
select { case &lt;-ch1: // 如果从 ch1 信道成功接收数据，则执行该分支代码 case ch2 &lt;- 1: // 如果成功向 ch2 信道成功发送数据，则执行该分支代码 default: // 如果上面都没有成功，则进入 default 分支处理流程 } select里的case后面并不带判断条件，而是一个信道的操作，不同于switch里的case
golang 的 select 就是监听 IO 操作，当 IO 操作发生时，触发相应的动作每个case语句里必须是一个IO操作，确切的说，应该是一个面向channel的IO操作。
注：Go 语言的 select 语句借鉴自 Unix 的 select() 函数，在 Unix 中，可以通过调用 select() 函数来监控一系列的文件句柄，一旦其中一个文件句柄发生了 IO 动作，该 select() 调用就会被返回（C 语言中就是这么做的），后来该机制也被用于实现高并发的 Socket 服务器程序。Go 语言直接在语言级别支持 select关键字，用于处理并发编程中通道之间异步 IO 通信问题。
注意：如果 ch1 或者 ch2 信道都阻塞的话，就会立即进入 default 分支，并不会阻塞。但是如果没有 default 语句，则会阻塞直到某个信道操作成功为止。
select语句只能用于信道的读写操作
select中的case条件(非阻塞)是并发执行的，select会选择先操作成功的那个case条件去执行，如果多个同时返回，则随机选择一个执行，此时将无法保证执行顺序。对于阻塞的case语句会直到其中有信道可以操作，如果有多个信道可操作，会随机选择其中一个 case 执行
对于case条件语句中，如果存在信道值为nil的读写操作，则该分支将被忽略，可以理解为从select语句中删除了这个case语句
如果有超时条件语句，判断逻辑为如果在这个时间段内一直没有满足条件的case,则执行这个超时case。如果此段时间内出现了可操作的case,则直接执行这个case。一般用超时语句代替了default语句
对于空的select{}，会引起死锁
对于for中的select{}, 也有可能会引起cpu占用过高的问题
示例 只能用于信道的操作 select的特性场景 竞争选举 func main() { ch1 := make(chan any, 1) ch2 := make(chan any, 1) ch3 := make(chan any, 1) ch1 &lt;- 1 ch2 &lt;- 2 ch3 &lt;- 3 select { case i := &lt;-ch1: fmt.Printf(&#34;从ch1读取了数据%d&#34;, i) case j := &lt;-ch2: fmt.Printf(&#34;从ch2读取了数据%d&#34;, j) case m := &lt;-ch3: fmt.Printf(&#34;从ch3读取了数据%d&#34;, m) } } 超时处理（保证不阻塞） func main() { ch1 := make(chan any, 1) go func() { time.Sleep(time.Second * 3) ch1 &lt;- 1 }() select { case str := &lt;-ch1: fmt.Println(&#34;receive str&#34;, str) case &lt;-time.After(time.Second * 5): fmt.Println(&#34;timeout!!&#34;) } ch2 := make(chan any, 1) go func() { time.Sleep(time.Second * 7) ch2 &lt;- 1 }() select { case str := &lt;-ch2: fmt.Println(&#34;receive str&#34;, str) case &lt;-time.After(time.Second * 5): fmt.Println(&#34;timeout!!&#34;) } } 运行结果： receive str 1 timeout!! 判断buffered channel是否阻塞 package main import ( &#34;fmt&#34; &#34;time&#34; ) func main() { bufChan := make(chan int, 5) go func() { time.Sleep(time.Second) for { &lt;-bufChan time.Sleep(5 * time.Second) } }() for { select { case bufChan &lt;- 1: fmt.Println(&#34;add success&#34;) time.Sleep(time.Second) default: fmt.Println(&#34;资源已满，请稍后再试&#34;) time.Sleep(time.Second) } } } 运行结果 add success add success add success add success add success add success add success 资源已满，请稍后再试 资源已满，请稍后再试 资源已满，请稍后再试 资源已满，请稍后再试 add success 资源已满，请稍后再试 资源已满，请稍后再试 资源已满，请稍后再试 资源已满，请稍后再试 add success 资源已满，请稍后再试 资源已满，请稍后再试 资源已满，请稍后再试 资源已满，请稍后再试 add success 资源已满，请稍后再试 资源已满，请稍后再试 ... 阻塞main函数 package main import ( &#34;fmt&#34; &#34;time&#34; ) func main() { bufChan := make(chan int) go func() { for{ bufChan &lt;-1 time.Sleep(time.Second) } }() go func() { for{ fmt.Println(&lt;-bufChan) } }() select{} } 如果换成for 也能阻塞main退出，但是对cpu的占用会变高
package main import ( &#34;fmt&#34; &#34;time&#34; ) func main() { bufChan := make(chan int) go func() { for{ bufChan &lt;-1 time.Sleep(time.Second) } }() go func() { for{ fmt.Println(&lt;-bufChan) } }() for{} } ]]></content></entry><entry><title>GMP模型</title><url>/posts/golang/2023-02-08-gmp%E6%A8%A1%E5%9E%8B/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[什么是GMP模型？ G：gorotine（协程） M：machine（内核线程） P：processor(调度器) Go语言运行时，通过核心元素G，M，P 和 自己的调度器，实现了自己的并发线程模型。调度器通过对G，M，P的调度实现了两级线程模型中操作系统内核之外的调度任务。
Golang调度器由来 Goroutine调度器器的GMP模型的设计思想 GMP模型简介 G：goroutine（协程） M：machine（内核线程） P：processor(调度器，负责G和M之间的调度，不是GMP模型的调度) 全局队列:存放等待运行的G
P的本地队列:
存放等待运行的G, 有数量限制(不超过256个), 新创建的G优先放置在本地队列，存满了会放在全局队列 P列表:程序启动时创建,默认数量为cpu线程数
M列表:当前操作系统分配到当前Go程序的内核线程数
P和M的数量:
P的数量可通过环境变量($GOMAXPROCS)或程序中代码设置runtime.GOMAXPROCS() . M的数量Go语言本身限制为10000,可通过runtime/debug包中的SetMaxThreads函数来设置, 有一个M阻塞,就会创建一个新的M,有M空闲就会回收或者睡眠。 调度器的设计策略 复用线程 避免频繁的创建销毁线程，有两种机制 work stealing机制和hand off机制
work stealing机制 : 当前P的本地队列和全局队列均无可运行的G时会尝试从其他P的队列中偷取G
hand off机制 : 当本线程正在运行的G发生阻塞时，会将G和M进行绑定，并把P转移给其他的空闲M
利用并行 GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个cpu上同时运行
抢占 在coroutine中要等待一个协程主动让出CPU才执行下一个协程.
在Go中，一个goroutine最多占⽤用CPU 10ms，防⽌止其他goroutine被饿死.
全局G队列列 用于存放G
调度规则 如果处理器没有任务可处理，它会按以下规则来执行，直到满足某一条规则：
从本地队列获取任务 从全局队列获取任务 从网络轮询器获取任务 从其它的处理器的本地队列窃取任务 go func() 经历了什么 先创建一个goroutine 也就是G G会有限存储在创建G的P的本地本地队列,若队列已满就会存在全局队列 G只能P的调度下运行在M上，M和P一一绑定,当G执行关闭后会在本地队列中取一个G运行,若队列为空，就会从全局队列取一个G，全局队列也为空的话就会从其他绑定的M和P的队列中偷取 M调度G的执行过程是一个循环机制 当M执行某个G的时候，如果发生了syscall或其他阻塞操作，M会阻塞，如果当前有一些G在运行，runtime就会把这个M与P进行绑定，然后去复用空间的线程或创建一个线程来服务这个P 当阻塞的M不再阻塞时，G会尝试获取一个空闲的P执行并放入其本地队列，获取不到P的话，这个M就会变成休眠状态，加入到空闲线程中，然后G会放入全局队列中。 M0 和 G0 M0是启动程序后的编号为0的主线程，这个M对应的实例例会在全局变量量runtime.m0中，不需要在heap上分配，M0负责执行初始化操作和启动第一个G，在之后M0就和其他的M⼀样了。
G0是每次启动一个M都会第一个创建的gourtine，G0是仅用于负责调度的G，G0不指向任何可执⾏的函数, 每个M都会有一个⾃⼰的G0。在调度或系统调用时会使用G0的栈空间, 全局变量的G0是M0的G0。
trace 编程 func main() { f, err := os.Create(&#34;trace.out&#34;) if err != nil { panic(err) } err = trace.Start(f) if err != nil { panic(err) } //业务代码 fmt.Println(&#34;hello trace&#34;) trace.Stop() } Web查看方式 $go tool trace trace.out Debug查看 go build -o trace main.go GODEBUG=schedtrace=1000 ./trace2 SCHED 调试的信息
0ms 从程序启动到输出经历的时间
gomaxprocs P的数量 ⼀般默认是和CPU的核⼼心数是⼀致的
idleprocs 处理理idle状态的P的数量，gomaxprocs-idleprocs= ⽬前正在执行的p的数量
threads 线程数量(包括M0，包括GODEBUG调试的线程)
spinningthreads 处于自旋状态的thread数量(自旋状态就是找到不G的M)
idlethread 处理idle状态的thread
runqueue 全局G队列中的G的数量
[0,0] 每个P的local queue本地队列列中，⽬目前存在G的数量量
Go调度器器GMP调度场景的全过程分析 P拥有G1，M1获取P后开始运行G1，G1使⽤用go func()创建了了G2，为了局部性G2优先加入到P1的本地队列。
G1运行完成后(函数:goexit)，M上运行的goroutine切换为G0，G0负责调度时协程的切换(函数:schedule)。 从P的本地队列取G2，从G0切换到G2，并开始运行G2(函数:execute)。实现了线程M1的复用。
这三个场景是创建G后如何存放
规定:在创建G时，运行的G会尝试唤醒其他空闲的P和M组合去执⾏。
假定G2唤醒了M2，M2绑定了P2，并运行G0，但P2本地队列没有G，M2此时为⾃旋线程(没有G但为运行状态的线程，不断寻找G)。
M2尝试从全局队列(简称“GQ”)取一批G放到P2的本地队列(函数:findrunnable())。M2从全局队列取的G数量符合下⾯面的公式: n = min(len(GQ)/GOMAXPROCS + 1, cap(GQ)/2)
全局队列已经没有G，那M就要执行work stealing(偷取):从其他有G的P那里偷取⼀半G过来，放到⾃己的P本地队列。P2从P1的本地队列尾部取一半的G，本例中⼀半则只有1个G8，放到P2的本地队列并执行。
最多有GOMAXPROCS个自旋的线程(当前例子中的GOMAXPROCS=4，所以一共4个P)，多余的没事做的线程会让他们休眠。
假定当前除了M3和M4为自旋线程，还有M5和M6为空闲的线程(没有得到P的绑定，注意我们这里最多就只能够存在4个P，所以P的数量应该永远是M&gt;=P, 大部分都是M在抢占需要运行的P)，G8创建了G9， G8进行了阻塞的系统调用，M2和P2立即解绑，P2会执行以下判断:如果P2本地队列列有G、全局队列有G 或有空闲的M，P2都会⽴马唤醒1个M和它绑定，否则P2则会加⼊到空闲P列表，等待M来获取可用的P。 本场景中，P2本地队列列有G9，可以和其他空闲的线程M5绑定。
M2和P2会解绑，但M2会记住P2，然后G8和M2进⼊入系统调用状态。当G8和M2退出系统调用时，会尝试获取P2，如果无法获取，则获取空闲的P，如果依然没有，G8会被记为可运行状态，并加入到全局队列,M2因为没有P的绑定而变成休眠状态(长时间休眠等待GC回收销毁)。
疑问 当M绑定P的本地队列中的G为空时，是先从全局队列中获取P还是从其他P的队列中偷取？
怎么理解 全局变量的G0是M0的G0 ?
GO调度完后放到哪里？
]]></content></entry><entry><title>面试题整理(Golang方向)</title><url>/posts/golang/2023-02-06-golang%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[面试题整理(Golang方向)
golang相关 list 结构 及底层实现？ // Element is an element of a linked list. type Element struct { // Next and previous pointers in the doubly-linked list of elements. // To simplify the implementation, internally a list l is implemented // as a ring, such that &amp;l.root is both the next element of the last // list element (l.Back()) and the previous element of the first list // element (l.Front()). next, prev *Element // The list to which this element belongs. list *List // The value stored with this element. Value any } // List represents a doubly linked list. // The zero value for List is an empty list ready to use. type List struct { root Element // sentinel list element, only &amp;root, root.prev, and root.next are used len int // current list length excluding (this) sentinel element } // Init initializes or clears list l. func (l *List) Init() *List { l.root.next = &amp;l.root l.root.prev = &amp;l.root l.len = 0 return l } 通过代码可以发现在go中list的底层结构是一个带有头结点的双链表，有一个前驱节点和一个后继节点。 通过其初始化的代码可以发现在其前驱和后继都指向其自身，且长度置0。Init不仅用于初始化，还可以用户清空链表
进程 线程 协程 进程：进程是程序一次动态执行的过程，是程序运行的基本单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信。进程占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、页表、文件句柄等）比较大，但相对比较稳定安全。
进程 线程又叫做轻量级进程，是CPU调度的最小单位线程从属于进程，是程序的实际执行者。一个进程至少包含一个主线程，也可以有更多的子线程。多个线程共享所属进程的资源，同时线程也拥有自己的专属资源。程间通信主要通过共享内存，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。
协程：协程是一种用户态的轻量级线程，协程的调度完全由用户控制。一个线程可以拥有多个协程，协程不是被操作系统内核所管理，而完全是由程序所控制。
##GMP调度模型原理
内容过多 详解点这里 协程如何等其余协程结束后再操作 sync.WaitGroup。WaitGroup就是用来等待一组操作完成的。WaitGroup内部实现了一个计数器，用来记录未完成的操作个数.
它提供了三个方法，Add()用来添加计数。Done()用来在操作结束时调用，使计数减一。Wait()用来等待所有的操作结束，即计数变为0，该函数会在计数不为0时等待，在计数为0时立即返回。
func main() { var wg sync.WaitGroup for i := 0; i &lt; 5; i++ { wg.Add(1) go func(i int) { time.Sleep(time.Second * time.Duration(rand.Intn(3))) fmt.Println(&#34;当时运行的i:&#34;, i) wg.Done() }(i) } wg.Wait() fmt.Println(&#34;运行结束，程序即将退出&#34;) } go的结构体能否比较 可以,但是有限制
同一个结构体且结构体不含有不可比较的类型可以比较
type Person struct { Name string Age int } func main() { p1 := Person{ Name: &#34;战鹰&#34;, Age: 3, } p2 := Person{ Name: &#34;捷豹&#34;, Age: 4, } p3 := Person{ Name: &#34;战鹰&#34;, Age: 3, } fmt.Println(p1 == p2) //false fmt.Println(p1 == p3) //true } 不同的结构体就算内容和值都一样也没法比较 同一个结构体如果包含了不可比较的类型，也无法直接比较
但是可以利用反射进行比较 reflect.DeepEqual()
func main() { p1 := Person1{ Name: &#34;战鹰&#34;, Age: 3, Hobby: []string{&#34;鱼肉肠&#34;, &#34;送外卖&#34;}, } p2 := Person1{ Name: &#34;战鹰&#34;, Age: 3, Hobby: []string{&#34;鱼肉肠&#34;, &#34;送外卖&#34;}, } p3 := Person1{ Name: &#34;战鹰&#34;, Age: 3, Hobby: []string{&#34;鱼肉肠&#34;, &#34;送外卖&#34;, &#34;抽象&#34;}, } fmt.Println(reflect.DeepEqual(p1, p2)) //true fmt.Println(reflect.DeepEqual(p1, p3)) //false } goroutine锁机制 互斥锁模式 底层实现 Go语言中使用sync包控制并发 有无缓冲channel的区别 无缓冲的与有缓冲channel有着重大差别：一个是同步的 一个是非同步的
ch1:=make(chan int) 无缓冲
ch2:=make(chan int,1) 有缓冲
ch1&lt;-1 程序运行到这里后如果ch1里的数据没人拿走,后面的代码不会继续执行
ch2&lt;-1 程序运行到这里后如果1进入了channel，不管ch2里的数据有没有人取走，程序都会继续执行，如果ch1里有数据，也就是缓存满了，后面的代码不会继续执行
go defer的原理 用于延迟函数的调用，常用于关闭文件或者关闭锁的场景。 defer语句采用类似栈的方式，每遇到一个defer就会把defer后面的函数压入栈中，在函数返回前再把栈中的函数依次取出执行。 一般函数正常返回时会执行被defer延迟的函数，特别的遇到return和panic时也会触发延迟函数。
defer作用于资源释放（关闭文件句柄、数据库连接、停止定时器ticker以及关闭管道）、流程控制（控制函数执行顺序，如wait.Group）和异常处理（recover()），但是defer关键字只能作用于函数或者函数调用。
延迟函数的参数在defer语句出现时就已经确定了 延迟函数按后进先出LIFO的顺序执行，即先出现的defer最后执行 延迟函数可能操作住函数的具体变量名称返回值 //数据结构 type _defer struct{ sp uintptr	// 函数栈指针 pc uintptr	// 程序计数器 fn *funcval	// 函数地址 link *_defer	// 用于链接多个defer } 每个_defer实例是对一个函数的封装，编译器会把每一个延迟函数编译成一个_defer实例暂存到goroutine数据结构中，待函数结束时再逐个取出执行。
多个_defer实例使用指针link链接成一个单链表，保存到goroutine中，下面是goroutine结构中关于_defer的部分
type g struct { _defer *_defer	// defer链表 } 每次插入_defer实例都是从链表的头部插入，函数执行结束再依次从头部取出defer执行。
defer的创建和执行 创建defer： deferproc() 将defer函数处理成_defer实例，并加入goroutine的链表中； 执行defer： deferreturn() 将defer从goroutine中取出并执行。
整个流程就是：编译器在编译阶段把defer语句替换成函数deferproc()，在return前插入函数deferreturn(), 每次执行deferproc()都会创建一个运行时_defer实例并存储，函数返回前执行deferreturn()依次拿出_defer实例并执行。
go select用处 Golang Select go slice如何扩容 切片(slice)是 Golang 中一种比较特殊的数据结构，这种数据结构更便于使用和管理数据集合。切片是围绕动态数组的概念构建的，可以按需自动增长和缩小。切片(slice)是可以看做是一个长度可变的数组。
切片(slice)自身并不是动态数组或者数组指针。它内部实现的数据结构通过指针引用底层数组，设定相关属性将数据读写操作限定在指定的区域内。
切片(slice)是对数组一个连续片段的引用，所以切片是一个引用类型。
//数据结构 type slice struct { array unsafe.Pointer len int cap int } 扩容规则 如果切片的容量小于1024个元素，那么扩容的时候slice的cap就乘以2；一旦元素个数超过1024个元素，增长因子就变成1.25，即每次增加原来容量的四分之一。
如果扩容之后，还没有触及原数组的容量，那么，切片中的指针指向的位置，就还是原数组，如果扩容之后，超过了原数组的容量，那么，Go就会开辟一块新的内存，把原来的值拷贝过来，这种情况丝毫不会影响到原数组。
go 逃逸分析是什么 Golang逃逸分析 退出程序时如何防止channel没有消费完 退出时将生产者关闭，不会产生多余的数据给消费者
package main import ( &#34;fmt&#34; &#34;runtime&#34; &#34;sync&#34; &#34;time&#34; ) var wg sync.WaitGroup // 生产者 func Send(ch chan int) { x := 0 defer func() { if err := recover(); err != nil &amp;&amp; err.(runtime.Error).Error() == &#34;send on closed channel&#34; { fmt.Println(err) fmt.Println(&#34;即将产生的数据：&#34;, x) } else { close(ch) //关闭的目的：不在发送数据 } wg.Done() }() for i := 0; i &lt; 10; i++ { x++ ch &lt;- x } } // 消费者 func Receive(ch chan int) { defer func() { if err := recover(); err != nil { fmt.Println(err) close(ch) //关闭的目的：不要让生产者继续发送数据 fmt.Println(&lt;-ch) //继续消费，输出结果为0,说明已经不会生产者已经不会再发送数据了 } wg.Done() }() for x := range ch { time.Sleep(time.Second) fmt.Println(x) if x == 3 { panic(&#34;发生意外的错误&#34;) //中断主程序,但是协程还是不会关闭的 } } fmt.Println(&#34;Receive任务结束&#34;) } func main() { fmt.Println(&#34;退出程序时，防止channel没有消费完&#34;) ch := make(chan int) wg.Add(2) go Send(ch) go Receive(ch) wg.Wait() fmt.Println(&#34;任务完成&#34;) _, ok := &lt;-ch fmt.Println(ok) } 循环队列 是否线程安全 如何做到 package main import &#34;fmt&#34; type Queue struct { arr []int front int rear int } func NewQueue(maxSize int) *Queue { return &amp;Queue{ arr: make([]int, maxSize), front: 0, rear: 0, } } func (q *Queue) Push(data int) { q.arr[q.rear] = data q.rear = (q.rear + 1) % len(q.arr) } func (q *Queue) Pop() int { tmp := q.arr[q.front] q.front = (q.front + 1) % len(q.arr) return tmp } func (q *Queue) IsEmpty() bool { return q.front == q.rear } func (q *Queue) IsFull() bool { return q.front == (q.rear+1)%len(q.arr) } func (q *Queue) Length() int { return (q.rear - q.front + len(q.arr)) % len(q.arr) } func main() { q := NewQueue(10) var i int for i &lt; 15 { if q.IsFull() { q.Pop() } q.Push(i) fmt.Println(&#34;Push &#34;, i, &#34;front:&#34;, q.front, &#34;rear:&#34;, q.rear, &#34; | &#34;, q.arr) i++ } } 运行结果: Push 0 front: 0 rear: 1 | [0 0 0 0 0 0 0 0 0 0] Push 1 front: 0 rear: 2 | [0 1 0 0 0 0 0 0 0 0] Push 2 front: 0 rear: 3 | [0 1 2 0 0 0 0 0 0 0] Push 3 front: 0 rear: 4 | [0 1 2 3 0 0 0 0 0 0] Push 4 front: 0 rear: 5 | [0 1 2 3 4 0 0 0 0 0] Push 5 front: 0 rear: 6 | [0 1 2 3 4 5 0 0 0 0] Push 6 front: 0 rear: 7 | [0 1 2 3 4 5 6 0 0 0] Push 7 front: 0 rear: 8 | [0 1 2 3 4 5 6 7 0 0] Push 8 front: 0 rear: 9 | [0 1 2 3 4 5 6 7 8 0] Push 9 front: 1 rear: 0 | [0 1 2 3 4 5 6 7 8 9] Push 10 front: 2 rear: 1 | [10 1 2 3 4 5 6 7 8 9] Push 11 front: 3 rear: 2 | [10 11 2 3 4 5 6 7 8 9] Push 12 front: 4 rear: 3 | [10 11 12 3 4 5 6 7 8 9] Push 13 front: 5 rear: 4 | [10 11 12 13 4 5 6 7 8 9] Push 14 front: 6 rear: 5 | [10 11 12 13 14 5 6 7 8 9] channel缓冲长度的确定 channel缓冲长度可以与上下游的速度比例成线性关系
sync Pool sync.pool是一个临时对象存储池
因为项目中频繁的创建对象和回收内存，造成了GC的压力；而sync.pool可以缓存对象暂时不用但是之后会用到的对象，并且不需要重新分配内存；这在很大程度上降低了GC的压力，并且提高了程序的性能
首先，需要为sync.Pool设置一个New函数，这个函数就是当你获取不到对象时，返回的默认值。接下来，你就可以通过Get和Put方法检索对象和临时存储对象了
注：创建的这个pool在第一次使用过后就不能再被赋值了；还有就是Pool中的对象随时都会被移除，并且不会有通知机制。而如果你存储的是一个对象的引用，那么这个对象也会被回收
package main import &#34;sync&#34; type Person struct { Name string } //Initialing pool var personalPool = sync.Pool{ // New optionally specifies a function to generate // a value when Get would otherwise return nil. New: func() interface{} { return &amp;Person{} }, } func main() { // Get hold of an instance newPerson := personalPool.Get().(*Person) // Defer release function // After that the same instance is // reusable by another routine defer personalPool.Put(newPerson) // using instance newPerson.Name = &#34;Jack&#34; } 如果有一个对象需要频繁的创建，并且有很大的开销，那么你就可以使用sync.pool
数据库相关 redis基本数据结构 String、List、Hash、Set、ZSet
https://sxz799.github.io/posts/redis/redis基础/ mysql 索引 innoDB 表锁还是行锁 InnoDB行锁是通过给索引上的索引项加锁来实现的，这一点MySQL与Oracle不同，后者是通过在数据块中对相应数据行加锁来实现的。InnoDB这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁！
在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。
行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁。行级锁的缺点是：由于需要请求大量的锁资源，所以速度慢，内存消耗大。
Linux相关 查找文件中的指定字符 使用 grep 命令 grep 666 a.txt 在a.txt中查找包含666的行 使用 sed 命令 使用 awk 脚本 查询端口占用 netstat -ntulp | grep 80
网络相关 http能否一次多个请求不等后端返回 可以
tcp udp 及udp优点 算法相关 5e整数大文件的排序]]></content></entry><entry><title>BCM943602CS蓝牙修复记录</title><url>/posts/hackintosh/2023-02-02-bcm943602cs%E8%93%9D%E7%89%99%E4%BF%AE%E5%A4%8D%E8%AE%B0%E5%BD%95/</url><categories><category>hackintosh</category></categories><tags><tag>hackintosh</tag></tags><content type="html">前言 记得在两年前做过一个b85+i5-4950的黑苹果配置，当时是在闲鱼购买的bcm943602cs三天线的无线网卡，安装系统的时候就可以直接免驱，进系统后蓝牙和wifi都是直接免驱，感觉这个卡还挺好的
，正好前段时间为了玩吃鸡买了b365m+9400f的台式，现在游戏也玩的少了，就准备装个黑苹果刷刷，于是在春节后就在闲鱼下单了一个943602cs网卡，年后有点忙没时间装系统，就只在windows上测试了一下蓝牙和wifi，能驱动就确认收货了，但是在装黑苹果的时候发现，蓝牙打不开，想退货也不可能，卖的话再买一个也不合适，就自己研究了一下，在这里记录一下驱动蓝牙的过程。
bug初现 初现的症状是蓝牙无法打开，蓝牙芯片组识别为BCM_2045A0
尝试修复 最开始以为是usb定制的原因，重新定制了一下usb，发现问题依旧。 又尝试加入了 BlueToolFixup.kext 开机后可以打开蓝牙也能搜索了，但是无法连接设备，此时感觉有戏。
继续尝试 之后又在论坛搜了一个这个卡的ProductId-&amp;gt;0x21ff,发现这个情况并不少见，而且论坛也给出了解决方案，但是有人反馈成功驱动，也有人反馈无效，而且帖子标题是10.12和10.13的老系统,现在都到13.1了，不知道有没有效就死马当成活马医，试一试吧。根据https://github.com/acidanthera/BrcmPatchRAM说明配置了一下蓝牙驱动。
12、13系统要用到的kext有三个 BrcmPatchRAM3.kext BrcmFirmwareData.kext BlueToolFixup.kext
10.15.X - 11 系统用这三个 BrcmPatchRAM3.kext BrcmFirmwareData.kext BrcmBluetoothInjector.kext
但是我这张bcm943602cs的ProductId并不在下载的支持列表中
[0489:e032] 20702 Combo USB [0489:e042] 20702A1 Lenovo China * [0489:e079] Lenovo China 43162 NGFF [0489:e07a] Lenovo NGFF (4352 / 20702) [04ca:2003] 20702A1 Lenovo China [04ca:200a] LiteOn (4352 Combo) [04ca:200b] LiteOn (4352 Combo) * [04ca:200c] LiteOn (4352 Combo) [04ca:200f] Acer / LiteOn (4352 Combo) [050d:065a] Belkin (20702) [0930:0221] Toshiba (4352 / 20702) [0930:0223] Toshiba NGFF (4352 / 20702) * [0a5c:216b] HP Rapture 4352Z NGFF Combo [0a5c:216e] HP Blackbird 43162 NGFF [0a5c:216f] Dell DW1560 (4352/20702) [0a5c:21de] 4352/20702A1 combo [0a5c:21e1] HP Softsailing (20702A1) [0a5c:21e6] non-UHE Lenovo Bluetooth (20702) [0a5c:21e8] Bluetooth USB Dongle (20702A1) * [0a5c:21ec] Inateck Bluetooth (20702A1) [0a5c:21fb] HP Supra 4352 (20702A1 Combo) [0a5c:21fd] Broadcom 4352Z [0a5c:22be] Broadcom BCM20702 Bluetooth 4.0 USB Device [0a5c:6410] Dell Wireless 1830 Bluetooth 4.1 LE [0a5c:6412] Dell Wireless 1820 Bluetooth 4.1 LE [0a5c:828d] Fenvi BCM94352Z [0b05:17cb] Asus BT-400 (20702 stand-alone) * [0b05:17cf] Asus (4352/20702A1 combo) * [0b05:180a] Azurewave (4360/20702 combo) [13d3:3404] Azurewave (4352HMB) * [13d3:3411] Dell Alienware (4352/20702A1 combo) * [13d3:3413] Azurewave (4360/20702 combo) [13d3:3418] Azurewave (4352/20702 combo) [13d3:3435] Azurewave (4352/20702 combo) [13d3:3456] Azurewave (4352/20702 combo) [413c:8143] Dell DW1550 (4352/20702 combo) 但是 acidanthera 在使用说明中有这么两句话 如果你的设备不在支持设备中，请根据需要修改 Info.plist 。
BrcmPatchRAM支持任何基于BCM20702芯片组的Broadcom USB蓝牙设备（可能也支持其他芯片组，但是尚未经过测试）。
于是根据论坛 解决方案 的提示修改BrcmPatchRAM3.kext中的info.plist
使用到的软件为PlistEdit Pro
原始的info.plist信息
修改后的信息
修改后将三大件放到oc的Kext目录并配置config 重启！
问题完美解决，双投，隔空投送，iPhone作为网络摄像头都可以正常使用，和白果卡并无差别(这张本来就是白果卡。。。不知道是寨卡还是啥情况，有没有可能是早期苹果打回给博通的卡呢?)
然后重启到windows，发现此时在win下蓝牙也驱动了，而且识别为apple内建卡。
总结 也是第一次知道不是所有的白果卡都可以无脑免驱，总体来说过程并不复杂，也没有耗费太多的时间。
更新 2023年02月05日11:02:59 用了两天后尝试去掉三大件，发现驱动仍然正常，达到了真正免驱的效果。</content></entry><entry><title>让Gin-Vue-Admin的表单支持图片</title><url>/posts/golang/2023-01-10-%E8%AE%A9gin-vue-admin%E7%9A%84%E8%A1%A8%E5%8D%95%E6%94%AF%E6%8C%81%E5%9B%BE%E7%89%87/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[在学习 gin-vue-admin 时发现生成代码时并不支持选择表单输入类型，都是默认的输入框或者下拉框，这样在传图片或附件是就需要手动修改前端来实现此功能。
数据结构 如下图所示
数据列表部分 代码前后对比
需要导入CustonPic模块
import CustomPic from &#39;@/components/customPic/index.vue&#39; 效果图
表单部分 数据列表还是挺简单的，麻烦的是表单部分
页面效果
代码前后对比
需要定义和导入和修改的东西比较多
// 要添加的地方： import {useUserStore} from &#34;@/pinia/modules/user&#34;; const userStore = useUserStore() const emit = defineEmits([&#39;on-success&#39;]) const path = ref(import.meta.env.VITE_BASE_API) let fileList = [] const uploadSuccess = (res) =&gt; { const { data } = res if (data.file) { emit(&#39;on-success&#39;, data.file.url) formData.value.pic=data.file.url } } const uploadError = () =&gt; { ElMessage({ type: &#39;error&#39;, message: &#39;上传失败&#39; }) } const removeFile = () =&gt; { formData.value.pic=&#39;&#39; } // 要修改的地方： const updateStudentFunc = async(row) =&gt; { const res = await findStudent({ ID: row.ID }) type.value = &#39;update&#39; if (res.code === 0) { formData.value = res.data.restudent if(formData.value.pic!=&#39;&#39;){ fileList=[{&#34;name&#34;:&#34;pic.jpg&#34;,&#34;url&#34;:&#34;/api/&#34;+formData.value.pic}] }else { fileList=[] } dialogFormVisible.value = true } } const closeDialog = () =&gt; { dialogFormVisible.value = false fileList=[] formData.value = { name: &#39;&#39;, gender: &#39;&#39;, pic: &#39;&#39;, } } ]]></content></entry><entry><title>让Gin-Vue-Admin的字典值支持字符串</title><url>/posts/golang/2023-01-09-%E8%AE%A9gin-vue-admin%E7%9A%84%E5%AD%97%E5%85%B8%E5%80%BC%E6%94%AF%E6%8C%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[最近在学习 gin-vue-admin 开发平台，发现在配置字典时，字典值只能使用int，不能使用string，这样就会导致后期做报表开发时，查看数据库内容时容易摸不到头脑，所以准备改一下源码，使其字典值支持string！
gva版本: 2.5.5 (2022/12/14)
后端部分 修改 sys_dictionary_detail.go 中结构体的定义 // model/system/sys_dictionary_detail.go line:12 // 修改Value的数据类型为string type SysDictionaryDetail struct { global.GVA_MODEL Label string `json:&#34;label&#34; form:&#34;label&#34; gorm:&#34;column:label;comment:展示值&#34;` // 展示值 Value string `json:&#34;value&#34; form:&#34;value&#34; gorm:&#34;column:value;comment:字典值&#34;` // 字典值 Status *bool `json:&#34;status&#34; form:&#34;status&#34; gorm:&#34;column:status;comment:启用状态&#34;` // 启用状态 Sort int `json:&#34;sort&#34; form:&#34;sort&#34; gorm:&#34;column:sort;comment:排序标记&#34;` // 排序标记 SysDictionaryID int `json:&#34;sysDictionaryID&#34; form:&#34;sysDictionaryID&#34; gorm:&#34;column:sys_dictionary_id;comment:关联标记&#34;` // 关联标记 } 修改dictionary_detail.go中默认字典的配置 文件位置: source/system/dictionary_detail.go
这里就不贴代码了，根据IDE的错误提示把原来的int类型的Value数据改为string即可
修改字典server中Value的类型
//service/system/sys_dictionary_detail.go line:71 //修改前：	if info.Value != 0 { db = db.Where(&#34;value = ?&#34;, info.Value) } //修改后：	if info.Value != &#34;&#34; { db = db.Where(&#34;value = ?&#34;, info.Value) } 修改前端文件模板 这里不贴代码了，看上去很乱，贴两张图，比较清晰明了
文件位置: resource/autocode_template/web/form.vue.tpl
文件位置: resource/autocode_template/web/table.vue.tpl
前端部分 修改字典配置页，字典值改为string // src/view/superAdmin/dictionary/sysDictionaryDetail.vue line:89 //修改前： &lt;el-form-item label=&#34;字典值&#34; prop=&#34;value&#34;&gt; &lt;el-input-number v-model.number=&#34;formData.value&#34; step-strictly :step=&#34;1&#34; placeholder=&#34;请输入字典值&#34; clearable :style=&#34;{width: &#39;100%&#39;}&#34; /&gt; &lt;/el-form-item&gt; //修改后： &lt;el-form-item label=&#34;字典值&#34; prop=&#34;value&#34;&gt; &lt;el-input v-model=&#34;formData.value&#34; placeholder=&#34;请输入字典值&#34; clearable :style=&#34;{width: &#39;100%&#39;}&#34; /&gt; &lt;/el-form-item&gt; 修改代码生成器页面代码实现string类型可配置字典 // src/view/systemTools/autoCode/component/fieldDialog.vue line:68 //修改前： &lt;el-form-item label=&#34;关联字典&#34; prop=&#34;dictType&#34;&gt; &lt;el-select v-model=&#34;middleDate.dictType&#34; style=&#34;width:100%&#34; :disabled=&#34;middleDate.fieldType!==&#39;int&#39;&#34; placeholder=&#34;请选择字典&#34; clearable &gt; &lt;el-option v-for=&#34;item in dictOptions&#34; :key=&#34;item.type&#34; :label=&#34;`${item.type}(${item.name})`&#34; :value=&#34;item.type&#34; /&gt; &lt;/el-select&gt; &lt;/el-form-item&gt; //修改后： &lt;el-form-item label=&#34;关联字典&#34; prop=&#34;dictType&#34;&gt; &lt;el-select v-model=&#34;middleDate.dictType&#34; :disabled=&#34;middleDate.fieldType!==&#39;string&#39;&#34; placeholder=&#34;请选择字典&#34; clearable &gt; &lt;el-option v-for=&#34;item in dictOptions&#34; :key=&#34;item.type&#34; :label=&#34;`${item.type}(${item.name})`&#34; :value=&#34;item.type&#34; /&gt; &lt;/el-select&gt; &lt;/el-form-item&gt; 修改完成！]]></content></entry><entry><title>在Mac OS系统下永久试用软件</title><url>/posts/hackintosh/2023-01-05-%E5%9C%A8macos%E7%B3%BB%E7%BB%9F%E4%B8%8B%E6%B0%B8%E4%B9%85%E8%AF%95%E7%94%A8%E8%BD%AF%E4%BB%B6/</url><categories><category>技巧</category></categories><tags><tag>永久试用</tag></tags><content type="html"><![CDATA[试用原理 部分软件每次启动后会先检查注册信息，只需要在系统启动后删除注册信息就可以永久免费试用！
支持的软件及下载地址 Beyond Compare PlistEdit Pro &hellip;
破解步骤 创建脚本 进入如下目录
cd &#34;/Users/$(whoami)/Library/Application Support/&#34; 新建一个FreeTrial文件
touch FreeTrial 内容如下(根据自己的实际使用情况修改下面的代码即可)
#!/bin/bash rm &#34;/Users/$(whoami)/Library/Application Support/Beyond Compare/registry.dat&#34; rm &#34;/Users/$(whoami)/Library/Application Support/PlistEdit Pro/.folderinfo&#34; 赋予新建的FreeTrial文件可执行权限
chmod +x FreeTrial 配置脚本开机运行 设置-通用-启动项
添加刚才创建的 FreeTrial 文件
这样有一个确定就是每次开机后都会打开一个终端窗口，如果你不想看到这个终端窗口的话可以手动执行该脚本。或者用其他更优雅的方式执行。
如果你想让页面好看一点，可以给FreeTrial配置一个icon
图标配置方式 在 这个网站 下载一个你喜欢的图标到桌面
右键点击 FreeTrial 在弹出的菜单中选择 显示简介 然后将刚才下载的图标拖到简介上方的图标即可。
]]></content></entry><entry><title>Golang中函数返回值注意点</title><url>/posts/golang/2022-12-09-golang%E4%B8%AD%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E5%80%BC%E6%B3%A8%E6%84%8F%E7%82%B9/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[Go语言函数返回值又两种方法，如下代码：
func GoReturn1() int { a := 0 return a } func GoReturn2() (a int) { a = 0 return } func main() { fmt.Println(&#34;返回值1：&#34;, GoReturn1()) fmt.Println(&#34;返回值2：&#34;, GoReturn2()) } 显然上面的函数返回值都是0没有什么不同，但是如果在函数体内加上一个defer func() ，那么就可能得到不同的结果 代码如下：
func GoReturn1() int { a := 0 defer func() { a++ }() return a } func GoReturn2() (a int) { a = 0 defer func() { a++ }() return a } func main() { fmt.Println(&#34;返回值1：&#34;, GoReturn1()) fmt.Println(&#34;返回值2：&#34;, GoReturn2()) } 运行结果： 返回值1： 0 返回值2： 1 为什么返回值不同呢？
由于Go的返回机制决定的，如果函数的返回值只声明了返回值的类型
func GoReturn1() int { a:=0 defer func(){ a++ } return a } 这种情况下Go会创建临时变量保存返回值,然后去执行 defer 后面的函数，这样虽然defer后面的函数修改了a的值，但不会修改临时变量中的值，所以会返回0
而函数声明返回值类型时同时带上了变量名，又是什么情况呢？
func GoReturn2() (a int) { a = 0 defer func() { a++ }() return a } 函数声明返回值类型时同时带上了变量名时，Go就不会创建临时变量保存返回值，而是直接返回声明时的变量，这样defer中修改了a的值.
]]></content></entry><entry><title>Golang泛型学习笔记</title><url>/posts/golang/2022-12-09-golang%E6%B3%9B%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[什么是泛型？ 泛型程序设计（generic programming）是程序设计语言的一种风格或范式。泛型允许程序员在强类型程序设计语言中编写代码时使用一些以后才指定的类型，在实例化时作为参数指明这些类型。
Golang泛型Demo package main import ( &#34;fmt&#34; ) func main() { strs := []string{&#34;aaa&#34;, &#34;vdfe&#34;, &#34;djmerui&#34;} is := []int{1, 2, 3} printArray(strs) printAnyArray(strs) printComparableArray(strs) printArray(is) printAnyArray(is) printComparableArray(is) } // T 形式类型 string int 指定的实际类型 func printArray[T string | int](arr []T) { for _, a := range arr { fmt.Println(a) } } // 内置的泛型类型 any 任意类型 func printAnyArray[T any](arr []T) { for _, a := range arr { fmt.Println(a) } } // 内置的泛型类型 comparable 可比较的类型 func printComparableArray[T comparable](arr []T) { for _, a := range arr { fmt.Println(a) } } 泛型的作用
泛型减少重复代码并提高类型安全性
在下面情最的时候非常适合使用泛型：当你需要针对不同类型书写同样的逻辑，使用泛型来简化代码是最好的
泛型类型 只定义一个类型就能代表你想要的所有类型
Demo：
package main import &#34;fmt&#34; func main() { type MySlice[T int | float64] []T var s1 MySlice[int] = []int{1, 2, 3, 4} var s2 MySlice[float64] = []float64{1.11, 2.22, 3.33, 4.44} fmt.Print(s1, &#34; &#34;) fmt.Printf(&#34;%T&#34;, s1) fmt.Println() fmt.Print(s2, &#34; &#34;) fmt.Printf(&#34;%T&#34;, s2) fmt.Println() type MyMap[KEY int | string, VALUE any] map[KEY]VALUE var mp MyMap[string, int] = map[string]int{ &#34;go&#34;: 5, &#34;java&#34;: 6, } fmt.Print(mp, &#34; &#34;) fmt.Printf(&#34;%T&#34;, mp) } 运行结果： [1 2 3 4] main.MySlice[int] [1.11 2.22 3.33 4.44] main.MySlice[float64] map[go:5 java:6] main.MyMap[string,int] 泛型map type TMap[K string | int, V any] map[K]V func main() { p := make(TMap[string, any]) p[&#34;1&#34;] = 456 p[&#34;2&#34;] = 45.6 p[&#34;3&#34;] = &#34;45.6&#34; for s := range p { r := reflect.TypeOf(p[s]) fmt.Println(p[s], r.String()) } } //运行结果： 456 int 45.6 float64 45.6 string 泛型函数 泛型函数 package main import &#34;fmt&#34; func Add[T int | float64 | string](t1, t2 T) T { return t1 + t2 } func main() { fmt.Println(Add(&#34;S&#34;, &#34;3&#34;)) fmt.Println(Add(1, 2)) fmt.Println(Add(1.5, 2.6)) fmt.Println(Add[string](&#34;de&#34;, &#34;fr&#34;)) fmt.Println(Add[int](2, 4)) } 运行结果： S3 3 4.1 defr 6 泛型方法 package main import &#34;fmt&#34; type MySlice[T int | float64 | string] []T func (s MySlice[T]) GetMax() T { var max T for _, v := range s { if v &gt; max { max = v } } return max } func main() { var s1 MySlice[int] = []int{1, 22, 3, 4, 5, 6, 6} fmt.Println(s1.GetMax()) var s2 MySlice[string] = []string{&#34;hrty&#34;, &#34;ger&#34;, &#34;cre&#34;} fmt.Println(s2.GetMax()) } 运行结果： 22 hrty 泛型的使用 Go的泛型(或者或类型形参）目前可使用在了个地方
泛型类型 -类型定义中带类型形参的类型
泛型rceiver -泛型类型的receiver
泛型西数 -带类型形参的函数
自定义泛型 package main import &#34;fmt&#34; type int888 int8 type MyInt interface { ~int8 | int | int32 | int64 | float64 } func GetMacNum[T MyInt](t1, t2 T) T { if t1 &gt; t2 { return t1 } return t2 } func main() { var a int888 = 2 var b int888 = 3 fmt.Println(GetMacNum(a, b)) } ]]></content></entry><entry><title>Python自动化-Selenium基操</title><url>/posts/python/2022-10-18-python%E8%87%AA%E5%8A%A8%E5%8C%96-selenium%E5%9F%BA%E6%93%8D/</url><categories><category>python</category></categories><tags><tag>python</tag><tag>自动化</tag></tags><content type="html"><![CDATA[最近有一个新的需求要在集团的一个内部系统中根据条件获取获取Excel数据并导入另外一个系统，要用到一些自动化相关内容，所以记录一下。
什么是Selenium Selenium是一个用于Web应用程序测试的工具。Selenium测试直接运行在浏览器中，就像真正的用户在操作一样。支持的浏览器包括IE（7, 8, 9, 10, 11），Mozilla Firefox，Safari，Google Chrome，Opera，Edge等。这个工具的主要功能包括：测试与浏览器的兼容性——测试应用程序是否能够很好得工作在不同浏览器和操作系统之上。测试系统功能——创建回归测试检验软件功能和用户需求。支持自动录制动作和自动生成.Net、Java、Perl等不同语言的测试脚本。
下载安装Selenium 需要安装好python环境,不在叙述。 下载安装命令
pip3 install selenium 下载浏览器驱动 淘宝镜像地址：https://registry.npmmirror.com/binary.html?path=chromedriver/ Google官方地址：https://chromedriver.storage.googleapis.com/index.html 根据操作系统类型下载即可
使用Selenium Selenium支持的浏览器很多，这里以Chrome为例。
from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service s = Service(&#39;driver/chromedriver&#39;) # 这里的chromedriver就是刚才下载的驱动 browser = webdriver.Chrome(service=s) url = &#39;https://www.baidu.com&#39; browser.get(url) time.sleep(1) searchText = browser.find_element(By.XPATH, &#39;//*[@id=&#34;kw&#34;]&#39;) searchText.send_keys(&#34;b.sxz799.fun&#34;) time.sleep(2) searchButton = browser.find_element(By.XPATH, &#39;//*[@id=&#34;su&#34;]&#39;) searchButton.click() time.sleep(10) browser.quit() #10秒后退出浏览器 运行后的效果为打开浏览器并搜索b.sxz799.fun
大致流程就是获取html中的元素并进行操作。
获取元素Xpath方法 先打开百度首页 找到输入框，鼠标右键 -&gt; 检查
在弹出的右侧开发者工具窗口中找到输入框对应的元素
鼠标右键-&gt; Copy -&gt; Copy XPath
此时剪切板中就保存了输入框的XPath(//*[@id=&quot;kw&quot;])，搜索按钮同理。
代码优化及封装获取元素函数 优化 可以初始化chrome driver驱动时设置一下隐式等待的时间，此代码仅需调用一次即可。
browser = webdriver.Chrome(service=s) browser.implicitly_wait(10) # 隐式等待 整个页面渲染 不影响性能 第一行代码: Creates a new instance of the chrome driver.
第一行代码: Starts the service and then creates new instance of chrome driver.
第二行代码: Sets a sticky timeout to implicitly wait for an element to be found, or a command to complete. This method only needs to be called one time per session. To set the timeout for calls to execute_async_script, see set_script_timeout.
封装 def get_element(by: str, value: str): # 定位方式，定位字符串 from time import time success = True start = time() try: browser.find_element(by, value) except Exception as e: success = False print(e) print(f&#39;获取元素超时：耗时：{time() - start}&#39;) return [success, browser.find_element(by, value)] 调用 result = get_element(By.XPATH, &#39;//*[@id=&#34;kw&#34;]&#39;) if result[0]: result[1].click() 设置文件默认下载位置 options = webdriver.ChromeOptions() prefs = {&#39;profile.default_content_settings.popups&#39;: 0, &#39;download.default_directory&#39;: &#39;/Users/sxz799/Desktop/downLoadDir&#39;} options.add_experimental_option(&#39;prefs&#39;, prefs) browser = webdriver.Chrome(service=s, options=options) ]]></content></entry><entry><title>antdesignvue在iPhone手机上传文件时选择文件</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-10-10-antdesignvue%E5%9C%A8iphone%E6%89%8B%E6%9C%BA%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E6%97%B6%E9%80%89%E6%8B%A9%E6%96%87%E4%BB%B6/</url><categories><category>技巧</category></categories><tags><tag>技巧</tag><tag>Vue</tag><tag>Antd</tag><tag>前端</tag></tags><content type="html"><![CDATA[还是这个项目 PublicFile-Server 的前端相关内容。
突然发现在iPhone上级上传文件的时候直接打开了相机，而在安卓手机上就可以选择相机或者文件。
搜索后发现只需要添加:capture=&quot;null&quot;即可。 代码如下：
&lt;div&gt; &lt;a-upload-dragger :progress=&#34;progress&#34; name=&#34;file&#34; :before-upload=&#34;beforeUpload&#34; :showUploadList=&#34;true&#34; :capture=&#34;null&#34; :multiple=&#34;false&#34; action=&#34;/file/upload&#34; @change=&#34;handleChange&#34;&gt; &lt;p class=&#34;ant-upload-drag-icon&#34;&gt; &lt;inbox-outlined&gt;&lt;/inbox-outlined&gt; &lt;/p&gt; &lt;p class=&#34;ant-upload-text&#34;&gt;点击或拖拽文件到这里进行上传&lt;/p&gt; &lt;/a-upload-dragger&gt; &lt;/div&gt; 这样的话iPhone手机就可以选择图库或者文件了！
]]></content></entry><entry><title>Gin+Vue前后端分离整合部署，不再需要nginx服务器</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-09-26-gin-vue%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E6%95%B4%E5%90%88%E9%83%A8%E7%BD%B2%E4%B8%8D%E5%86%8D%E9%9C%80%E8%A6%81nginx%E6%9C%8D%E5%8A%A1%E5%99%A8/</url><categories><category>技巧</category></categories><tags><tag>Gin</tag><tag>vue</tag></tags><content type="html"><![CDATA[前言 最近在学前端，写了两个很小的项目 PublicFile-Server 、 PublicClipboard-Server-NoDB 两个项目都是前后端分离,分别用到了antdesignvue和elementUI。 两个都是单页面项目，如果用前后端分离去部署的话实在是麻烦。
Gin框架自带了静态文件服务,所以只需要简单修改代码即可实现前后端整合，当然开发的时候前后端仍然是分离的。
修改前端 前端修改起来超级简单
## vue.config.js const { defineConfig } = require(&#39;@vue/cli-service&#39;) module.exports = defineConfig({ transpileDependencies: true, publicPath: &#34;/static&#34;, //加上这一行即可 devServer: { port: 4000, proxy: { &#39;/file&#39;: { ws: false, target: &#34;http://127.0.0.1:9091&#34;, changeOrigin: true } } }, }) 修改后端 后端也是很简单的 在main.go的同级目录下新建一个static目录，然后将前端生成的dist目录下的所有文件都放进去。 然后再gin注册路由之前加上下面的代码即可
func main() { util.InitDB() model.InitAutoMigrateDB() r := gin.Default() ///添加的代码/// r.LoadHTMLGlob(&#34;static/index.html&#34;) r.Static(&#34;/static&#34;, &#34;static&#34;) r.GET(&#34;/&#34;, func(context *gin.Context) { context.HTML(200, &#34;index.html&#34;, &#34;&#34;) }) //////// router.RegRouter(r) r.Run(&#34;:&#34; + viper.GetString(&#34;server.port&#34;)) } 打包项目 后端编译后只需要将static目录和主程序一块打包即可。
]]></content></entry><entry><title>常用sql语句记录</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-09-22-%E5%B8%B8%E7%94%A8sql%E8%AF%AD%E5%8F%A5%E8%AE%B0%E5%BD%95/</url><categories><category>技巧</category></categories><tags><tag>mysql</tag></tags><content type="html">批量修改A表中数据在B表中的映射数据
UPDATE tableA a LEFT JOIN tableB b on a.Aid=b.Bid set a.codeA=b.codeB</content></entry><entry><title>Go语言实现RPC跨平台服务</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-09-03-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0rpc%E8%B7%A8%E5%B9%B3%E5%8F%B0%E6%9C%8D%E5%8A%A1/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[什么是RPC 服务 RPC，也就是远程过程调用，是分布式系统中不同节点调用的方式（进程间通信），属于 C/S 模式。RPC 由客户端发起，调用服务端的方法进行通信，然后服务端把结果返回给客户端。
RPC的核心有两个：通信协议和序列化。在 HTTP 2 之前，一般采用自定义 TCP 协议的方式进行通信，HTTP 2 出来后，也有采用该协议的，比如流行的gRPC。
序列化和反序列化是一种把传输内容编码和解码的方式，常见的编解码方式有 JSON、Protobuf 等。
在大多数 RPC的架构设计中，都有Client、Client Stub、Server、Server Stub这四个组件，Client 和 Server 之间通过 Socket 进行通信。RPC 架构如下图所示： 下面你总结下 RPC 调用的流程：
客户端（Client）调用客户端存根（Client Stub），同时把参数传给客户端存根； 客户端存根将参数打包编码，并通过系统调用发送到服务端； 客户端本地系统发送信息到服务器； 服务器系统将信息发送到服务端存根（Server Stub）； 服务端存根解析信息，也就是解码； 服务端存根调用真正的服务端程序（Sever）； 服务端（Server）处理后，通过同样的方式，把结果再返回给客户端（Client）。 RPC 调用常用于大型项目，也就是我们现在常说的微服务，而且还会包含服务注册、治理、监控等功能，是一套完整的体系。 Go 语言 RPC 简单入门 在 Go SDK 中，已经内置了 net/rpc 包来帮助开发者实现 RPC。简单来说，net/rpc 包提供了通过网络访问服务端对象方法的能力。
现在我通过一个加法运算来演示 RPC的使用，它的服务端代码如下所示：
package server type MathService struct { } type Args struct { A, B int } func (m *MathService) Add(args Args, reply *int) error { *reply = args.A + args.B return nil } 在以上代码中：
定义了MathService，用于表示一个远程服务对象；
Args 结构体用于表示参数；
Add 这个方法实现了加法的功能，加法的结果通过 replay这个指针变量返回。
有了这个定义好的服务对象，就可以把它注册到暴露的服务列表中，以供其他客户端使用了。在Go 语言中，要注册一个一个RPC 服务对象还是比较简单的，通过 RegisterName 方法即可，示例代码如下所示：
package main import ( &#34;gotour/ch22/server&#34; &#34;log&#34; &#34;net&#34; &#34;net/rpc&#34; ) func main() { rpc.RegisterName(&#34;MathService&#34;,new(server.MathService)) l, e := net.Listen(&#34;tcp&#34;, &#34;:1234&#34;) if e != nil { log.Fatal(&#34;listen error:&#34;, e) } rpc.Accept(l) } 以上示例代码中，通过 RegisterName 函数注册了一个服务对象，该函数接收两个参数：
服务名称（MathService）；
具体的服务对象，也就是我刚刚定义好的MathService 这个结构体。
然后通过 net.Listen 函数建立一个TCP 链接，在 1234 端口进行监听，最后通过 rpc.Accept 函数在该 TCP 链接上提供 MathService 这个 RPC 服务。现在客户端就可以看到MathService这个服务以及它的Add 方法了。
任何一个框架都有自己的规则，net/rpc 这个 Go 语言提供的RPC 框架也不例外。要想把一个对象注册为 RPC 服务，可以让客户端远程访问，那么该对象（类型）的方法必须满足如下条件：
方法的类型是可导出的（公开的）； 方法本身也是可导出的； 方法必须有 2 个参数，并且参数类型是可导出或者内建的； 方法必须返回一个 error 类型。 总结下来，该方法的格式如下所示：
func (t *T) MethodName(argType T1, replyType *T2) error 这里面的 T1、T2都是可以被 encoding/gob 序列化的。
第一个参数 argType 是调用者（客户端）提供的；
第二个参数 replyType是返回给调用者结果，必须是指针类型。
有了提供好的RPC 服务，现在再来看下客户端如何调用，它的代码如下所示：
package main import ( &#34;fmt&#34; &#34;gotour/ch22/server&#34; &#34;log&#34; &#34;net/rpc&#34; ) func main() { client, err := rpc.Dial(&#34;tcp&#34;, &#34;localhost:1234&#34;) if err != nil { log.Fatal(&#34;dialing:&#34;, err) } args := server.Args{A:7,B:8} var reply int err = client.Call(&#34;MathService.Add&#34;, args, &amp;reply) if err != nil { log.Fatal(&#34;MathService.Add error:&#34;, err) } fmt.Printf(&#34;MathService.Add: %d+%d=%d&#34;, args.A, args.B, reply) } 在以上实例代码中，首先通过 rpc.Dial 函数建立 TCP 链接，需要注意的是这里的 IP、端口要和RPC 服务提供的一致，确保可以建立 RCP 链接。
TCP 链接建立成功后，就需要准备远程方法需要的参数，也就是示例中的args 和 reply。参数准备好之后，就可以通过 Call 方法调用远程的RPC 服务了。Call 方法有 3 个参数，它们的作用分别如下所示：
调用的远程方法的名字，这里是MathService.Add，点前面的部分是注册的服务的名称，点后面的部分是该服务的方法；
客户端为了调用远程方法提供的参数，示例中是args；
为了接收远程方法返回的结果，必须是一个指针，也就是示例中的&amp; replay，这样客户端就可以获得服务端返回的结果了。
基于 HTTP的RPC RPC 除了可以通过 TCP 协议调用之外，还可以通过HTTP 协议进行调用，而且内置的net/rpc 包已经支持，现在我修改以上示例代码，支持 HTTP 协议的调用，服务端代码如下所示：
func main() { rpc.RegisterName(&#34;MathService&#34;, new(server.MathService)) rpc.HandleHTTP()//新增的 l, e := net.Listen(&#34;tcp&#34;, &#34;:1234&#34;) if e != nil { log.Fatal(&#34;listen error:&#34;, e) } http.Serve(l, nil)//换成http的服务 } 以上是服务端代码的修改，只需修改两处，已经在代码中标注出来了，很容易理解。
服务端修改的代码不算多，客户端修改的代码就更少了，只需要修改一处即可，修改的部分如下所示：
func main() { client, err := rpc.DialHTTP(&#34;tcp&#34;, &#34;localhost:1234&#34;) //省略了其他没有修改的代码 } 从以上代码可以看到，只需要把建立链接的方法从 Dial 换成 DialHTTP 即可。
现在分别运行服务端和客户端代码，就可以看到输出的结果了，和上面使用TCP 链接时是一样的。
此外，Go 语言 net/rpc 包提供的 HTTP 协议的 RPC 还有一个调试的 URL，运行服务端代码后，在浏览器中输入 http://localhost:1234/debug/rpc 回车，即可看到服务端注册的RPC 服务，以及每个服务的方法.
注册的 RPC 服务、方法的签名、已经被调用的次数都可以看到。
JSON RPC 跨平台通信 以上我实现的RPC 服务是基于 gob 编码的，这种编码在跨语言调用的时候比较困难，而当前在微服务架构中，RPC 服务的实现者和调用者都可能是不同的编程语言，因此我们实现的 RPC 服务要支持多语言的调用。
基于 TCP 的 JSON RPC 实现跨语言 RPC 服务的核心在于选择一个通用的编码，这样大多数语言都支持，比如常用的JSON。在 Go 语言中，实现一个 JSON RPC 服务非常简单，只需要使用 net/rpc/jsonrpc 包即可。
同样以上面的示例为例，我把它改造成支持 JSON的RPC 服务，服务端代码如下所示：
func main() { rpc.RegisterName(&#34;MathService&#34;, new(server.MathService)) l, e := net.Listen(&#34;tcp&#34;, &#34;:1234&#34;) if e != nil { log.Fatal(&#34;listen error:&#34;, e) } for { conn, err := l.Accept() if err != nil { log.Println(&#34;jsonrpc.Serve: accept:&#34;, err.Error()) return } //json rpc go jsonrpc.ServeConn(conn) } } 从以上代码可以看到，相比 gob 编码的RPC 服务，JSON 的 RPC 服务是把链接交给了jsonrpc.ServeConn这个函数处理，达到了基于 JSON 进行 RPC 调用的目的。
JSON RPC 的客户端代码也非常少，只需要修改一处，修改的部分如下所示：
func main() { client, err := jsonrpc.Dial(&#34;tcp&#34;, &#34;localhost:1234&#34;) //省略了其他没有修改的代码 } 从以上代码可以看到，只需要把建立链接的 Dial方法换成 jsonrpc 包中的即可。
以上是使用 Go 语言作为客户端调用 RPC 服务的示例，其他编程语言也是类似的，只需要遵守 JSON-RPC 规范即可。
基于 HTTP的JSON RPC 相比基于 TCP 调用的RPC 来说，使用 HTTP肯定会更方便，也更通用。Go 语言内置的jsonrpc 并没有实现基于 HTTP的传输，所以就需要自己来实现，这里参考 gob 编码的HTTP RPC 实现方式，来实现基于 HTTP的JSON RPC 服务。
还是上面的示例，我改造下让其支持 HTTP 协议，RPC 服务端代码如下所示：
func main() { rpc.RegisterName(&#34;MathService&#34;, new(server.MathService)) //注册一个path，用于提供基于http的json rpc服务 http.HandleFunc(rpc.DefaultRPCPath, func(rw http.ResponseWriter, r *http.Request) { conn, _, err := rw.(http.Hijacker).Hijack() if err != nil { log.Print(&#34;rpc hijacking &#34;, r.RemoteAddr, &#34;: &#34;, err.Error()) return } var connected = &#34;200 Connected to JSON RPC&#34; io.WriteString(conn, &#34;HTTP/1.0 &#34;+connected+&#34;\n\n&#34;) jsonrpc.ServeConn(conn) }) l, e := net.Listen(&#34;tcp&#34;, &#34;:1234&#34;) if e != nil { log.Fatal(&#34;listen error:&#34;, e) } http.Serve(l, nil)//换成http的服务 } 以上代码的实现基于 HTTP 协议的核心，即使用 http.HandleFunc 注册了一个 path，对外提供基于 HTTP 的 JSON RPC 服务。在这个 HTTP 服务的实现中，通过Hijack方法劫持链接，然后转交给 jsonrpc 处理，这样就实现了基于 HTTP 协议的 JSON RPC 服务。
实现了服务端的代码后，现在开始实现客户端调用，它的代码如下所示：
func main() { client, err := DialHTTP(&#34;tcp&#34;, &#34;localhost:1234&#34;) if err != nil { log.Fatal(&#34;dialing:&#34;, err) } args := server.Args{A:7,B:8} var reply int err = client.Call(&#34;MathService.Add&#34;, args, &amp;reply) if err != nil { log.Fatal(&#34;MathService.Add error:&#34;, err) } fmt.Printf(&#34;MathService.Add: %d+%d=%d&#34;, args.A, args.B, reply) } // DialHTTP connects to an HTTP RPC server at the specified network address // listening on the default HTTP RPC path. func DialHTTP(network, address string) (*rpc.Client, error) { return DialHTTPPath(network, address, rpc.DefaultRPCPath) } // DialHTTPPath connects to an HTTP RPC server // at the specified network address and path. func DialHTTPPath(network, address, path string) (*rpc.Client, error) { var err error conn, err := net.Dial(network, address) if err != nil { return nil, err } io.WriteString(conn, &#34;GET &#34;+path+&#34; HTTP/1.0\n\n&#34;) // Require successful HTTP response // before switching to RPC protocol. resp, err := http.ReadResponse(bufio.NewReader(conn), &amp;http.Request{Method: &#34;GET&#34;}) connected := &#34;200 Connected to JSON RPC&#34; if err == nil &amp;&amp; resp.Status == connected { return jsonrpc.NewClient(conn), nil } if err == nil { err = errors.New(&#34;unexpected HTTP response: &#34; + resp.Status) } conn.Close() return nil, &amp;net.OpError{ Op: &#34;dial-http&#34;, Net: network + &#34; &#34; + address, Addr: nil, Err: err, } } 以上这段代码的核心在于通过建立好的TCP 链接，发送 HTTP 请求调用远程的HTTP JSON RPC 服务，这里使用的是 HTTP GET 方法。
分别运行服务端和客户端，就可以看到正确的HTTP JSON RPC 调用结果了。
总结 基于 Go 语言自带的RPC 框架，讲解了 RPC 服务的实现以及调用。不过在实际的项目开发中，使用Go 语言自带的 RPC 框架并不多，但是这里我还是以自带的框架为例进行讲解，这样可以更好地理解 RPC 的使用以及实现原理。如果你可以很好地掌握它们，那么你使用第三方的 RPC 框架也可以很快上手。
在实际的项目中，比较常用的是Google的gRPC 框架，它是通过Protobuf 序列化的，是基于 HTTP/2 协议的二进制传输，并且支持很多编程语言，效率也比较高。
]]></content></entry><entry><title>Go语言RESTfulAPI服务</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-09-03-%E8%BD%ACgo%E8%AF%AD%E8%A8%80restful-api-%E6%9C%8D%E5%8A%A1/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[使用G语言编写 RESTful API 和 RPC 服务。在实际开发项目中，编写的这些服务可以被其他服务使用，这样就组成了微服务的架构；也可以被前端调用，这样就可以前后端分离。
什么是 RESTful API RESTful API 是一套规范，它可以规范我们如何对服务器上的资源进行操作。在了解 RESTful API 之前，先学习一下 HTTP Method，因为 RESTful API 和它是密不可分的。
说起 HTTP Method，最常见的就是POST和GET，最早在 HTTP 0.9 版本中，只有一个GET方法，该方法是一个幂等方法，用于获取服务器上的资源，也就是我们在浏览器中直接输入网址回车请求的方法。
在 HTTP 1.0 版本中又增加了HEAD和POST方法，其中常用的是 POST 方法，一般用于给服务端提交一个资源，导致服务器的资源发生变化。
随着网络越来越复杂，发现这两个方法是不够用的，就继续新增了方法。所以在 HTTP1.1 版本的时候，一口气增加到了 9 个，新增的方法有 HEAD、OPTIONS、PUT、DELETE、TRACE、PATCH 和 CONNECT。
GET 方法可请求一个指定资源的表示形式，使用 GET 的请求应该只被用于获取数据。 HEAD 方法用于请求一个与 GET 请求的响应相同的响应，但没有响应体。 POST 方法用于将实体提交到指定的资源，通常导致服务器上的状态变化或副作用。 PUT 方法用于请求有效载荷替换目标资源的所有当前表示。 DELETE 方法用于删除指定的资源。 CONNECT 方法用于建立一个到由目标资源标识的服务器的隧道。 OPTIONS 方法用于描述目标资源的通信选项。 TRACE 方法用于沿着到目标资源的路径执行一个消息环回测试。 PATCH 方法用于对资源应用部分修改。 在 RESTful API 中，使用的主要是以下五种 HTTP 方法：
GET，表示读取服务器上的资源； POST，表示在服务器上创建资源； PUT，表示更新或者替换服务器上的资源； DELETE，表示删除服务器上的资源； PATCH，表示更新 / 修改资源的一部分。 以上 HTTP 方法在 RESTful API 规范中是一个操作，操作的就是服务器的资源，服务器的资源通过特定的 URL 表示。
现在通过一些示例更好地理解 RESTful API，如下所示：
HTTP GET https://www.flysnow.org/users HTTP GET https://www.flysnow.org/users/123 以上是两个 GET 方法的示例：
第一个表示获取所有用户的信息；
第二个表示获取 ID 为 123 用户的信息。
下面再看一个 POST 方法的示例，如下所示：
HTTP POST https://www.flysnow.org/users 这个示例表示创建一个用户，通过 POST 方法给服务器提供创建这个用户所需的全部信息。 现在已经知道了如何创建一个用户，那么如果要更新某个特定的用户怎么做呢？其实也非常简单，示例代码如下所示：
HTTP PUT https://www.flysnow.org/users/123 这表示要更新 / 替换 ID 为 123 的这个用户，在更新的时候，会通过 PUT 方法提供更新这个用户需要的全部用户信息。这里 PUT 方法和 POST 方法不太一样的是，从 URL 上看，PUT 方法操作的是单个资源，比如这里 ID 为 123 的用户。
小提示：如果要更新一个用户的部分信息，使用 PATCH 方法更恰当。
看到这里，相信你已经知道了如何删除一个用户，示例代码如下所示：
HTTP DELETE https://www.flysnow.org/users/123 DELETE 方法的使用和 PUT 方法一样，也是操作单个资源，这里是删除 ID 为 123 的这个用户。
一个简单的 RESTful API 现在通过一个使用 Golang 实现 RESTful API 风格的示例，加深 RESTful API 的理解。 Go 语言的一个很大的优势，就是可以很容易地开发出网络后台服务，而且性能快、效率高。在开发后端 HTTP 网络应用服务的时候，我们需要处理很多 HTTP 的请求访问，比如常见的RESTful API 服务，就要处理很多 HTTP 请求，然后把处理的信息返回给使用者。对于这类需求，Golang 提供了内置的 net/http 包帮我们处理这些 HTTP 请求，让我们可以比较方便地开发一个 HTTP 服务。
下面我们来看一个简单的 HTTP 服务的 Go 语言实现，代码如下所示：
func main() { http.HandleFunc(&#34;/users&#34;,handleUsers) http.ListenAndServe(&#34;:8080&#34;, nil) } func handleUsers(w http.ResponseWriter, r *http.Request){ fmt.Fprintln(w,&#34;ID:1,Name:张三&#34;) fmt.Fprintln(w,&#34;ID:2,Name:李四&#34;) fmt.Fprintln(w,&#34;ID:3,Name:王五&#34;) } 运行程序后在终端输入下面命令 curl http://localhost:8080/users 得到如下结果
ID:1,Name:张三 ID:2,Name:李四 ID:3,Name:王五 也就是获取所有的用户信息，但是这并不是一个 RESTful API，因为使用者不仅可以通过 HTTP GET 方法获得所有的用户信息，还可以通过 POST、DELETE、PUT 等 HTTP 方法获得所有的用户信息，这显然不符合 RESTful API 的规范。 现在对以上示例进行修改，使它符合 RESTful API 的规范，修改后的示例代码如下所示：
func handleUsers(w http.ResponseWriter, r *http.Request){ switch r.Method { case &#34;GET&#34;: w.WriteHeader(http.StatusOK) fmt.Fprintln(w,&#34;ID:1,Name:张三&#34;) fmt.Fprintln(w,&#34;ID:2,Name:李四&#34;) fmt.Fprintln(w,&#34;ID:3,Name:王五&#34;) default: w.WriteHeader(http.StatusNotFound) fmt.Fprintln(w,&#34;not found&#34;) } } 这里我只修改了 handleUsers 函数，在该函数中增加了只在使用 GET 方法时，才获得所有用户的信息，其他情况返回 not found。
现在再运行这个示例，会发现只能通过 HTTP GET 方法进行访问了，使用其他方法会提示 not found。
➜ awesomeProject curl -X POST http://localhost:8080/users ID:1,Name:张三 ID:2,Name:李四 ID:3,Name:王五 ➜ awesomeProject curl -X POST http://localhost:8080/users not found ➜ awesomeProject RESTful JSON API 在项目中最常见的是使用 JSON 格式传输信息，也就是我们提供的 RESTful API 要返回 JSON 内容给使用者。
同样用上面的示例，我把它改造成可以返回 JSON 内容的方式，示例代码如下所示：
//数据源，类似MySQL中的数据 var users = []User{ {ID: 1,Name: &#34;张三&#34;}, {ID: 2,Name: &#34;李四&#34;}, {ID: 3,Name: &#34;王五&#34;}, } func handleUsers(w http.ResponseWriter, r *http.Request){ switch r.Method { case &#34;GET&#34;: users,err:=json.Marshal(users) if err!=nil { w.WriteHeader(http.StatusInternalServerError) fmt.Fprint(w,&#34;{\&#34;message\&#34;: \&#34;&#34;+err.Error()+&#34;\&#34;}&#34;) }else { w.WriteHeader(http.StatusOK) w.Write(users) } default: w.WriteHeader(http.StatusNotFound) fmt.Fprint(w,&#34;{\&#34;message\&#34;: \&#34;not found\&#34;}&#34;) } } //用户 type User struct { ID int Name string } 从以上代码可以看到，这次的改造主要是新建了一个 User 结构体，并且使用 users 这个切片存储所有的用户，然后在 handleUsers 函数中把它转化为一个 JSON 数组返回。这样，就实现了基于 JSON 数据格式的 RESTful API。
curl http://localhost:8080/users [{&#34;ID&#34;:1,&#34;Name&#34;:&#34;张三&#34;},{&#34;ID&#34;:2,&#34;Name&#34;:&#34;李四&#34;},{&#34;ID&#34;:3,&#34;Name&#34;:&#34;王五&#34;}] curl -X POST http://localhost:8080/users {&#34;message&#34;: &#34;not found&#34;} Gin 框架 虽然 Go 语言自带的 net/http 包，可以比较容易地创建 HTTP 服务，但是它也有很多不足：
不能单独地对请求方法（POST、GET 等）注册特定的处理函数；
不支持 Path 变量参数；
不能自动对 Path 进行校准；
性能一般；
扩展性不足；
&hellip;
基于以上这些不足，出现了很多 Golang Web 框架，如 Mux，Gin、Fiber 等，今天学习的就是这款使用最多的 Gin 框架。
引入 Gin 框架 Gin 框架是一个在 Github 上开源的 Web 框架，封装了很多 Web 开发需要的通用功能，并且性能也非常高，可以让我们很容易地写出 RESTful API。
Gin 框架其实是一个模块，也就是 Go Mod，所以采用 Go Mod 的方法引入即可。
首先需要下载安装 Gin 框架，安装代码如下：
go get -u github.com/gin-gonic/gin 然后就可以在 Go 语言代码中导入使用了，导入代码如下：
import &#34;github.com/gin-gonic/gin&#34; 通过以上安装和导入这两个步骤，就可以在你的 Go 语言项目中使用 Gin 框架了。
使用 Gin 框架 现在，已经引入了 Gin 框架，下面我就是用 Gin 框架重写上面的示例，修改的代码如下所示：
func main() { r:=gin.Default() r.GET(&#34;/users&#34;, listUser) r.Run(&#34;:8080&#34;) } func listUser(c *gin.Context) { c.JSON(200,users) } 相比 net/http 包，Gin 框架的代码非常简单，通过它的 GET 方法就可以创建一个只处理 HTTP GET 方法的服务，而且输出 JSON 格式的数据也非常简单，使用 c.JSON 方法即可。
最后通过 Run 方法启动 HTTP 服务，监听在 8080 端口。现在运行这个 Gin 示例，在浏览器中输入 http://localhost:8080/users，看到的信息和通过 net/http 包实现的效果是一样的。
获取特定的用户 现在你已经掌握了如何使用 Gin 框架创建一个简单的 RESTful API，并且可以返回所有的用户信息，那么如何获取特定用户的信息呢？
我们知道，如果要获得特定用户的信息，需要使用的是 GET 方法，并且 URL 格式如下所示：
http://localhost:8080/users/2
以上示例中的 2 是用户的 ID，也就是通过 ID 来获取特定的用户。
下面通过 Gin 框架 Path 路径参数来实现这个功能，示例代码如下：
func main() { //省略没有改动的代码 r.GET(&#34;/users/:id&#34;, getUser) } func getUser(c *gin.Context) { id := c.Param(&#34;id&#34;) var user User found := false //类似于数据库的SQL查询 for _, u := range users { if strings.EqualFold(id, strconv.Itoa(u.ID)) { user = u found = true break } } if found { c.JSON(200, user) } else { c.JSON(404, gin.H{ &#34;message&#34;: &#34;用户不存在&#34;, }) } } 在 Gin 框架中，路径中使用冒号表示 Path 路径参数，比如示例中的 :id，然后在 getUser 函数中可以通过 c.Param(&ldquo;id&rdquo;) 获取需要查询用户的 ID 值。
小提示：Param 方法的参数要和 Path 路径参数中的一致，比如示例中都是 ID。
现在运行这个示例，通过浏览器访问 http://localhost:8080/users/2，就可以获得 ID 为 2 的用户，输出信息如下所示：
{&#34;ID&#34;:2,&#34;Name&#34;:&#34;李四&#34;} 可以看到，已经正确的获取到了 ID 为 2 的用户，他的名字叫李四。
假如我们访问一个不存在的 ID，会得到什么结果呢？比如 99，示例如下所示：
curl http://localhost:8080/users/99 {&#34;message&#34;:&#34;用户不存在&#34;} 从以上示例输出可以看到，返回了『用户不存在』的信息，和我们代码中处理的逻辑一样。
新增一个用户 现在已经可以使用 Gin 获取所有用户，还可以获取特定的用户，那么你也应该知道如何新增一个用户了，现在我通过 Gin 实现如何新增一个用户，看和你想的方案是否相似。
根据 RESTful API 规范，实现新增使用的是 POST 方法，并且 URL 的格式为 http://localhost:8080/users ，向这个 URL 发送数据，就可以新增一个用户，然后返回创建的用户信息。
现在使用 Gin 框架实现新增一个用户，示例代码如下：
func main() { //省略没有改动的代码 r.POST(&#34;/users&#34;, createUser) } func createUser(c *gin.Context) { name := c.DefaultPostForm(&#34;name&#34;, &#34;&#34;) if name != &#34;&#34; { u := User{ID: len(users) + 1, Name: name} users = append(users, u) c.JSON(http.StatusCreated,u) } else { c.JSON(http.StatusOK, gin.H{ &#34;message&#34;: &#34;请输入用户名称&#34;, }) } } 以上新增用户的主要逻辑是获取客户端上传的 name 值，然后生成一个 User 用户，最后把它存储到 users 集合中，达到新增用户的目的。
在这个示例中，使用 POST 方法来新增用户，所以只能通过 POST 方法才能新增用户成功。
现在运行这个示例，然后通过如下命令发送一个新增用户的请求，查看结果：
curl -X POST -d &#39;name=golang&#39; http://localhost:8080/users {&#34;ID&#34;:4,&#34;Name&#34;:&#34;golang&#34;} 可以看到新增用户成功，并且返回了新增的用户，还有分配的 ID。
总结 Go 语言已经给我们提供了比较强大的 SDK，让我们可以很容易地开发网络服务的应用，而借助第三方的 Web 框架，可以让这件事情更容易、更高效。比如这篇文章介绍的 Gin 框架，就可以很容易让我们开发出 RESTful API，更多关于 Gin 框架的使用可以参考 Golang Gin 实战系列文章。
在我们做项目开发的时候，要善于借助已经有的轮子，让自己的开发更有效率，也更容易实现。
]]></content></entry><entry><title>oh-my-zsh安装配置记录</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-09-01-oh-my-zsh%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/</url><categories><category>技巧</category></categories><tags><tag>oh-my-zsh</tag></tags><content type="html"><![CDATA[Oh My Zsh is a delightful, open source, community-driven framework for managing your Zsh configuration. It comes bundled with thousands of helpful functions, helpers, plugins, themes, and a few things that make you shout&hellip;
&ldquo;Oh My ZSH!&rdquo;
官网地址 安装 安装命令(二者均可)：
sh -c &#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&#34; sh -c &#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)&#34; 环境变量失效？ 将~/.bash_profile文件中的变量复制到~/.zshrc目录 macos下如果你之前用的是zsh 就将~/.zshrc.pre-oh-my-zsh文件中的变量复制到~/.zshrc目录即可
修改主题 // ~/.zshrc # Set name of the theme to load --- if set to &#34;random&#34;, it will # load a random theme each time oh-my-zsh is loaded, in which case, # to know which specific one was loaded, run: echo $RANDOM_THEME # See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes ZSH_THEME=&#34;robbyrussell&#34; 插件 常用的两个插件
zsh-autosuggestions 自动建议补全 安装命令
git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions zsh-syntax-highlighting 语法高亮插件 安装命令
git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting 安装好以后启用插件,也是在~/.zshrc中配置
// ~/.zshrc # Which plugins would you like to load? # Standard plugins can be found in $ZSH/plugins/ # Custom plugins may be added to $ZSH_CUSTOM/plugins/ # Example format: plugins=(rails git textmate ruby lighthouse) # Add wisely, as too many plugins slow down shell startup. plugins=(git z zsh-autosuggestions zsh-syntax-highlighting) 刚安装好以后应该是只有一个git,后门两个是刚才下载的
z是自带插件，可以历史目录记录
配置好以后使用下面命令更新配置
source ~/.zshrc ]]></content></entry><entry><title>Go语言模块化管理与协作开发</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-09-01-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9D%97%E5%8C%96%E7%AE%A1%E7%90%86%E4%B8%8E%E5%8D%8F%E4%BD%9C%E5%BC%80%E5%8F%91/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[任何业务，都是从简单向复杂演进的。而在业务演进的过程中，技术是从单体向多模块、多服务演进的。技术的这种演进方式的核心目的是复用代码、提高效率。
Go 语言中的包 什么是包 在业务非常简单的时候，甚至可以把代码写到一个 Go 文件中。但随着业务逐渐复杂，就会发现，如果代码都放在一个 Go 文件中，会变得难以维护，这时候就需要抽取代码，把相同业务的代码放在一个目录中。在 Go 语言中，这个目录叫作包。
在 Go 语言中，一个包是通过package 关键字定义的，最常见的就是main 包，它的定义如下所示：
package main
此外，之前演示示例经常使用到的 fmt 包，也是通过 package 关键字声明的。
一个包就是一个独立的空间，你可以在这个包里定义函数、结构体等。这时，我们认为这些函数、结构体是属于这个包的。 所有的go文件除了空行和注释，都应该在第一行声明所在的包，且同一个目录下的所有go文件都应该在一个包里(推荐包名和文件夹名保持一致)。
使用包 如果想使用一个包里的函数或者结构体，就需要先导入这个包，才能使用，比如常用的 fmt包，代码示例如下所示。
package main import &#34;fmt&#34; func main() { fmt.Println(&#34;先导入fmt包，才能使用&#34;) } 要导入一个包，需要使用 import 关键字；如果需要同时导入多个包，则可以使用小括号，示例代码如下所示。
import ( &#34;fmt&#34; &#34;os&#34; ) 从以上示例可以看到，该示例导入了 fmt 和 os 这两个包，使用了小括号，每一行写了一个要导入的包。
作用域 讲到了包之间的导入和使用，就不得不提作用域这个概念，因为只有满足作用域的函数才可以被调用。
在Java 语言中，通过 public、private 这些修饰符修饰一个类的作用域；
但是在Go 语言中，并没有这样的作用域修饰符，它是通过首字母是否大写来区分的，这同时也体现了 Go 语言的简洁。
如上述示例中 fmt 包中的Println 函数：
它的首字母就是大写的 P，所以该函数才可以在 main 包中使用；
如果 Println 函数的首字母是小写的 p，那么它只能在 fmt 包中被使用，不能跨包使用。
这里我为你总结下 Go 语言的作用域：
Go 语言中，所有的定义，比如函数、变量、结构体等，如果首字母是大写，那么就可以被其他包使用；
反之，如果首字母是小写的，就只能在同一个包内使用。
自定义包 我们也可以自定义自己的包，通过包的方式把相同业务、相同职责的代码放在一起。比如你有一个 util 包，用于存放一些常用的工具函数，项目结构如下所示：
myproject ├── main.go └── util └── string.go 在 Go 语言中，一个包对应一个文件夹，上面的项目结构示例也验证了这一点。在这个示例中，有一个 util 文件夹，它里面有一个 string.go 文件，这个 Go 语言文件就属于 util 包，它的包定义如下所示： package util
可以看到，Go 语言中的包是代码的一种组织形式，通过包把相同业务或者相同职责的代码放在一起。通过包对代码进行归类，便于代码维护以及被其他包调用，提高团队协作效率。
init 函数 除了 main 这个特殊的函数外，Go 语言还有一个特殊的函数——init，通过它可以实现包级别的一些初始化操作。
init 函数没有返回值，也没有参数，它先于 main 函数执行，代码如下所示：
func init() { fmt.Println(&#34;init in main.go &#34;) } 一个包中可以有多个 init 函数，但是它们的执行顺序并不确定，所以如果你定义了多个 init 函数的话，要确保它们是相互独立的，一定不要有顺序上的依赖。
那么 init 函数作用是什么呢? 其实就是在导入一个包时，可以对这个包做一些必要的初始化操作，比如数据库连接和一些数据的检查，确保我们可以正确地使用这个包。
Go 语言中的模块 如果包是比较低级的代码组织形式的话，那么模块就是更高级别的，在 Go 语言中，一个模块可以包含很多个包，所以模块是相关的包的集合。
在 Go 语言中：
一个模块通常是一个项目，比如这个专栏实例中使用的 gotour 项目；
也可以是一个框架，比如常用的 Web 框架 gin。
go mod Go 语言为我们提供了 go mod 命令来创建一个模块（项目），比如要创建一个 gotour 模块，你可以通过如下命令实现：
➜ go mod init gotour go: creating new go.mod: module gotour 运行这一命令后，你会看到已经创建好一个名字为 gotour 的文件夹，里面有一个 go.mod 文件，它里面的内容如下所示：
module gotour go 1.15 第一句是该项目的模块名，也就是 gotour；
第二句表示要编译该模块至少需要Go 1.15 版本的 SDK。
小提示：模块名最好是以自己的域名开头，比如 flysnow.org/gotour，这样就可以很大程度上保证模块名的唯一，不至于和其他模块重名。
使用第三方模块 模块化为什么可以提高开发效率？最重要的原因就是复用了现有的模块，Go 语言也不例外。比如你可以把项目中的公共代码抽取为一个模块，这样就可以供其他项目使用，不用再重复开发；同理，在 Github 上也有很多开源的 Go 语言项目，它们都是一个个独立的模块，也可以被我们直接使用，提高我们的开发效率，比如 Web 框架 gin-gonic/gin。
众所周知，在使用第三方模块之前，需要先设置下 Go 代理，也就是 GOPROXY，这样我们就可以获取到第三方模块了。
在这里我推荐 goproxy.io 这个代理，非常好用，速度也很快。要使用这个代理，需要进行如下代码设置：
go env -w GO111MODULE=on go env -w GOPROXY=https://goproxy.io,direct 打开终端，输入这一命令回车即可设置成功。
在实际的项目开发中，除了第三方模块外，还有我们自己开发的模块，放在了公司的 GitLab上，这时候就要把公司 Git 代码库的域名排除在 Go PROXY 之外，为此 Go 语言提供了GOPRIVATE 这个环境变量帮助我们达到目的。通过如下命令即可设置 GOPRIVATE：
# 设置不走 proxy 的私有仓库，多个用逗号相隔（可选） go env -w GOPRIVATE=*.corp.example.com 以上域名只是一个示例，实际使用时你要改成自己公司私有仓库的域名。
一切都准备好就可以使用第三方的模块了，假设我们要使用 Gin 这个 Web 框架，首先需要安装它，通过如下命令即可安装 Gin 这个 Web 框架:
go get -u github.com/gin-gonic/gin 安装成功后，就可以像 Go 语言的标准包一样，通过 import 命令导入你的代码中使用它，代码如下所示：
package main import ( &#34;fmt&#34; &#34;github.com/gin-gonic/gin&#34; ) func main() { fmt.Println(&#34;先导入fmt包，才能使用&#34;) r := gin.Default() r.Run() } 以上代码现在还无法编译通过，因为还没有同步 Gin 这个模块的依赖，也就是没有把它添加到go.mod 文件中。通过如下命令可以添加缺失的模块：
go mod tidy 运行这一命令，就可以把缺失的模块添加进来，同时它也可以移除不再需要的模块。这时你再查看 go.mod 文件，会发现内容已经变成了这样：
module gotour go 1.15 require ( github.com/gin-gonic/gin v1.6.3 github.com/golang/protobuf v1.4.2 // indirect github.com/google/go-cmp v0.5.2 // indirect github.com/kr/text v0.2.0 // indirect github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect github.com/modern-go/reflect2 v1.0.1 // indirect github.com/niemeyer/pretty v0.0.0-20200227124842-a10e7caefd8e // indirect github.com/stretchr/testify v1.6.1 // indirect golang.org/x/sys v0.0.0-20201009025420-dfb3f7c4e634 // indirect golang.org/x/xerrors v0.0.0-20200804184101-5ec99f83aff1 // indirect gopkg.in/check.v1 v1.0.0-20200227125254-8fa46927fb4f // indirect gopkg.in/yaml.v2 v2.3.0 // indirect ) 所以我们不用手动去修改 go.mod 文件，通过 Go 语言的工具链比如 go mod tidy 命令，就可以帮助我们自动地维护、自动地添加或者修改 go.mod 的内容。
总结 在 Go 语言中，包是同一目录中，编译在一起的源文件的集合。包里面含有函数、类型、变量和常量，不同包之间的调用，必须要首字母大写才可以。
而模块又是相关的包的集合，它里面包含了很多为了实现该模块的包，并且还可以通过模块的方式，把已经完成的模块提供给其他项目（模块）使用，达到了代码复用、研发效率提高的目的。
所以对于你的项目（模块）来说，它具有模块 ➡ 包 ➡ 函数类型这样三层结构，同一个模块中，可以通过包组织代码，达到代码复用的目的；在不同模块中，就需要通过模块的引入，达到这个目的。
]]></content></entry><entry><title>Go语言代码检查和优化</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-30-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%BB%A3%E7%A0%81%E6%A3%80%E6%9F%A5%E5%92%8C%E4%BC%98%E5%8C%96/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[代码规范检查 什么是代码规范检查 代码规范检查，顾名思义，是从 Go 语言层面出发，依据 Go 语言的规范，对你写的代码进行的静态扫描检查，这种检查和你的业务无关。
比如你定义了个常量，从未使用过，虽然对代码运行并没有造成什么影响，但是这个常量是可以删除的，代码如下所示：
const name = &#34;Golang&#34; func main() { } 示例中的常量 name 其实并没有使用，所以为了节省内存你可以删除它，这种未使用常量的情况就可以通过代码规范检查检测出来。 再比如，你调用了一个函数，该函数返回了一个 error，但是你并没有对该 error 做判断，这种情况下，程序也可以正常编译运行。但是代码写得不严谨，因为返回的 error 被我们忽略了。代码如下所示：
func main() { os.Mkdir(&#34;tmp&#34;,0666) } 示例代码中，Mkdir 函数是有返回 error 的，但是并没有对返回的 error 做判断，这种情况下，哪怕创建目录失败，你也不知道，因为错误被忽略了。如果使用代码规范检查，这类潜在的问题也会被检测出来。
以上两个例子可以理解什么是代码规范检查、它有什么用。除了这两种情况，还有拼写问题、死代码、代码简化检测、命名中带下划线、冗余代码等，都可以使用代码规范检查检测出来。
golangci-lint 要想对代码进行检查，则需要对代码进行扫描，静态分析写的代码是否存在规范问题。
小提示：静态代码分析是不会运行代码的。
可用于 Go 语言代码分析的工具有很多，比如 golint、gofmt、misspell 等，如果一一引用配置，就会比较烦琐，所以通常我们不会单独地使用它们，而是使用 golangci-lint。
golangci-lint 是一个集成工具，它集成了很多静态代码分析工具，便于我们使用。通过配置这一工具，我们可以很灵活地启用需要的代码规范检查。
如果要使用 golangci-lint，首先需要安装。因为 golangci-lint 本身就是 Go 语言编写的，所以我们可以从源代码安装它，打开终端，输入如下命令即可安装。
go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest 安装完成后，在终端输入如下命令，检测是否安装成功。
golangci-lint version golangci-lint has version v1.49.0 built from (unknown, mod sum: &#34;h1:I8WHOavragDttlLHtSraHn/h39C+R60bEQ5NoGcHQr8=&#34;) on (unknown) 小提示：在 MacOS 下也可以使用 brew 来安装 golangci-lint。
好了，安装成功 golangci-lint 后，就可以使用它进行代码检查了，我以上面示例中的常量 name 和 Mkdir 函数为例，演示 golangci-lint 的使用。在终端输入如下命令回车：
golangci-lint run . //结果 main.go:8:10: Error return value of `os.Mkdir` is not checked (errcheck) os.Mkdir(&#34;tmp&#34;, 0666) ^ main.go:5:7: const `name` is unused (unused) const name = &#34;Golang&#34; ^ 通过代码检测结果可以看到，两个代码规范问题都被检测出来了。
golangci-lint 配置 golangci-lint 的配置比较灵活，比如你可以自定义要启用哪些 linter。golangci-lint 默认启用的 linter，包括这些：
deadcode - 死代码检查 errcheck - 返回错误是否使用检查 gosimple - 检查代码是否可以简化 govet - 代码可疑检查，比如格式化字符串和类型不一致 ineffassign - 检查是否有未使用的代码 staticcheck - 静态分析检查 structcheck - 查找未使用的结构体字段 typecheck - 类型检查 unused - 未使用代码检查 varcheck - 未使用的全局变量和常量检查 小提示：golangci-lint 支持的更多 linter，可以在终端中输入 golangci-lint linters 命令查看，并且可以看到每个 linter 的说明。
如果要修改默认启用的 linter，就需要对 golangci-lint 进行配置。即在项目根目录下新建一个名字为 .golangci.yml 的文件，这就是 golangci-lint 的配置文件。在运行代码规范检查的时候，golangci-lint 会自动使用它。假设我只启用 unused 检查，可以这样配置：
.golangci.yml linters: disable-all: true enable: - unused 在团队多人协作开发中，有一个固定的 golangci-lint 版本是非常重要的，这样大家就可以基于同样的标准检查代码。要配置 golangci-lint 使用的版本也比较简单，在配置文件中添加如下代码即可：
service: golangci-lint-version: 1.32.2 # use the fixed version to not introduce new linters unexpectedly 此外，你还可以针对每个启用的 linter 进行配置，比如要设置拼写检测的语言为 US，可以使用如下代码设置：
linters-settings: misspell: locale: US golangci-lint 的配置比较多，你自己可以灵活配置。关于 golangci-lint 的更多配置可以参考 官方文档 ，给出一个常用的
.golangci.yml linters-settings: golint: min-confidence: 0 misspell: locale: US linters: disable-all: true enable: - typecheck - goimports - misspell - govet - golint - ineffassign - gosimple - deadcode - structcheck - unused - errcheck service: golangci-lint-version: 1.32.2 # use the fixed version to not introduce new linters unexpectedly 集成 golangci-lint 到 CI 代码检查一定要集成到 CI 流程中，效果才会更好，这样开发者提交代码的时候，CI 就会自动检查代码，及时发现问题并进行修正。
不管你是使用 Jenkins，还是 Gitlab CI，或者 Github Action，都可以通过Makefile的方式运行 golangci-lint。现在我在项目根目录下创建一个 Makefile 文件，并添加如下代码：
Makefile getdeps: @mkdir -p ${GOPATH}/bin @which golangci-lint 1&gt;/dev/null || (echo &#34;Installing golangci-lint&#34; &amp;&amp; go get github.com/golangci/golangci-lint/cmd/golangci-lint@v1.32.2) lint: @echo &#34;Running $@ check&#34; @GO111MODULE=on ${GOPATH}/bin/golangci-lint cache clean @GO111MODULE=on ${GOPATH}/bin/golangci-lint run --timeout=5m --config ./.golangci.yml verifiers: getdeps lint 好了，现在你就可以把如下命令添加到你的 CI 中了，它可以帮你自动安装 golangci-lint，并检查你的代码。
make verifiers 性能优化 性能优化的目的是让程序更好、更快地运行，但是它不是必要的，这一点一定要记住。所以在程序开始的时候，不必刻意追求性能优化，先大胆地写代码就好了，写正确的代码是性能优化的前提。
堆分配还是栈 在比较古老的 C 语言中，内存分配是手动申请的，内存释放也需要手动完成。
手动控制有一个很大的好处就是你需要多少就申请多少，可以最大化地利用内存；
但是这种方式也有一个明显的缺点，就是如果忘记释放内存，就会导致内存泄漏。
所以，为了让程序员更好地专注于业务代码的实现，Go 语言增加了垃圾回收机制，自动地回收不再使用的内存。
Go 语言有两部分内存空间：栈内存和堆内存。
栈内存由编译器自动分配和释放，开发者无法控制。栈内存一般存储函数中的局部变量、参数等，函数创建的时候，这些内存会被自动创建；函数返回的时候，这些内存会被自动释放。
堆内存的生命周期比栈内存要长，如果函数返回的值还会在其他地方使用，那么这个值就会被编译器自动分配到堆上。堆内存相比栈内存来说，不能自动被编译器释放，只能通过垃圾回收器才能释放，所以栈内存效率会很高。
逃逸分析 既然栈内存的效率更高，肯定是优先使用栈内存。那么 Go 语言是如何判断一个变量应该分配到堆上还是栈上的呢？这就需要逃逸分析了。下面通过一个示例来学习逃逸分析，代码如下：
func newString() *string{ s:=new(string) *s = &#34;Golang&#34; return s } 在这个示例中：
通过 new 函数申请了一块内存；
然后把它赋值给了指针变量 s；
最后通过 return 关键字返回。
小提示：以上 newString 函数是没有意义的，这里只是为了方便演示。 现在通过逃逸分析来看下是否发生了逃逸，命令如下：
go build -gcflags=&#34;-m -l&#34; . 结果 # awesomeProject ./main.go:4:10: new(string) escapes to heap 在这一命令中，-m 表示打印出逃逸分析信息，-l 表示禁止内联，可以更好地观察逃逸。从以上输出结果可以看到，发生了逃逸，也就是说指针作为函数返回值的时候，一定会发生逃逸。
逃逸到堆内存的变量不能马上被回收，只能通过垃圾回收标记清除，增加了垃圾回收的压力，所以要尽可能地避免逃逸，让变量分配在栈内存上，这样函数返回时就可以回收资源，提升效率。
下面我对 newString 函数进行了避免逃逸的优化，优化后的函数代码如下：
func newString() string{ s:=new(string) *s = &#34;Golang&#34; return *s } 再次通过命令查看以上代码的逃逸分析，命令如下：
go build -gcflags=&#34;-m -l&#34; . 运行结果 # awesomeProject ./main.go:4:10: new(string) does not escape 通过分析结果可以看到，虽然还是声明了指针变量 s，但是函数返回的并不是指针，所以没有发生逃逸。
这就是关于指针作为函数返回逃逸的例子，那么是不是不使用指针就不会发生逃逸了呢？下面看个例子，代码如下：
fmt.Println(&#34;Golang&#34;) go build -gcflags=&#34;-m -l&#34; . 运行结果 ./main.go:7:13: ... argument does not escape ./main.go:7:14: &#34;Golang&#34; escapes to heap 观察这一结果，你会发现「Golang」这个字符串逃逸到了堆上，这是因为「Golang」这个字符串被已经逃逸的指针变量引用，所以它也跟着逃逸了，引用代码如下：
func (p *pp) printArg(arg interface{}, verb rune) { p.arg = arg //省略其他无关代码 } 所以被已经逃逸的指针引用的变量也会发生逃逸。
Go 语言中有 3 个比较特殊的类型，它们是 slice、map 和 chan，被这三种类型引用的指针也会发生逃逸，看个这样的例子：
func main() { m:=map[int]*string{} s:=&#34;Golang&#34; m[0] = &amp;s } go build -gcflags=&#34;-m -l&#34; . 运行结果 # awesomeProject ./main.go:5:2: moved to heap: s ./main.go:4:22: map[int]*string{} does not escape 从这一结果可以看到，变量 m 没有逃逸，反而被变量 m 引用的变量 s 逃逸到了堆上。所以被map、slice 和 chan 这三种类型引用的指针一定会发生逃逸的。
逃逸分析是判断变量是分配在堆上还是栈上的一种方法，在实际的项目中要尽可能避免逃逸，这样就不会被 GC 拖慢速度，从而提升效率。
小技巧：从逃逸分析来看，指针虽然可以减少内存的拷贝，但它同样会引起逃逸，所以要根据实际情况选择是否使用指针。
优化技巧 通过前面小节的介绍，相信你已经了解了栈内存和堆内存，以及变量什么时候会逃逸，那么在优化的时候思路就比较清晰了，因为都是基于以上原理进行的。下面我总结几个优化的小技巧：
第 1 个需要介绍的技巧是尽可能避免逃逸，因为栈内存效率更高，还不用 GC。比如小对象的传参，array 要比 slice 效果好。
如果避免不了逃逸，还是在堆上分配了内存，那么对于频繁的内存申请操作，我们要学会重用内存，比如使用 sync.Pool，这是第 2 个技巧。
第 3 个技巧就是选用合适的算法，达到高性能的目的，比如空间换时间。
小提示：性能优化的时候，要结合基准测试，来验证自己的优化是否有提升。
以上是基于 GO 语言的内存管理机制总结出的 3 个方向的技巧，基于这 3 个大方向基本上可以优化出你想要的效果。除此之外，还有一些小技巧，比如要尽可能避免使用锁、并发加锁的范围要尽可能小、使用 StringBuilder 做 string 和 [ ] byte 之间的转换、defer 嵌套不要太多等等。
最后推荐一个 Go 语言自带的性能剖析的工具 pprof，通过它你可以查看 CPU 分析、内存分析、阻塞分析、互斥锁分析
总结 主要学习了代码规范检查和性能优化两部分内容，其中代码规范检查是从工具使用的角度学习，而性能优化可能涉及的点太多，所以是从原理的角度讲解，明白了原理，就能更好地优化代码。
是否进行性能优化取决于两点：业务需求和自我驱动。所以不要刻意地去做性能优化，尤其是不要提前做，先保证代码正确并上线，然后再根据业务需要，决定是否进行优化以及花多少时间优化。自我驱动其实是一种编码能力的体现，比如有经验的开发者在编码的时候，潜意识地就避免了逃逸，减少了内存拷贝，在高并发的场景中设计了低延迟的架构。
]]></content></entry><entry><title>Go语言单元测试</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-29-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[单元测试 什么是单元测试 顾名思义，单元测试强调的是对单元进行测试。在开发中，一个单元可以是一个函数、一个模块等。一般情况下，你要测试的单元应该是一个完整的最小单元，比如 Go 语言的函数。这样的话，当每个最小单元都被验证通过，那么整个模块、甚至整个程序就都可以被验证通过。 单元测试由开发者自己编写，也就是谁改动了代码，谁就要编写相应的单元测试代码以验证本次改动的正确性。
Go 语言的单元测试 虽然每种编程语言里单元测试的概念是一样的，但它们对单元测试的设计不一样。Go 语言也有自己的单元测试规范，通过典型的例子斐波那契数列进行演示。 斐波那契数列是一个经典的黄金分隔数列：它的第 0 项是 0；第 1 项是 1；从第 2 项开始，每一项都等于前两项之和。所以它的数列是：0、1、1、2、3、5、8、13、21……
说明：为了便于总结后面的函数方程式，这里特意写的从第 0 项开始，其实现实中没有第 0 项。
根据以上规律，可以总结出它的函数方程式。
F(0)=0 F(1)=1 F(n)=F(n - 1)+F(n - 2) 有了函数方程式，再编写一个 Go 语言函数来计算斐波那契数列就比较简单了，代码如下：
func Fibonacci(n int) int { if n &lt; 0 { return 0 } if n == 0 { return 0 } if n == 1 { return 1 } return Fibonacci(n-1) + Fibonacci(n-2) } Fibonacci 函数已经编写好了，可以供其他开发者使用，不过在使用之前，需要先对它进行单元测试。需要新建一个 go 文件用于存放单元测试代码。
//main_test.go func TestFibonacci(t *testing.T) { type args struct { n int } tests := []struct { name string args args want int }{ {&#34;1&#34;, args{0}, 0}, {&#34;1&#34;, args{1}, 1}, {&#34;1&#34;, args{2}, 1}, {&#34;1&#34;, args{3}, 2}, {&#34;1&#34;, args{4}, 3}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := Fibonacci(tt.args.n); got != tt.want { t.Errorf(&#34;Fibonacci() = %v, want %v&#34;, got, tt.want) } }) } } 运行下面的命令进行测试
go test -v .
测试结果 === RUN TestFibonacci === RUN TestFibonacci/1 === RUN TestFibonacci/1#01 === RUN TestFibonacci/1#02 === RUN TestFibonacci/1#03 === RUN TestFibonacci/1#04 --- PASS: TestFibonacci (0.00s) --- PASS: TestFibonacci/1 (0.00s) --- PASS: TestFibonacci/1#01 (0.00s) --- PASS: TestFibonacci/1#02 (0.00s) --- PASS: TestFibonacci/1#03 (0.00s) --- PASS: TestFibonacci/1#04 (0.00s) PASS ok awesomeProject 0.005s 在打印的测试结果中，你可以看到 PASS 标记，说明单元测试通过，而且还可以看到我在单元测试中写的日志。
这就是一个完整的 Go 语言单元测试用例，它是在 Go 语言提供的测试框架下完成的。Go 语言测试框架可以让我们很容易地进行单元测试，但是需要遵循五点规则。
含有单元测试代码的 go 文件必须以 _test.go 结尾，Go 语言测试工具只认符合这个规则的文件。
单元测试文件名 _test.go 前面的部分最好是被测试的函数所在的 go 文件的文件名，比如以上示例中单元测试文件叫 main_test.go，因为测试的 Fibonacci 函数在 main.go 文件里。
单元测试的函数名必须以 Test 开头，是可导出的、公开的函数。
测试函数的签名必须接收一个指向 testing.T 类型的指针，并且不能返回任何值。
函数名最好是 Test + 要测试的函数名，比如例子中是 TestFibonacci，表示测试的是 Fibonacci 这个函数。
单元测试覆盖率 Go 语言提供了非常方便的命令来查看单元测试覆盖率。还是以 Fibonacci 函数的单元测试为例，通过一行命令即可查看它的单元测试覆盖率。
go test -v --coverprofile=.cover .
=== RUN TestFibonacci === RUN TestFibonacci/1 === RUN TestFibonacci/1#01 === RUN TestFibonacci/1#02 === RUN TestFibonacci/1#03 === RUN TestFibonacci/1#04 === RUN TestFibonacci/1#05 === RUN TestFibonacci/1#06 --- PASS: TestFibonacci (0.00s) --- PASS: TestFibonacci/1 (0.00s) --- PASS: TestFibonacci/1#01 (0.00s) --- PASS: TestFibonacci/1#02 (0.00s) --- PASS: TestFibonacci/1#03 (0.00s) --- PASS: TestFibonacci/1#04 (0.00s) --- PASS: TestFibonacci/1#05 (0.00s) --- PASS: TestFibonacci/1#06 (0.00s) PASS coverage: 85.7% of statements ok awesomeProject 0.005s coverage: 75.0% of statements 可以看到，测试覆盖率为 85.7%。从这个数字来看，Fibonacci 函数应该没有被全面地测试，这时候就需要查看详细的单元测试覆盖率报告了。
go tool cover -html=.cover -o=fib.html
执行命令后会在当前页面生成一个fib.html文件，用浏览器打开后如下图
红色标记的部分是没有测试到的，绿色标记的部分是已经测试到的。这就是单元测试覆盖率报告的好处，通过它你可以很容易地检测自己写的单元测试是否完全覆盖。
根据报告，我再修改一下单元测试，把没有覆盖的代码逻辑覆盖到，代码如下：
{&#34;1&#34;, args{-1}, 0}, 也就是说，由于图中 n&lt;0 的部分显示为红色，表示没有测试到，所以我们需要再添加一组测试用例，用于测试 n&lt;0 的情况。现在再运行这个单元测试，查看它的单元测试覆盖率，就会发现已经是 100% 了。
基准测试 什么是基准测试 基准测试（Benchmark）是一项用于测量和评估软件性能指标的方法，主要用于评估你写的代码的性能。
Go 语言的基准测试 Go 语言的基准测试和单元测试规则基本一样，只是测试函数的命名规则不一样。现在还以 Fibonacci 函数为例，演示 Go 语言基准测试的使用。
Fibonacci 函数的基准测试代码如下：
func BenchmarkFibonacci(b *testing.B){ for i:=0;i&lt;b.N;i++{ Fibonacci(10) } } 这是一个非常简单的 Go 语言基准测试示例，它和单元测试的不同点如下：
基准测试函数必须以 Benchmark 开头，必须是可导出的；
函数的签名必须接收一个指向 testing.B 类型的指针，并且不能返回任何值；
最后的 for 循环很重要，被测试的代码要放到循环里；
b.N 是基准测试框架提供的，表示循环的次数，因为需要反复调用测试的代码，才可以评估性能。
写好了基准测试，就可以通过如下命令来测试 Fibonacci 函数的性能
go test -bench=. .
运行结果 goos: darwin goarch: amd64 pkg: awesomeProject cpu: Intel(R) Core(TM) i5-8259U CPU @ 2.30GHz BenchmarkFibonacci-8 4666878 253.8 ns/op PASS ok awesomeProject 1.452s 运行基准测试也要使用 go test 命令，不过要加上 -bench 这个 Flag，它接受一个表达式作为参数，以匹配基准测试的函数，&quot;.&ldquo;表示运行所有基准测试。
下面着重解释输出的结果。看到函数后面的 -8 了吗？这个表示运行基准测试时对应的 GOMAXPROCS 的值。接着的 4666878 表示运行 for 循环的次数，也就是调用被测试代码的次数，最后的 253.8 ns/op 表示每次需要花费 253.8 纳秒。 基准测试的时间默认是 1 秒，也就是 1 秒调用 3461616 次、每次调用花费 343 纳秒。如果想让测试运行的时间更长，可以通过 -benchtime 指定，比如 3 秒，代码如下所示： go test -bench=. -benchtime=3s .
计时方法 进行基准测试之前会做一些准备，比如构建测试数据等，这些准备也需要消耗时间，所以需要把这部分时间排除在外。这就需要通过 ResetTimer 方法重置计时器，示例代码如下：
func BenchmarkFibonacci(b *testing.B) { n := 10 b.ResetTimer() //重置计时器 for i := 0; i &lt; b.N; i++ { Fibonacci(n) } } 这样可以避免因为准备数据耗时造成的干扰。
除了 ResetTimer 方法外，还有 StartTimer 和 StopTimer 方法，帮你灵活地控制什么时候开始计时、什么时候停止计时。
内存统计 在基准测试时，还可以统计每次操作分配内存的次数，以及每次操作分配的字节数，这两个指标可以作为优化代码的参考。要开启内存统计也比较简单，代码如下，即通过 ReportAllocs() 方法：
func BenchmarkFibonacci(b *testing.B) { n := 10 b.ReportAllocs() //开启内存统计 b.ResetTimer() //重置计时器 for i := 0; i &lt; b.N; i++ { Fibonacci(n) } } 运行结果 BenchmarkFibonacci-8 4726185 276.1 ns/op 0 B/op 0 allocs/op PASS ok awesomeProject 1.571s 可以看到相比原来的基准测试多了两个指标，分别是 0 B/op 和 0 allocs/op。前者表示每次操作分配了多少字节的内存，后者表示每次操作分配内存的次数。这两个指标可以作为代码优化的参考，尽可能地越小越好。
小提示：以上两个指标是否越小越好？这是不一定的，因为有时候代码实现需要空间换时间，所以要根据自己的具体业务而定，做到在满足业务的情况下越小越好。
并发基准测试 除了普通的基准测试外，Go 语言还支持并发基准测试，你可以测试在多个 goroutine 并发下代码的性能。还是以 Fibonacci 为例，它的并发基准测试代码如下：
func BenchmarkFibonacciRunParallel(b *testing.B) { n := 10 b.RunParallel(func(pb *testing.PB) { for pb.Next() { Fibonacci(n) } }) } 可以看到，Go 语言通过 RunParallel 方法运行并发基准测试。RunParallel 方法会创建多个 goroutine，并将 b.N 分配给这些 goroutine 执行
基准测试实战 还是以 Fibonacci 函数为例，通过前面小节的基准测试，会发现它并没有分配新的内存，也就是说 Fibonacci 函数慢并不是因为内存，排除掉这个原因，就可以归结为所写的算法问题了。
在递归运算中，一定会有重复计算，这是影响递归的主要因素。解决重复计算可以使用缓存，把已经计算好的结果保存起来，就可以重复使用了。
基于这个思路，将 Fibonacci 函数的代码进行如下修改：
var cache = map[int]int{} func Fibonacci(n int) int { if v, ok := cache[n]; ok { return v } result := 0 switch { case n &lt; 0: result = 0 case n == 0: result = 0 case n == 1: result = 1 default: result = Fibonacci(n-1) + Fibonacci(n-2) } cache[n] = result return result } 这组代码的核心在于采用一个 map 将已经计算好的结果缓存、便于重新使用。改造后，我再来运行基准测试，看看刚刚优化的效果，如下所示：
goos: darwin goarch: amd64 pkg: awesomeProject cpu: Intel(R) Core(TM) i5-8259U CPU @ 2.30GHz BenchmarkFibonacci-8 147522349 8.802 ns/op 0 B/op 0 allocs/op PASS ok awesomeProject 2.130s 可以看到，结果为 8.802 纳秒，相比优化前的 276 纳秒，性能足足提高了 31 倍。
总结 单元测试是保证代码质量的好方法，但单元测试也不是万能的，使用它可以降低 Bug 率，但也不要完全依赖。除了单元测试外，还可以辅以 Code Review、人工测试等手段更好地保证代码质量。
]]></content></entry><entry><title>Go语言中的Slice</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-29-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84slice/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[数组 几乎所有的编程语言里都存在数组，Go 也不例外。那么为什么 Go 语言除了数组之外又设计了 slice 呢？要想解答这个问题，先来了解数组的局限性。
在下面的示例中，a1、a2 是两个定义好的数组，但是它们的类型不一样。变量 a1 的类型是 [1]string，变量 a2 的类型是 [2]string，也就是说数组的大小属于数组类型的一部分，只有数组内部元素类型和大小一致时，这两个数组才是同一类型。
a1:=[1]string{&#34;golang&#34;} a2:=[2]string{&#34;golang&#34;} 可以总结为，一个数组由两部分构成：数组的大小和数组内的元素类型。
//数组结构伪代码表示 array{ len item type } 比如变量 a1 的大小是 1，内部元素的类型是 string，也就是说 a1 最多只能存储 1 个类型为 string 的元素。而 a2 的大小是 2，内部元素的类型也是 string，所以 a2 最多可以存储 2 个类型为 string 的元素。一旦一个数组被声明，它的大小和内部元素的类型就不能改变，你不能随意地向数组添加任意多个元素。这是数组的第一个限制。
既然数组的大小是固定的，如果需要使用数组存储大量的数据，就需要提前指定一个合适的大小，比如 10 万，代码如下所示：
a10:=[100000]string{&#34;golang&#34;} 这样虽然可以解决问题，但又带来了另外的问题，那就是内存占用。因为在 Go 语言中，函数间的传参是值传递的，数组作为参数在各个函数之间被传递的时候，同样的内容就会被一遍遍地复制，这就会造成大量的内存浪费，这是数组的第二个限制。
虽然数组有限制，但是它是 Go 非常重要的底层数据结构，比如 slice 切片的底层数据就存储在数组中。
slice 切片 数组虽然也不错，但是在操作上有不少限制，为了解决这些限制，Go 语言创造了 slice，也就是切片。切片是对数组的抽象和封装，它的底层是一个数组存储所有的元素，但是它可以动态地添加元素，容量不足时还可以自动扩容，你完全可以把切片理解为动态数组。在 Go 语言中，除了明确需要指定长度大小的类型需要数组来完成，大多数情况下都是使用切片的。
动态扩容 通过内置的 append 方法，你可以向一个切片中追加任意多个元素，所以这就可以解决数组的第一个限制。
func main() { ss:=[]string{&#34;golang&#34;,&#34;张三&#34;} ss=append(ss,&#34;李四&#34;,&#34;王五&#34;) fmt.Println(ss) } 运行结果 [golang 张三 李四 王五] 当通过 append 追加元素时，如果切片的容量不够，append 函数会自动扩容。比如上面的例子，打印出使用 append 前后的切片长度和容量，代码如下：
func main() { ss := []string{&#34;golang&#34;, &#34;张三&#34;} fmt.Println(&#34;切片ss长度为&#34;, len(ss), &#34;,容量为&#34;, cap(ss)) ss = append(ss, &#34;李四&#34;, &#34;王五&#34;) fmt.Println(&#34;切片ss长度为&#34;, len(ss), &#34;,容量为&#34;, cap(ss)) fmt.Println(ss) } 运行结果 切片ss长度为 2 ,容量为 2 切片ss长度为 4 ,容量为 4 [golang 张三 李四 王五] 在调用 append 之前，容量是 2，调用之后容量是 4，说明自动扩容了。
小提示：append 自动扩容的原理是新创建一个底层数组，把原来切片内的元素拷贝到新数组中，然后再返回一个指向新数组的切片。
数据结构 在 Go 语言中，切片其实是一个结构体，它的定义如下所示：
type SliceHeader struct { Data uintptr Len int Cap int } SliceHeader 是切片在运行时的表现形式，它有三个字段 Data、Len 和 Cap。
Data 用来指向存储切片元素的数组。
Len 代表切片的长度。
Cap 代表切片的容量。
通过这三个字段，就可以把一个数组抽象成一个切片，便于更好的操作，所以不同切片对应的底层 Data 指向的可能是同一个数组。现在通过一个示例来证明，代码如下：
func main() { a1 := [2]string{&#34;golang&#34;, &#34;张三&#34;} s1 := a1[0:1] s2 := a1[:] fmt.Println(s1, s2) //打印出s1和s2的Data值 ( Data是指向底层数组的 )，是一样的 fmt.Println((*reflect.SliceHeader)(unsafe.Pointer(&amp;s1)).Data) fmt.Println((*reflect.SliceHeader)(unsafe.Pointer(&amp;s2)).Data) } 运行结果 [golang] [golang 张三] 824634089504 824634089504 这两个切片共用一个数组，所以我们在切片赋值、重新进行切片操作时，使用的还是同一个数组，没有复制原来的元素。这样可以减少内存的占用，提高效率。
注意：多个切片共用一个底层数组虽然可以减少内存占用，但是如果有一个切片修改内部的元素，其他切片也会受影响。所以在切片作为参数在函数间传递的时候要小心，尽可能不要修改原切片内的元素。
func main() { a1 := [2]string{&#34;golang&#34;, &#34;张三&#34;} s1 := a1[0:1] s2 := a1[:] fmt.Println(s1, s2) s1[0] = &#34;java&#34; fmt.Println(s1, s2) } 运行结果 [golang] [golang 张三] [java] [java 张三] 通过运行结果我们发现 修改s1下标为0的元素时 s2下标为0的元素也被修改了。
切片的本质是 SliceHeader，又因为函数的参数是值传递，所以传递的是 SliceHeader 的副本，而不是底层数组的副本。这时候切片的优势就体现出来了，因为 SliceHeader 的副本内存占用非常少，即使是一个非常大的切片（底层数组有很多元素），也顶多占用 24 个字节的内存，这就解决了大数组在传参时内存浪费的问题。
小提示：SliceHeader 三个字段的类型分别是 uintptr、int 和 int，在 64 位的机器上，这三个字段最多也就是 int64 类型，一个 int64 占 8 个字节，三个 int64 占 24 个字节内存。
高效的原因 如果从集合类型的角度考虑，数组、切片和 map 都是集合类型，因为它们都可以存放元素，但是数组和切片的取值和赋值操作要更高效，因为它们是连续的内存操作，通过索引就可以快速地找到元素存储的地址。
小提示：当然 map 的价值也非常大，因为它的 Key 可以是很多类型，比如 int、int64、string 等，但是数组和切片的索引只能是整数。
进一步对比，在数组和切片中，切片又是高效的，因为它在赋值、函数传参的时候，并不会把所有的元素都复制一遍，而只是复制 SliceHeader 的三个字段就可以了，共用的还是同一个底层数组。
在下面的示例中，我定义了两个函数 arrayF 和 sliceF，分别打印传入的数组和切片底层对应的数组指针。
func main() { a1:=[2]string{&#34;golang&#34;,&#34;张三&#34;} fmt.Printf(&#34;函数main数组指针：%p\n&#34;,&amp;a1) arrayF(a1) s1:=a1[0:1] fmt.Println((*reflect.SliceHeader)(unsafe.Pointer(&amp;s1)).Data) sliceF(s1) } func arrayF(a [2]string){ fmt.Printf(&#34;函数arrayF数组指针：%p\n&#34;,&amp;a) } func sliceF(s []string){ fmt.Printf(&#34;函数sliceF Data：%d\n&#34;,(*reflect.SliceHeader)(unsafe.Pointer(&amp;s)).Data) } 运行结果 函数main数组指针：0xc00005a020 函数arrayF数组指针：0xc00005a040 824634089504 函数sliceF Data：824634089504 同一个数组在 main 函数中的指针和在 arrayF 函数中的指针是不一样的，这说明数组在传参的时候被复制了，又产生了一个新数组。而 slice 切片的底层 Data 是一样的，这说明不管是在 main 函数还是 sliceF 函数中，这两个切片共用的还是同一个底层数组，底层数组并没有被复制。
小提示：切片的高效还体现在 for range 循环中，因为循环得到的临时变量也是个值拷贝，所以在遍历大的数组时，切片的效率更高。
切片基于指针的封装是它效率高的根本原因，因为可以减少内存的占用，以及减少内存复制时的时间消耗。
string 和 []byte 互转 把一个 []byte 转为一个 string 字符串，然后再转换回来，示例代码如下：
s:=&#34;golang&#34; b:=[]byte(s) s3:=string(b) fmt.Println(s,string(b),s3) 运行结果 golang golang golang Go 语言通过先分配一个内存再复制内容的方式，实现 string 和 []byte 之间的强制转换。现在我通过 string 和 []byte 指向的真实内容的内存地址，来验证强制转换是采用重新分配内存的方式。如下面的代码所示：
s:=&#34;golang&#34; fmt.Printf(&#34;s的内存地址：%d\n&#34;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s)).Data) b:=[]byte(s) fmt.Printf(&#34;b的内存地址：%d\n&#34;,(*reflect.SliceHeader)(unsafe.Pointer(&amp;b)).Data) s3:=string(b) fmt.Printf(&#34;s3的内存地址：%d\n&#34;, (*reflect.StringHeader)(unsafe.Pointer(&amp;s3)).Data) 运行结果 s的内存地址：17444283 b的内存地址：824634330856 s3的内存地址：824634330824 通过以上的示例代码，你已经知道了 SliceHeader 是什么。其实 StringHeader 和 SliceHeader 一样，代表的是字符串在程序运行时的真实结构，StringHeader 的定义如下所示：
// StringHeader is the runtime representation of a string. type StringHeader struct { Data uintptr Len int } 也就是说，在程序运行的时候，字符串和切片本质上就是 StringHeader 和 SliceHeader。这两个结构体都有一个 Data 字段，用于存放指向真实内容的指针。所以我们打印出 Data 这个字段的值，就可以判断 string 和 []byte 强制转换后是不是重新分配了内存。
现在你已经知道了 []byte(s) 和 string(b) 这种强制转换会重新拷贝一份字符串，如果字符串非常大，由于内存开销大，对于有高性能要求的程序来说，这种方式就无法满足了，需要进行性能优化。
如何优化呢？既然是因为内存分配导致内存开销大，那么优化的思路应该是在不重新申请内存的情况下实现类型转换。
仔细观察 StringHeader 和 SliceHeader 这两个结构体，会发现它们的前两个字段一模一样，那么 []byte 转 string，就等于通过 unsafe.Pointer 把 *SliceHeader 转为 *StringHeader，也就是 *[]byte 转 *string，原理和我上面讲的把切片转换成一个自定义的 slice 结构体类似。
在下面的示例中，s4 和 s3 的内容是一样的。不一样的是 s4 没有申请新内存（零拷贝），它和变量 b 使用的是同一块内存，因为它们的底层 Data 字段值相同，这样就节约了内存，也达到了 []byte 转 string 的目的。
s:=&#34;golang&#34; b:=[]byte(s) s4:=*(*string)(unsafe.Pointer(&amp;b)) SliceHeader 有 Data、Len、Cap 三个字段，StringHeader 有 Data、Len 两个字段，所以 *SliceHeader 通过 unsafe.Pointer 转为 *StringHeader 的时候没有问题，因为 *SliceHeader 可以提供 *StringHeader 所需的 Data 和 Len 字段的值。但是反过来却不行了，因为 *StringHeader 缺少 *SliceHeader 所需的 Cap 字段，需要我们自己补上一个默认值。
在下面的示例中，b1 和 b 的内容是一样的，不一样的是 b1 没有申请新内存，而是和变量 s 使用同一块内存，因为它们底层的 Data 字段相同，所以也节约了内存。
s:=&#34;golang&#34; sh:=(*reflect.SliceHeader)(unsafe.Pointer(&amp;s)) sh.Cap = sh.Len b1:=*(*[]byte)(unsafe.Pointer(sh)) 注意：通过 unsafe.Pointer 把 string 转为 []byte 后，不能对 []byte 修改，比如不可以进行 b1[0]=12 这种操作，会报异常，导致程序崩溃。这是因为在 Go 语言中 string 内存是只读的。
通过 unsafe.Pointer 进行类型转换，避免内存拷贝提升性能的方法在 Go 语言标准库中也有使用，比如 strings.Builder 这个结构体，它内部有 buf 字段存储内容，在通过 String 方法把 []byte 类型的 buf 转为 string 的时候，就使用 unsafe.Pointer 提高了效率，代码如下：
// String returns the accumulated string. func (b *Builder) String() string { return *(*string)(unsafe.Pointer(&amp;b.buf)) } string 和 []byte 的互转就是一个很好的利用 SliceHeader 结构体的示例，通过它可以实现零拷贝的类型转换，提升了效率，避免了内存浪费。
小实例分析 package main import &#34;fmt&#34; func append2(s []string) { if len(s) &gt; 0 { s[0] = &#34;666&#34; } s = append(s, &#34;4&#34;) fmt.Printf(&#34;2:地址：%p 值： %v len:%d cap:%d\n&#34;, s, s, len(s), cap(s)) } func main() { s := []string{&#34;2&#34;, &#34;3&#34;} fmt.Printf(&#34;1:地址：%p 值： %v len:%d cap:%d\n&#34;, s, s, len(s), cap(s)) append2(s) fmt.Printf(&#34;3:地址：%p 值： %v len:%d cap:%d\n&#34;, s, s, len(s), cap(s)) } //运行结果 1:地址：0xc0000b6000 值： [2 3] len:2 cap:2 2:地址：0xc0000aa040 值： [666 3 4] len:3 cap:4 3:地址：0xc0000b6000 值： [666 3] len:2 cap:2 解析： 第一行输出是s刚初始化此时值为 2和3 且长度为2 容量也为2 第二行输出是在append2函数中修改了index为0为666且追加4后的结果,此时追加了666导致切片扩容，所以其地址发省了变化 那么如果我们初始化时就给他足够的长度呢？
package main import &#34;fmt&#34; func append2(s []string) { if len(s) &gt; 0 { s[0] = &#34;666&#34; } s = append(s, &#34;5&#34;) fmt.Printf(&#34;2:地址：%p 值： %v len:%d cap:%d\n&#34;, s, s, len(s), cap(s)) } func main() { s := []string{&#34;2&#34;, &#34;3&#34;} s = append(s, &#34;4&#34;) fmt.Printf(&#34;1:地址：%p 值： %v len:%d cap:%d\n&#34;, s, s, len(s), cap(s)) append2(s) fmt.Printf(&#34;3:地址：%p 值： %v len:%d cap:%d\n&#34;, s, s, len(s), cap(s)) } //运行结果 1:地址：0xc000026080 值： [2 3 4] len:3 cap:4 2:地址：0xc000026080 值： [666 3 4 5] len:4 cap:4 3:地址：0xc000026080 值： [666 3 4] len:3 cap:4 此时我们在调用append2函数前 切片的容量就够追加一个元素进去，但是在main函数中的s还是没有追加的&quot;5&quot;,但是index为0的2却改为了666，而且其len仍然是3
所以可以发现slice在传递时不是完全的引用传递,应该是只传递了指向数组的指针过去，所以在append2中改成了底层数组的元素，但是并没有改变切片本身的len。
总结 通过 slice 切片的分析，可以更深地感受 Go 的魅力，它把底层的指针、数组等进行封装，提供一个切片的概念给开发者，这样既可以方便使用、提高开发效率，又可以提高程序的性能。
Go 语言设计切片的思路非常有借鉴意义，也可以使用 uintptr 或者 slice 类型的字段来提升性能，就像 Go 语言 SliceHeader 里的 Data uintptr 字段一样。
]]></content></entry><entry><title>Go语言又爱又恨的unsafe</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-28-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%8F%88%E7%88%B1%E5%8F%88%E6%81%A8%E7%9A%84unsafe/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[顾名思义，unsafe 是不安全的。Go 将其定义为这个包名，也是为了让我们尽可能地不使用它。不过虽然不安全，它也有优势，那就是可以绕过 Go 的内存安全机制，直接对内存进行读写。所以有时候出于性能需要，还是会冒险使用它来对内存进行操作。
指针类型转换 Go 的设计者为了编写方便、提高效率且降低复杂度，将其设计成一门强类型的静态语言。强类型意味着一旦定义了，类型就不能改变；静态意味着类型检查在运行前就做了。同时出于安全考虑，Go 语言是不允许两个指针类型进行转换的。
我们一般使用 *T 作为一个指针类型，表示一个指向类型 T 变量的指针。为了安全的考虑，两个不同的指针类型不能相互转换，比如 *int 不能转为 *float64。
我们来看下面的代码：
func main() { i:= 10 ip:=&amp;i var fp *float64 = (*float64)(ip) fmt.Println(fp) } 运行结果 cannot convert ip (type * int) to type * float64 这个代码在编译的时候，会提示 cannot convert ip (type * int) to type * float64，也就是不能进行强制转型。那如果还是需要转换呢？这就需要使用 unsafe 包里的 Pointer 了。下面先学习 unsafe.Pointer 是什么，再学习如何转换。
unsafe.Pointer unsafe.Pointer 是一种特殊意义的指针，可以表示任意类型的地址，类似 C 语言里的 void* 指针，是全能型的。
正常情况下，*int 无法转换为 *float64，但是通过 unsafe.Pointer 做中转就可以了。在下面的示例中，我通过 unsafe.Pointer 把 *int 转换为 *float64，并且对新的 *float64 进行 3 倍的乘法操作，你会发现原来变量 i 的值也被改变了，变为 30。
func main() { i:= 10 ip:=&amp;i var fp *float64 = (*float64)(unsafe.Pointer(ip)) *fp = *fp * 3 fmt.Println(i) } 运行结果 30 这个例子没有任何实际意义，但是说明了通过 unsafe.Pointer 这个万能的指针，我们可以在 *T 之间做任何转换。那么 unsafe.Pointer 到底是什么？为什么其他类型的指针可以转换为 unsafe.Pointer 呢？这就要看 unsafe.Pointer 的源代码定义了，如下所示：
// ArbitraryType is here for the purposes of documentation // only and is not actually part of the unsafe package. // It represents the type of an arbitrary Go expression. type ArbitraryType int type Pointer *ArbitraryType 按 Go 语言官方的注释，ArbitraryType 可以表示任何类型（这里的 ArbitraryType 仅仅是文档需要，不用太关注它本身，只要记住可以表示任何类型即可）。 而 unsafe.Pointer 又是 *ArbitraryType，也就是说 unsafe.Pointer 是任何类型的指针，也就是一个通用型的指针，足以表示任何内存地址。
uintptr 指针类型 uintptr 也是一种指针类型，它足够大，可以表示任何指针。它的类型定义如下所示：
// uintptr is an integer type that is large enough // to hold the bit pattern of any pointer. type uintptr uintptr 既然已经有了 unsafe.Pointer，为什么还要设计 uintptr 类型呢？这是因为 unsafe.Pointer 不能进行运算，比如不支持 +（加号）运算符操作，但是 uintptr 可以。通过它，可以对指针偏移进行计算，这样就可以访问特定的内存，达到对特定内存读写的目的，这是真正内存级别的操作。
在下面的代码中，通过指针偏移修改 struct 结构体内的字段为例，演示 uintptr 的用法。
func main() { p :=new(person) //Name是person的第一个字段不用偏移，即可通过指针修改 pName:=(*string)(unsafe.Pointer(p)) *pName=&#34;张三&#34; //Age并不是person的第一个字段，所以需要进行偏移，这样才能正确定位到Age字段这块内存，才可以正确的修改 pAge:=(*int)(unsafe.Pointer(uintptr(unsafe.Pointer(p))+unsafe.Offsetof(p.Age))) *pAge = 20 fmt.Println(*p) } type person struct { Name string Age int } 运行结果 {张三 20} 这个示例不是通过直接访问相应字段的方式对 person 结构体字段赋值，而是通过指针偏移找到相应的内存，然后对内存操作进行赋值。
先使用 new 函数声明一个 *person 类型的指针变量 p。
然后把 *person 类型的指针变量 p 通过 unsafe.Pointer，转换为 *string 类型的指针变量 pName。
因为 person 这个结构体的第一个字段就是 string 类型的 Name，所以 pName 这个指针就指向 Name 字段（偏移为 0），对 pName 进行修改其实就是修改字段 Name 的值。
因为 Age 字段不是 person 的第一个字段，要修改它必须要进行指针偏移运算。所以需要先把指针变量 p 通过 unsafe.Pointer 转换为 uintptr，这样才能进行地址运算。既然要进行指针偏移，那么要偏移多少呢？这个偏移量可以通过函数 unsafe.Offsetof 计算出来，该函数返回的是一个 uintptr 类型的偏移量，有了这个偏移量就可以通过 + 号运算符获得正确的 Age 字段的内存地址了，也就是通过 unsafe.Pointer 转换后的 *int 类型的指针变量 pAge。
然后需要注意的是，如果要进行指针运算，要先通过 unsafe.Pointer 转换为 uintptr 类型的指针。指针运算完毕后，还要通过 unsafe.Pointer 转换为真实的指针类型（比如示例中的 *int 类型），这样可以对这块内存进行赋值或取值操作。
有了指向字段 Age 的指针变量 pAge，就可以对其进行赋值操作，修改字段 Age 的值了。
指针运算的核心在于它操作的是一个个内存地址，通过内存地址的增减，就可以指向一块块不同的内存并对其进行操作，而且不必知道这块内存被起了什么名字（变量名）。
指针转换规则 你已经知道 Go 语言中存在三种类型的指针，它们分别是：常用的 *T、unsafe.Pointer 及 uintptr。通过以上示例，可以总结出这三者的转换规则：
任何类型的 *T 都可以转换为 unsafe.Pointer；
unsafe.Pointer 也可以转换为任何类型的 *T；
unsafe.Pointer 可以转换为 uintptr；
uintptr 也可以转换为 unsafe.Pointer。
可以发现，unsafe.Pointer 主要用于指针类型的转换，而且是各个指针类型转换的桥梁。uintptr 主要用于指针运算，尤其是通过偏移量定位不同的内存。
unsafe.Sizeof Sizeof 函数可以返回一个类型所占用的内存大小，这个大小只与类型有关，和类型对应的变量存储的内容大小无关，比如 bool 型占用一个字节、int8 也占用一个字节。
func main() { fmt.Println(unsafe.Sizeof(true)) fmt.Println(unsafe.Sizeof(int8(0))) fmt.Println(unsafe.Sizeof(int16(10))) fmt.Println(unsafe.Sizeof(int32(10000000))) fmt.Println(unsafe.Sizeof(int64(10000000000000))) fmt.Println(unsafe.Sizeof(float64(10000000000000))) fmt.Println(unsafe.Sizeof(int(10000000000000000))) fmt.Println(unsafe.Sizeof(string(&#34;qwert&#34;))) fmt.Println(unsafe.Sizeof([]string{&#34;qwertyu&#34;, &#34;张三&#34;, &#34;56455849584&#34;})) fmt.Println(unsafe.Sizeof(person{ Name: &#34;222&#34;, Age: 0, Age2: 0, })) } type person struct { Name string Age int Age2 float64 } 运行结果 1 1 2 4 8 8 8 16 24 32 小提示：一个 struct 结构体的内存占用大小，等于它包含的字段类型内存占用大小之和。
总结 unsafe 包里最常用的就是 Pointer 指针，通过它可以让你在 *T、uintptr 及 Pointer 三者间转换，从而实现自己的需求，比如零内存拷贝或通过 uintptr 进行指针运算，这些都可以提高程序效率。
unsafe 包里的功能虽然不安全，但的确很香，比如指针运算、类型转换等，都可以帮助我们提高性能。不过我还是建议尽可能地不使用，因为它可以绕开 Go 语言编译器的检查，可能会因为你的操作失误而出现问题。当然如果是需要提高性能的必要操作，还是可以使用，比如 []byte 转 string，就可以通过 unsafe.Pointer 实现零内存拷贝
//零内存拷贝实现[]byte转string func main() { str := &#34;abc&#34; bys := []byte(str) fmt.Println(bys) // [97 98 99] str2 := (*string)(unsafe.Pointer(&amp;bys)) bys[0] = 98 fmt.Println(*str2) // bbc } ]]></content></entry><entry><title>Go语言字符串和结构体之间转换</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-27-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E7%BB%93%E6%9E%84%E4%BD%93%E4%B9%8B%E9%97%B4%E8%BD%AC%E6%8D%A2/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[在web应用调用 API 的时候，需要把 API 返回的 JSON 字符串转换为 struct 结构体，便于操作。那么一个 JSON 字符串是如何转换为 struct 结构体的呢？这就需要用到反射的知识，今天学习基于字符串和结构体之间的转换，一步步地揭开 Go 语言运行时反射的面纱。
反射是什么？ 和 Java 语言一样，Go 语言也有运行时反射，这为我们提供了一种可以在运行时操作任意类型对象的能力。比如查看一个接口变量的具体类型、看看一个结构体有多少字段、修改某个字段的值等。
Go 语言是静态编译类语言，比如在定义一个变量的时候，已经知道了它是什么类型，那么为什么还需要反射呢？这是因为有些事情只有在运行时才知道。比如你定义了一个函数，它有一个interface{}类型的参数，这也就意味着调用者可以传递任何类型的参数给这个函数。在这种情况下，如果你想知道调用传递的是什么类型的参数，就需要用到反射。如果你想知道一个结构体有哪些字段和方法，也需要反射。 以常用的函数 fmt.Println 为例，如下所示：
//src/fmt/print.go func Println(a ...interface{}) (n int, err error) { return Fprintln(os.Stdout, a...) } fmt.Println 的源代码有一个可变参数，类型为 interface{}，这意味着你可以传递零个或者多个任意类型参数给它，都能被正确打印。
reflect.Value 和 reflect.Type 在 Go 语言的反射定义中，任何接口都由两部分组成：接口的具体类型，以及具体类型对应的值。比如 var i int = 3，因为 interface{} 可以表示任何类型，所以变量 i 可以转为 interface{}。你可以把变量 i 当成一个接口，那么这个变量在 Go 反射中的表示就是 &lt;Value,Type&gt;。其中 Value 为变量的值，即 3，而 Type 为变量的类型，即 int。
小提示：interface{} 是空接口，可以表示任何类型，也就是说你可以把任何类型转换为空接口，它通常用于反射、类型断言，以减少重复代码，简化编程。
在 Go 反射中，标准库为我们提供了两种类型 reflect.Value 和 reflect.Type 来分别表示变量的值和类型，并且提供了两个函数 reflect.ValueOf 和 reflect.TypeOf 分别获取任意对象的 reflect.Value 和 reflect.Type。
func main() { i := 3 iv := reflect.ValueOf(i) it := reflect.TypeOf(i) fmt.Println(&#34;value : &#34;, iv) fmt.Println(&#34;type : &#34;, it) } 运行结果 value : 3 type : int 代码定义了一个 int 类型的变量 i，它的值为 3，然后通过 reflect.ValueOf 和 reflect.TypeOf 函数就可以获得变量 i 对应的 reflect.Value 和 reflect.Type。通过 fmt.Println 函数打印后，可以看到结果，这也可以证明 reflect.Value 表示的是变量的值，reflect.Type 表示的是变量的类型。
reflect.Value 在 Go 语言中，reflect.Value 被定义为一个 struct 结构体，它的定义如下面的代码所示：
// src/reflect/value.go type Value struct { typ *rtype ptr unsafe.Pointer flag } reflect.Value 结构体的字段都是私有的，也就是说，我们只能使用 reflect.Value 的方法。现在看看它有哪些常用方法，如下所示：
//针对具体类型的系列方法 //以下是用于获取对应的值 Bool Bytes Complex Float Int String Uint CanSet //是否可以修改对应的值 以下是用于修改对应的值 Set SetBool SetBytes SetComplex SetFloat SetInt SetString Elem //获取指针指向的值，一般用于修改对应的值 //以下Field系列方法用于获取struct类型中的字段 Field FieldByIndex FieldByName FieldByNameFunc Interface //获取对应的原始类型 IsNil //值是否为nil IsZero //值是否是零值 Kind //获取对应的类型类别，比如Array、Slice、Map等 //获取对应的方法 Method MethodByName NumField //获取struct类型中字段的数量 NumMethod//类型上方法集的数量 Type//获取对应的reflect.Type 看着比较多，其实就三类：
一类用于获取和修改对应的值； 一类和 struct 类型的字段有关，用于获取对应的字段； 一类和类型上的方法集有关，用于获取对应的方法。 获取原始类型 func main() { i:=3 iv:=reflect.ValueOf(i) i1:=iv.Interface().(int) fmt.Println(i1) } 运行结果 3 修改对应的值 func main() { i:=3 ipv:=reflect.ValueOf(&amp;i) ipv.Elem().SetInt(4) fmt.Println(i) } 运行结果 4 这样就通过反射修改了一个变量。因为 reflect.ValueOf 函数返回的是一份值的拷贝，所以我们要传入变量的指针才可以。 因为传递的是一个指针，所以需要调用 Elem 方法找到这个指针指向的值，这样才能修改。 最后我们就可以使用 SetInt 方法修改值了。
要修改一个变量的值，有几个关键点：传递指针（可寻址），通过 Elem 方法获取指向的值，才可以保证值可以被修改，reflect.Value 为我们提供了 CanSet 方法判断是否可以修改该变量。
那么如何修改 struct 结构体字段的值呢？参考变量的修改方式，可总结出以下步骤：
传递一个 struct 结构体的指针，获取对应的 reflect.Value；
通过 Elem 方法获取指针指向的值；
通过 Field 方法获取要修改的字段；
通过 Set 系列方法修改成对应的值。
func main() { p := person{Name: &#34;张三&#34;, Age: 20} ppv := reflect.ValueOf(&amp;p) ppv.Elem().Field(0).SetString(&#34;李四&#34;) fmt.Println(p) ppv.Elem().FieldByName(&#34;Name&#34;).SetString(&#34;王五&#34;) fmt.Println(p) } type person struct { Name string Age int } 运行结果 {李四 20} {王五 20} 最后再来总结一下通过反射修改一个值的规则。
可被寻址，通俗地讲就是要向 reflect.ValueOf 函数传递一个指针作为参数。
如果要修改 struct 结构体字段值的话，该字段需要是可导出的，而不是私有的，也就是该字段的首字母为大写。
记得使用 Elem 方法获得指针指向的值，这样才能调用 Set 系列方法进行修改。
记住以上规则，你就可以在程序运行时通过反射修改一个变量或字段的值。
获取对应的底层类型 底层类型是什么意思呢？其实对应的主要是基础类型，比如接口、结构体、指针&hellip;&hellip;因为我们可以通过 type 关键字声明很多新的类型。比如在上面的例子中，变量 p 的实际类型是 person，但是 person 对应的底层类型是 struct 这个结构体类型，而 &amp;p 对应的则是指针类型。我们来通过下面的代码进行验证：
func main() { p:=person{Name: &#34;张三&#34;,Age: 20} ppv:=reflect.ValueOf(&amp;p) fmt.Println(ppv.Kind()) pv:=reflect.ValueOf(p) fmt.Println(pv.Kind()) } 运行结果 ptr struct Kind 方法返回一个 Kind 类型的值，它是一个常量，有以下可供使用的值：
// src/reflect/type.go type Kind uint const ( Invalid Kind = iota Bool Int Int8 Int16 Int32 Int64 Uint Uint8 Uint16 Uint32 Uint64 Uintptr Float32 Float64 Complex64 Complex128 Array Chan Func Interface Map Ptr Slice String Struct UnsafePointer ) 从以上源代码定义的 Kind 常量列表可以看到，已经包含了 Go 语言的所有底层类型。
reflect.Type reflect.Value 可以用于与值有关的操作中，而如果是和变量类型本身有关的操作，则最好使用 reflect.Type，比如要获取结构体对应的字段名称或方法。
要反射获取一个变量的 reflect.Type，可以通过函数 reflect.TypeOf。
接口定义 和 reflect.Value 不同，reflect.Type 是一个接口，而不是一个结构体，所以也只能使用它的方法。
以下是我列出来的 reflect.Type 接口常用的方法。从这个列表来看，大部分都和 reflect.Value 的方法功能相同。
type Type interface { Implements(u Type) bool AssignableTo(u Type) bool ConvertibleTo(u Type) bool Comparable() bool //以下这些方法和Value结构体的功能相同 Kind() Kind Method(int) Method MethodByName(string) (Method, bool) NumMethod() int Elem() Type Field(i int) StructField FieldByIndex(index []int) StructField FieldByName(name string) (StructField, bool) FieldByNameFunc(match func(string) bool) (StructField, bool) NumField() int } 其中几个特有的方法如下：
Implements 方法用于判断是否实现了接口 u；
AssignableTo 方法用于判断是否可以赋值给类型 u，其实就是是否可以使用 =，即赋值运算符；
ConvertibleTo 方法用于判断是否可以转换成类型 u，其实就是是否可以进行类型转换；
Comparable 方法用于判断该类型是否是可比较的，其实就是是否可以使用关系运算符进行比较。
遍历结构体的字段和方法 先给person类型添加一个String方法
func (p person) String() string{ return fmt.Sprintf(&#34;Name is %s,Age is %d&#34;,p.Name,p.Age) } 新增一个 String 方法，返回对应的字符串信息，这样 person 这个 struct 结构体也实现了 fmt.Stringer 接口。 可以通过 NumField 方法获取结构体字段的数量，然后使用 for 循环，通过 Field 方法就可以遍历结构体的字段，并打印出字段名称。同理，遍历结构体的方法也是同样的思路，代码也类似，如下所示：
func main() { p:=person{Name: &#34;张三&#34;,Age: 20} pt:=reflect.TypeOf(p) //遍历person的字段 for i:=0;i&lt;pt.NumField();i++{ fmt.Println(&#34;字段：&#34;,pt.Field(i).Name) } //遍历person的方法 for i:=0;i&lt;pt.NumMethod();i++{ fmt.Println(&#34;方法：&#34;,pt.Method(i).Name) } } 运行结果 字段： Name 字段： Age 方法： String 小技巧：你可以通过 FieldByName 方法获取指定的字段，也可以通过 MethodByName 方法获取指定的方法，这在需要获取某个特定的字段或者方法时非常高效，而不是使用遍历。
是否实现某接口 通过 reflect.Type 还可以判断是否实现了某接口。我还是以 person 结构体为例，判断它是否实现了接口 fmt.Stringer 和 io.Writer，如下面的代码所示：
func main() { p:=person{Name: &#34;张三&#34;,Age: 20} pt:=reflect.TypeOf(p) stringerType:=reflect.TypeOf((*fmt.Stringer)(nil)).Elem() writerType:=reflect.TypeOf((*io.Writer)(nil)).Elem() fmt.Println(&#34;是否实现了fmt.Stringer：&#34;,pt.Implements(stringerType)) fmt.Println(&#34;是否实现了io.Writer：&#34;,pt.Implements(writerType)) } 运行结果 是否实现了fmt.Stringer： true 是否实现了io.Writer： false 小提示：尽可能通过类型断言的方式判断是否实现了某接口，而不是通过反射。
字符串和结构体互转 Go 语言的标准库有一个 json 包，通过它可以把 JSON 字符串转为一个 struct 结构体，也可以把一个 struct 结构体转为一个 json 字符串。如下面的代码所示：
func main() { p := person{Name: &#34;张三&#34;, Age: 20} //struct to json jsonB, err := json.Marshal(p) if err == nil { fmt.Println(string(jsonB)) } //json to struct respJSON := &#34;{\&#34;Name\&#34;:\&#34;李四\&#34;,\&#34;Age\&#34;:40}&#34; json.Unmarshal([]byte(respJSON), &amp;p) fmt.Println(p) } 运行结果 {&#34;Name&#34;:&#34;张三&#34;,&#34;Age&#34;:20} Name is 李四,Age is 40 仔细观察以上打印出的 JSON 字符串，发现 JSON 字符串的 Key 和 struct 结构体的字段名称一样，比如示例中的 Name 和 Age。那么是否可以改变它们呢？比如改成小写的 name 和 age，并且字段的名称还是大写的 Name 和 Age。当然可以，要达到这个目的就需要用到 struct tag 的功能了。
//修改结构体的定义 type person struct { Name string `json:&#34;name&#34;` Age int `json:&#34;age&#34;` } 修改后上面的代码
func main() { p := person{Name: &#34;张三&#34;, Age: 20} //struct to json jsonB, err := json.Marshal(p) if err == nil { fmt.Println(string(jsonB)) } //json to struct respJSON := &#34;{\&#34;name\&#34;:\&#34;李四\&#34;,\&#34;Age\&#34;:40}&#34; json.Unmarshal([]byte(respJSON), &amp;p) fmt.Println(p) } 运行结果 {&#34;name&#34;:&#34;张三&#34;,&#34;age&#34;:20} Name is 李四,Age is 40 可以发现输入json已经变成了小写，而且在json转结构体时,字段名和tag都是可以用的.
struct tag 是整个 JSON 和 struct 互转的关键，这个 tag 就像是我们为 struct 字段起的别名，那么 json 包是如何获得这个 tag 的呢？这就需要反射了。我们来看下面的代码：
for i:=0;i&lt;pt.NumField();i++{ sf:=pt.Field(i) fmt.Printf(&#34;字段%s上,json tag为%s\n&#34;,sf.Name,sf.Tag.Get(&#34;json&#34;)) } 要想获得字段上的 tag，就要先反射获得对应的字段，我们可以通过 Field 方法做到。该方法返回一个 StructField 结构体，它有一个字段是 Tag，存有字段的所有 tag。示例中要获得 Key 为 json 的 tag，所以只需要调用 sf.Tag.Get(&ldquo;json&rdquo;) 即可。
结构体的字段可以有多个 tag，用于不同的场景，比如 json 转换、bson 转换、orm 解析等。如果有多个 tag，要使用空格分隔。采用不同的 Key 可以获得不同的 tag，如下面的代码所示：
type person struct { Name string `json:&#34;name&#34; bson:&#34;b_name&#34;` Age int `json:&#34;age&#34; bson:&#34;b_name&#34;` } func (p person) String() string { return fmt.Sprintf(&#34;Name is %s,Age is %d&#34;, p.Name, p.Age) } func main() { p := person{Name: &#34;张三&#34;, Age: 20} //struct to json pt := reflect.TypeOf(p) //遍历person字段中key为json、bson的tag for i := 0; i &lt; pt.NumField(); i++ { sf := pt.Field(i) fmt.Printf(&#34;字段%s上,json tag为%s\n&#34;, sf.Name, sf.Tag.Get(&#34;json&#34;)) fmt.Printf(&#34;字段%s上,bson tag为%s\n&#34;, sf.Name, sf.Tag.Get(&#34;bson&#34;)) } } 运行结果 字段Name上,json tag为name 字段Name上,bson tag为b_name 字段Age上,json tag为age 字段Age上,bson tag为b_name 实现 Struct 转 JSON func main() { p:=person{Name: &#34;张三&#34;,Age: 20} pv:=reflect.ValueOf(p) pt:=reflect.TypeOf(p) //自己实现的struct to json jsonBuilder:=strings.Builder{} jsonBuilder.WriteString(&#34;{&#34;) num:=pt.NumField() for i:=0;i&lt;num;i++{ jsonTag:=pt.Field(i).Tag.Get(&#34;json&#34;) //获取json tag jsonBuilder.WriteString(&#34;\&#34;&#34;+jsonTag+&#34;\&#34;&#34;) jsonBuilder.WriteString(&#34;:&#34;) //获取字段的值 jsonBuilder.WriteString(fmt.Sprintf(&#34;\&#34;%v\&#34;&#34;,pv.Field(i))) if i&lt;num-1{ jsonBuilder.WriteString(&#34;,&#34;) } } jsonBuilder.WriteString(&#34;}&#34;) fmt.Println(jsonBuilder.String())//打印json字符串 } json 字符串的转换只是 struct tag 的一个应用场景，你完全可以把 struct tag 当成结构体中字段的元数据配置，使用它来做想做的任何事情，比如 orm 映射、xml 转换、生成 swagger 文档等。
反射定律 反射是计算机语言中程序检视其自身结构的一种方法，它属于元编程的一种形式。反射灵活、强大，但也存在不安全。它可以绕过编译器的很多静态检查，如果过多使用便会造成混乱。为了帮助开发者更好地理解反射，Go 语言的作者在博客上总结了反射的三大定律。
任何接口值 interface{} 都可以反射出反射对象，也就是 reflect.Value 和 reflect.Type，通过函数 reflect.ValueOf 和 reflect.TypeOf 获得。
反射对象也可以还原为 interface{} 变量，也就是第 1 条定律的可逆性，通过 reflect.Value 结构体的 Interface 方法获得。
要修改反射的对象，该值必须可设置，也就是可寻址，参考修改变量的值的内容理解。
小提示：任何类型的变量都可以转换为空接口 intferface{}，所以第 1 条定律中函数 reflect.ValueOf 和 reflect.TypeOf 的参数就是 interface{}，表示可以把任何类型的变量转换为反射对象。在第 2 条定律中，reflect.Value 结构体的 Interface 方法返回的值也是 interface{}，表示可以把反射对象还原为对应的类型变量。
总结 在反射中，reflect.Value 对应的是变量的值，如果你需要进行和变量的值有关的操作，应该优先使用 reflect.Value，比如获取变量的值、修改变量的值等。reflect.Type 对应的是变量的类型，如果你需要进行和变量的类型本身有关的操作，应该优先使用 reflect.Type，比如获取结构体内的字段、类型拥有的方法集等。
反射虽然很强大，可以简化编程、减少重复代码，但是过度使用会让你的代码变得复杂混乱。所以除非非常必要，否则尽可能少地使用它们。
]]></content></entry><entry><title>Go语言中make和new的区别</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-26-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%B8%ADmake%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[程序的运行都需要内存，比如像变量的创建、函数的调用、数据的计算等。所以在需要内存的时候就要申请内存，进行内存分配。在 C/C++ 这类语言中，内存是由开发者自己管理的，需要主动申请和释放，而在 Go 语言中则是由该语言自己管理的，开发者不用做太多干涉，只需要声明变量，Go 语言就会根据变量的类型自动分配相应的内存。
Go 语言程序所管理的虚拟内存空间会被分为两部分：堆内存和栈内存。栈内存主要由 Go 语言来管理，开发者无法干涉太多，堆内存才是我们开发者发挥能力的舞台，因为程序的数据大部分分配在堆内存上，一个程序的大部分内存占用也是在堆内存上。
小提示：我们常说的 Go 语言的内存垃圾回收是针对堆内存的垃圾回收。
变量的声明、初始化就涉及内存的分配，比如声明变量会用到 var 关键字，如果要对变量初始化，就会用到 = 赋值运算符。除此之外还可以使用内置函数 new 和 make，这两个函数在前面的代码中已经见过，它们的功能非常相似，但可能还是比较迷惑，今天就基于内存分配，进而引出内置函数 new 和 make，学习他们的不同，以及使用场景。
变量 变量的声明 var s string //使用var关键字声明一个变量
该示例只是声明了一个变量 s，类型为 string，并没有对它进行初始化，所以它的值为 string 的零值，也就是 &ldquo;&quot;（空字符串）。
之前学到 string 其实是个值类型，现在我们来声明一个指针类型的变量试试，如下所示：
var sp *string
发现也是可以的，但是它同样没有被初始化，所以它的值是 *string 类型的零值，也就是 nil。
变量的赋值 变量可以通过 = 运算符赋值，也就是修改变量的值。如果在声明一个变量的时候就给这个变量赋值，这种操作就称为变量的初始化。如果要对一个变量初始化，可以有三种办法。
声明时直接初始化，比如 var s string = &ldquo;我的Blog&rdquo;。 声明后再进行初始化，比如 s=&ldquo;我的Blog&rdquo;（假设已经声明变量 s）。 使用 := 简单声明，比如 s:=&ldquo;我的Blog&rdquo;。 小提示：变量的初始化也是一种赋值，只不过它发生在变量声明的时候，时机最靠前。也就是说，当你获得这个变量时，它就已经被赋值了。
下面通过代码演示
func main() { var s string s = &#34;张三&#34; fmt.Println(s) } 运行结果： 张三 看下面的代码
func main() { var sp *string fmt.Println(sp) *sp = &#34;Golang&#34; fmt.Println(*sp) } 运行结果： &lt;nil&gt; panic: runtime error: invalid memory address or nil pointer dereference [signal SIGSEGV: segmentation violation code=0x1 addr=0x0 pc=0x108979a] 可以看到通过var直接声明一个指针 此时他的值是nil 而对于值类型来说，即使只声明一个变量，没有对其初始化，该变量也会有分配好的内存。 在下面的示例中，我声明了一个变量 s，并没有对其初始化，但是可以通过 &amp;s 获取它的内存地址。这其实是 Go 语言帮我们做的，可以直接使用。
func main() { var s string fmt.Printf(&#34;%p\n&#34;,&amp;s) } 运行结果 0xc00010c210 于是可以得到结论：如果要对一个变量赋值，这个变量必须有对应的分配好的内存，这样才可以对这块内存操作，完成赋值的目的。
小提示：其实不止赋值操作，对于指针变量，如果没有分配内存，取值操作一样会报 nil 异常，因为没有可以操作的内存。
所以一个变量必须要经过声明、内存分配才能赋值，才可以在声明的时候进行初始化。指针类型在声明的时候，Go 语言并没有自动分配内存，所以不能对其进行赋值操作，这和值类型不一样。
小提示：map 和 chan 也一样，因为它们本质上也是指针类型。
所以下面这段代码就会报错
func main() { var mp map[string]int mp[&#34;小米&#34;] = 16 } 运行结果 panic: assignment to entry in nil map new 函数 上面我们发现声明指针后是没有分配内存的，那么new函数就是用来分配内存的
func main() { var sp *string fmt.Println(sp) sp = new(string)//关键点 fmt.Println(sp) *sp = &#34;张三&#34; fmt.Println(*sp) } 运行结果 &lt;nil&gt; 0xc000010250 张三 通过结果我们发现 sp = new(string)执行后 指针sp就指向了0xc000010250 再给这块内存赋值就没问题了。
内置函数 new 的作用是什么呢？可以通过它的源代码定义分析，如下所示：
// The new built-in function allocates memory. The first argument is a type, // not a value, and the value returned is a pointer to a newly // allocated zero value of that type. func new(Type) *Type 它的作用就是根据传入的类型申请一块内存，然后返回指向这块内存的指针，指针指向的数据就是该类型的零值。
变量初始化 值类型初始化 不在多说了，看下演示代码即可
type person struct { name string age int } func main() { var s string = &#34;golang&#34; s1 := &#34;golang2&#34; p := person{name: &#34;张三&#34;, age: 18} } 指针变量初始化 在前面我们知道了 new 函数可以申请内存并返回一个指向该内存的指针，但是这块内存中数据的值默认是该类型的零值，在一些情况下并不满足业务需求。比如我想得到一个 *person 类型的指针，并且它的 name 是张三、age 是 20，但是 new 函数只有一个类型参数，并没有初始化值的参数，此时该怎么办呢？要达到这个目的可以自定义一个函数，对指针变量进行初始化，如下所示：
type person struct { name string age int } func NewPerson() *person{ p:=new(person) p.name = &#34;张三&#34; p.age = 20 return p } func main() { pp := NewPerson() fmt.Print(pp) } 运行结果 &amp;{张三 20} 也可以对NewPerson函数进行优化，让他可以接受参数
type person struct { name string age int } func NewPerson(name string, age int) *person { p := new(person) p.name = name p.age = age return p } func main() { pp := NewPerson(&#34;李四&#34;, 22) fmt.Print(pp) } 运行结果 &amp;{李四 22} make 函数 在使用 make 函数创建 map 的时候，其实调用的是 makemap 函数，如下所示：
// makemap implements Go map creation for make(map[k]v, hint). func makemap(t *maptype, hint int, h *hmap) *hmap{ //省略无关代码 } makemap 函数返回的是 *hmap 类型，而 hmap 是一个结构体，它的定义如下面的代码所示：
// A header for a Go map. type hmap struct { // Note: the format of the hmap is also encoded in cmd/compile/internal/gc/reflect.go. // Make sure this stays in sync with the compiler&#39;s definition. count int // # live cells == size of map. Must be first (used by len() builtin) flags uint8 B uint8 // log_2 of # of buckets (can hold up to loadFactor * 2^B items) noverflow uint16 // approximate number of overflow buckets; see incrnoverflow for details hash0 uint32 // hash seed buckets unsafe.Pointer // array of 2^B Buckets. may be nil if count==0. oldbuckets unsafe.Pointer // previous bucket array of half the size, non-nil only when growing nevacuate uintptr // progress counter for evacuation (buckets less than this have been evacuated) extra *mapextra // optional fields } 可以看到，我们平时使用的 map 关键字其实非常复杂，它包含 map 的大小 count、存储桶 buckets 等。要想使用这样的 hmap，不是简单地通过 new 函数返回一个 *hmap 就可以，还需要对其进行初始化，这就是 make 函数要做的事情，如下所示：
m:=make(map[string]int,10)
是不是发现 make 函数和上一小节中自定义的 NewPerson 函数很像？其实 make 函数就是 map 类型的工厂函数，它可以根据传递它的 K-V 键值对类型，创建不同类型的 map，同时可以初始化 map 的大小。
小提示：make 函数不只是 map 类型的工厂函数，还是 chan、slice 的工厂函数。它同时可以用于 slice、chan 和 map 这三种类型的初始化。
总结 new 函数只用于分配内存，并且把内存清零，也就是返回一个指向对应类型零值的指针。new 函数一般用于需要显式地返回指针的情况，不是太常用。
make 函数只用于 slice、chan 和 map 这三种内置类型的创建和初始化，因为这三种类型的结构比较复杂，比如 slice 要提前初始化好内部元素的类型，slice 的长度和容量等，这样才可以更好地使用它们。
]]></content></entry><entry><title>Go语言值,引用,指针之间的区别</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-25-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%80%BC%E5%BC%95%E7%94%A8%E6%8C%87%E9%92%88%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[前言 先看一段代码
type address struct { province string city string } func (addr address) String() string { return fmt.Sprintf(&#34;the addr is %s%s&#34;, addr.province, addr.city) } func main() { add := address{province: &#34;山东省&#34;, city: &#34;济南市&#34;} printString(add) printString(&amp;add) } func printString(s fmt.Stringer) { fmt.Println(s.String()) } 运行结果： the addr is 山东省济南市 the addr is 山东省济南市 这段代码中先声明了一个结构体address，结构体有两个string类型的元素组成，分别是省份和城市
然后为addres这个结构体实现了String方法 返回值类型为string 并且进行了格式化
在main函数中先创建一个addres对象并初始化了值 然后分别使用变量和他的指针作为参数调用了printString函数 这个函数的形参是fmt.Stringer 看一下这个fmt.Stringer的解释
Stringer 由任何具有 String 方法的值实现，该方法定义了该值的“native”格式。 String 方法用于将作为操作数传递的值打印到任何接受字符串的格式或未格式化的printer（例如 Print）
因为address实现了String方法，所以可以将addr传入printString函数
printString函数就是将传入变量调用String方法的结果打印出来 也就是上面接口实现时的返回值 由此可见在代码
func (addr address) String() string { return fmt.Sprintf(&#34;the addr is %s%s&#34;, addr.province, addr.city) } 中，不仅address实现了String方法 *address 也实现了String方法
如果我们将这个实现方法改成下面的样子结果会怎样呢？
func (addr *address) String() string { return fmt.Sprintf(&#34;the addr is %s%s&#34;, addr.province, addr.city) } 改成这样之后我们发现 printString(add)报错了，根据提示可以发现使用指针作为方法接收者，则只有指针实现了该方法，使用值作为方法接收者，则值和指针都实现了该方法。
再看下面的代码 在这个示例中，因为类型 address 已经实现了接口 fmt.Stringer，所以它的值可以被赋予变量 si，而且 si 也可以作为参数传递给函数 printString。 接着你可以使用 sip:=&amp;si 这样的操作获得一个指向接口的指针，这是没有问题的。不过最终你无法把指向接口的指针 sip 作为参数传递给函数 printString，Go 语言的编译器会提示如上图所示 于是可以总结为：虽然指向具体类型的指针可以实现一个接口，但是指向接口的指针永远不可能实现该接口。 所以在go语言中就不要用一个指针去指向另一个指针了。
参数传递 下面进入正题，学习一下值、引用、指针在参数传递时的区别 看下面的代码
type person struct { name string age int } func modifyPerson(p person) { p.name = p.name+&#34;6&#34; p.age = p.age+1 } func main() { p := person{name: &#34;张三&#34;, age: 18} modifyPerson(p) fmt.Println(&#34;person name:&#34;, p.name, &#34;,age:&#34;, p.age) } 运行结果： person name: 张三 ,age: 18 在这段代码中声明了一个结构体和修改结构体中元素值的方法，然后再main函数中创建一个结构体对象并修改值然后打印这个对象 但程序运行的结果却不是修改后的结果。这是因为在调用modifyPerson函数的时候传过去的只是p的拷贝而不是p本身，所以此时修改并没有改变原始p的值 那怎么修改才能得到我们想要的结果呢?
type person struct { name string age int } func modifyPerson(p *person) { p.name = p.name + &#34;6&#34; p.age = p.age + 1 } func main() { p := person{name: &#34;张三&#34;, age: 18} modifyPerson(&amp;p) fmt.Println(&#34;person name:&#34;, p.name, &#34;,age:&#34;, p.age) } 运行结果： person name: 张三6 ,age: 19 只需要将modifyPerson的参数改为person的指针类型即可,同时将modifyPerson(p)改为modifyPerson(&amp;p)
下面修改一下代码来看下p在内存中的地址 先看值传递的
func modifyPerson(p person) { fmt.Printf(&#34;modifyPerson函数中p的地址 %p\n&#34;, &amp;p) p.name = p.name + &#34;6&#34; p.age = p.age + 1 } func main() { p := person{name: &#34;张三&#34;, age: 18} fmt.Printf(&#34;main函数modifyPerson之前p的地址 %p\n&#34;, &amp;p) modifyPerson(p) fmt.Printf(&#34;main函数modifyPerson之后p的地址 %p\n&#34;, &amp;p) fmt.Println(&#34;person name:&#34;, p.name, &#34;,age:&#34;, p.age) } 运行结果 main函数modifyPerson之前p的地址 0xc00000c030 modifyPerson函数中p的地址 0xc00000c048 main函数modifyPerson之后p的地址 0xc00000c030 person name: 张三 ,age: 18 通过结果我们可以发现在main函数和modifyPerson函数中p的地址是不同的，modifyPerson函数中p只是main中p的一份拷贝，所以在modifyPerson中修改后，main函数中的p是不受影响的。 导致这种结果的原因是 Go 语言中的函数传参都是值传递。 值传递指的是传递原来数据的一份拷贝，而不是原来的数据本身。 除了 struct 外，还有浮点型、整型、字符串、布尔、数组，这些都是值类型。
再看指针传递的
func modifyPerson(p *person) { fmt.Printf(&#34;modifyPerson函数中p的地址 %p\n&#34;, &amp;p) p.name = p.name + &#34;6&#34; p.age = p.age + 1 } func main() { p := person{name: &#34;张三&#34;, age: 18} fmt.Printf(&#34;main函数modifyPerson之前p的地址 %p\n&#34;, &amp;p) modifyPerson(&amp;p) fmt.Printf(&#34;main函数modifyPerson之后p的地址 %p\n&#34;, &amp;p) fmt.Println(&#34;person name:&#34;, p.name, &#34;,age:&#34;, p.age) } 运行结果 main函数modifyPerson之前p的地址 0xc00000c030 modifyPerson函数中p的地址 0xc00000e030 main函数modifyPerson之后p的地址 0xc00000c030 person name: 张三6 ,age: 19 通过运行结果可以发现 modifyPerson函数和main函数中p的地址是一样的。
小提示：值传递的是指针，也是内存地址。通过内存地址可以找到原数据的那块内存，所以修改它也就等于修改了原数据。
引用类型 在Go语言中map 和 chan是引用类型
map: 讲上面的例子修改一下，不使用结构体改用map
func modifyMap(p map[string]int) { p[&#34;张三&#34;] = p[&#34;张三&#34;] + 1 } func main() { m := make(map[string]int) m[&#34;张三&#34;] = 18 fmt.Println(&#34;张三的年龄为&#34;, m[&#34;张三&#34;]) modifyMap(m) fmt.Println(&#34;张三的年龄为&#34;, m[&#34;张三&#34;]) } 运行结果 张三的年龄为 18 张三的年龄为 19 没有使用指针，只是用了 map 类型的参数，按照 Go 语言值传递的原则，modifyMap 函数中的 map 是一个副本，怎么会修改成功呢？ 要想解答这个问题，就要从 make 这个 Go 语言内建的函数说起。在 Go 语言中，任何创建 map 的代码（不管是字面量还是 make 函数）最终调用的都是 runtime.makemap 函数。
小提示：用字面量或者 make 函数的方式创建 map，并转换成 makemap 函数的调用，这个转换是 Go 语言编译器自动帮我们做的。
从下面的代码可以看到，makemap 函数返回的是一个 *hmap 类型，也就是说返回的是一个指针，所以我们创建的 map 其实就是一个 *hmap。
// makemap implements Go map creation for make(map[k]v, hint). func makemap(t *maptype, hint int, h *hmap) *hmap{ //省略无关代码 } 因为 Go 语言的 map 类型本质上就是 *hmap，所以根据替换的原则，我刚刚定义的 modifyMap(p map) 函数其实就是 modifyMap(p *hmap)。这是不是和之前说的指针类型的参数调用一样了。这也是通过 map 类型的参数可以修改原始数据的原因，因为它本质上就是个指针。
所以在这里，Go 语言通过 make 函数或字面量的包装为我们省去了指针的操作，让我们可以更容易地使用 map。其实就是语法糖。
注意：这里的 map 可以理解为引用类型，但是它本质上是个指针，只是可以叫作引用类型而已。在参数传递时，它还是值传递，并不是其他编程语言中所谓的引用传递。
chan: 通过下面的源代码可以看到，所创建的 chan 其实是个 *hchan，所以它在参数传递中也和 map 一样。
func makechan(t *chantype, size int64) *hchan { //省略无关代码 } 严格来说，Go 语言没有引用类型，但是我们可以把 map、chan 称为引用类型，这样便于理解。除了 map、chan 之外，Go 语言中的函数、接口、slice 切片都可以称为引用类型。
函数类型也是引用就可以很好的解释之前学习匿名函数的代码了：
func creatFunc1() func() int { i := 0 return func() int { i++ return i } } func main() { addFunc1 := creatFunc1() fmt.Println(addFunc1()) fmt.Println(addFunc1()) fmt.Println(addFunc1()) } 运行结果： 1 2 3 类型的零值 在 Go 语言中，定义变量要么通过声明、要么通过 make 和 new 函数，不一样的是 make 和 new 函数属于显式声明并初始化。如果我们声明的变量没有显式声明初始化，那么该变量的默认值就是对应类型的零值。 总结 在 Go 语言中，函数的参数传递只有值传递，而且传递的实参都是原始数据的一份拷贝。如果拷贝的内容是值类型的，那么在函数中就无法修改原始数据；如果拷贝的内容是指针（或者可以理解为引用类型 map、chan 等），那么就可以在函数中修改原始数据。
]]></content></entry><entry><title>Go语言指针学习</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-24-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E6%8C%87%E9%92%88%E5%AD%A6%E4%B9%A0/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[什么是指针 程序运行时的数据是存放在内存中的，而内存会被抽象为一系列具有连续编号的存储空间，那么每一个存储在内存中的数据都会有一个编号，这个编号就是内存地址。有了这个内存地址就可以找到这个内存中存储的数据，而内存地址可以被赋值给一个指针。
小提示：内存地址通常为 16 进制的数字表示，比如 0x45b876。
可以总结为：在编程语言中，指针是一种数据类型，用来存储一个内存地址，该地址指向存储在该内存中的对象。这个对象可以是字符串、整数、函数或者你自定义的结构体。
小技巧：你也可以简单地把指针理解为内存地址。
举个通俗的例子，每本书中都有目录，目录上会有相应章节的页码，你可以把页码理解为一系列的内存地址，通过页码你可以快速地定位到具体的章节（也就是说，通过内存地址可以快速地找到存储的数据）。
Go语言中指针的声明和定义 func main() { name := &#34;Golang&#34; nameP := &amp;name //取地址 fmt.Println(&#34;name变量的值为:&#34;, name) fmt.Println(&#34;nameP变量的值为:&#34;, nameP) fmt.Printf(&#34;nameP变量的类型为:%T&#34;, nameP) } //运行结果 name变量的值为: Golang nameP变量的值为: 0xc000010200 nameP变量的类型为:*string 这一串 0xc000010200 就是内存地址(这个每次运行得到的结果都是不一样的)，这个内存地址可以赋值给指针变量 nameP。
指针类型非常廉价，只占用 4 个或者 8 个字节的内存大小。
以上示例中 nameP 指针的类型是 *string，用于指向 string 类型的数据。在 Go 语言中使用类型名称前加 * 的方式，即可表示一个对应的指针类型。比如 int 类型的指针类型是 *int，float64 类型的指针类型是 *float64，自定义结构体 A 的指针类型是 *A。总之，指针类型就是在对应的类型前加 * 号。
从图中可以看到普通变量 name 的值“Golang”被放到内存地址为 0xc000010200 的内存块中。指针类型变量也是变量，它也需要一块内存用来存储值，这块内存对应的地址就是 0xc00000e028，存储的值是 0xc000010200。相信你已经看到关键点了，指针变量 nameP 的值正好是普通变量 name 的内存地址，所以就建立指向关系。
小提示：指针变量的值就是它所指向数据的内存地址，普通变量的值就是我们具体存放的数据。
不同的指针类型是无法相互赋值的，比如你不能对一个 string 类型的变量取地址然后赋值给 *int指针类型，编译器会提示你 Cannot use &lsquo;&amp;name&rsquo; (type *string) as type *int in assignment。
此外，除了可以通过简短声明的方式声明一个指针类型的变量外，也可以使用 var 关键字声明，如下面示例中的 var intP *int 就声明了一个 *int 类型的变量 intP。
var intP *int intP = &amp;name //指针类型不同，无法赋值 可以看到指针变量也和普通的变量一样，既可以通过 var 关键字定义，也可以通过简短声明定义。
小提示：通过 var 声明的指针变量是不能直接取值或赋值的(不能将对应类型的值赋值给他但是可以把指针地址赋值给他)，因为这时候它仅仅是个变量，还没有对应的内存地址，它的值是 nil。
举例
var intP *int *intP = 10 运行报错： panic: runtime error: invalid memory address or nil pointer dereference 但是可以将另一个变量地址赋值给他
var intP *int i := 10 intP = &amp;i fmt.Print(*intP) 运行结果： 10 或者这样初始化
var intP *int = new(int) //更推荐简短声明法，这里是为了演示 //intP:=new(int) *intP=10 fmt.Print(*intP) 运行结果： 10 和普通类型不一样的是，指针类型还可以通过内置的 new 函数来声明，如下所示： intP1:=new(int) 内置的 new 函数有一个参数，可以传递类型给它。它会返回对应的指针类型，比如上述示例中会返回一个 *int 类型的 intP1。
指针的操作 在 Go 语言中指针的操作无非是两种：一种是获取指针指向的值，一种是修改指针指向的值。
nameV:=*nameP fmt.Println(&#34;nameP指针指向的值为:&#34;,nameV) //获取指针指向的值 可以看到，要获取指针指向的值，只需要在指针变量前加 * 号即可，获得的变量 nameV 的值就是“Golang”，方法比较简单。
修改指针指向的值也非常简单，比如下面的例子：
*nameP = &#34;golang&#34; //修改指针指向的值 之前是Golang fmt.Println(&#34;nameP指针指向的值为:&#34;,*nameP) fmt.Println(&#34;name变量的值为:&#34;,name) 运行结果： nameP指针指向的值为: golang name变量的值为: golang 通过打印结果可以看到，不光 nameP 指针指向的值被改变了，变量 name 的值也被改变了，这就是指针的作用。因为变量 name 存储数据的内存就是指针 nameP 指向的内存，这块内存被 nameP 修改后，变量 name 的值也被修改了。
指针参数 假如有一个函数 modifyAge，想要用来修改年龄，如下面的代码所示。但运行它，你会看到 age 的值并没有被修改，还是 18，并没有变成 20。
func modifyAge(age int) { age = 20 } func main() { age := 18 modifyAge(age) fmt.Println(&#34;age的值为:&#34;, age) } 运行结果： age的值为: 18 导致这种结果的原因是 modifyAge 中的 age 只是实参 age 的一份拷贝，所以修改它不会改变实参 age 的值。
如果要达到修改年龄的目的，就需要使用指针，现在对刚刚的示例进行改造，如下所示：
func modifyAge(age *int) { *age = 20 } func main() { age := 18 modifyAge(&amp;age) fmt.Println(&#34;age的值为:&#34;, age) } 运行结果： age的值为: 20 也就是说，当你需要在函数中通过形参改变实参的值时，需要使用指针类型的参数。
指针接收者 对于是否使用指针类型作为接收者，有以下几点参考：
1.如果接收者类型是 map、slice、channel 这类引用类型，不使用指针；
2.如果需要修改接收者，那么需要使用指针；
3.如果接收者是比较大的类型，可以考虑使用指针，因为内存拷贝廉价，所以效率高。
所以对于是否使用指针类型作为接收者，还需要你根据实际情况考虑。
什么情况下使用指针 从以上指针的详细分析中，我们可以总结出指针的两大好处：
可以修改指向数据的值；
在变量赋值，参数传值的时候可以节省内存。
不过 Go 语言作为一种高级语言，在指针的使用上还是比较克制的。它在设计的时候就对指针进行了诸多限制，比如指针不能进行运算，也不能获取常量的指针。
不要对 map、slice、channel 这类引用类型使用指针；
如果需要修改方法接收者内部的数据或者状态时，需要使用指针；
如果需要修改参数的值或者内部数据时，也需要使用指针类型的参数；
如果是比较大的结构体，每次参数传递或者调用方法都要内存拷贝，内存占用多，这时候可以考虑使用指针；
像 int、bool 这样的小数据类型没必要使用指针；
如果需要并发安全，则尽可能地不要使用指针，使用指针一定要保证并发安全；
指针最好不要嵌套，也就是不要使用一个指向指针的指针，虽然 Go 语言允许这么做，但是这会使你的代码变得异常复杂。
总结 为了使编程变得更简单，指针在高级的语言中被逐渐淡化，但是它也的确有自己的优势：修改数据的值和节省内存。所以在 Go 语言的开发中我们要尽可能地使用值类型，而不是指针类型，因为值类型可以使你的开发变得更简单，并且也是并发安全的。如果你想使用指针类型，就要参考上面提到的使用指针的条件，看是否满足，要在满足和必须的情况下才使用指针。
]]></content></entry><entry><title>Go语言常见的高效并发模式</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-18-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%B8%B8%E8%A7%81%E7%9A%84%E9%AB%98%E6%95%88%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[如何用 goroutine、channel、sync包 这些基础元素组成并发模式，更好地编写并发程序。
for select 循环模式 for { //for无限循环，或者for range循环 select { //通过一个channel控制 } } for select 循环模式一 无限循环直到停止指令 for { select { case &lt;-done: return default: //执行具体的任务 } } for select 循环模式二 迭代循环 一般用于把可以迭代的内容发送到 channel 上 for _,s:=range []int{}{ select { case &lt;-done: return case resultCh &lt;- s: } } select timeout 模式 假如需要访问服务器获取数据，因为网络的不同响应时间不一样，为保证程序的质量，不可能一直等待网络返回，所以需要设置一个超时时间，这时候就可以使用 select timeout 模式
func main() { result := make(chan string) go func() { //模拟网络访问 time.Sleep(8 * time.Second) result &lt;- &#34;服务端结果&#34; }() select { case v := &lt;-result: fmt.Println(v) case &lt;-time.After(5 * time.Second): fmt.Println(&#34;网络访问超时了&#34;) } } select timeout 模式的核心在于通过 time.After 函数设置一个超时时间，防止因为异常造成 select 语句的无限等待。
Pipeline 模式 Pipeline 模式也称为流水线模式，模拟的就是现实世界中的流水线生产。以手机组装为例，整条生产流水线可能有成百上千道工序，每道工序只负责自己的事情，最终经过一道道工序组装，就完成了一部手机的生产。
从技术上看，每一道工序的输出，就是下一道工序的输入，在工序之间传递的东西就是数据，这种模式称为流水线模式，而传递的数据称为数据流。 通过以上流水线模式示意图，可以看到从最开始的生产，经过工序 1、2、3、4 到最终成品，这就是一条比较形象的流水线，也就是 Pipeline。
现在以组装手机为例，讲解流水线模式的使用。假设一条组装手机的流水线有 3 道工序，分别是配件采购、配件组装、打包成品，如图所示： 从以上示意图中可以看到，采购的配件通过 channel 传递给工序 2 进行组装，然后再通过 channel 传递给工序 3 打包成品。相对工序 2 来说，工序 1 是生产者，工序 3 是消费者。相对工序 1 来说，工序 2 是消费者。相对工序 3 来说，工序 2 是生产者。
//工序1采购 func buy(n int) &lt;-chan string { out := make(chan string) go func() { defer close(out) for i := 1; i &lt;= n; i++ { out &lt;- fmt.Sprint(&#34;配件&#34;, i) } }() return out } //工序2组装 func build(in &lt;-chan string) &lt;-chan string { out := make(chan string) go func() { defer close(out) for c := range in { out &lt;- &#34;组装(&#34; + c + &#34;)&#34; } }() return out } //工序3打包 func pack(in &lt;-chan string) &lt;-chan string { out := make(chan string) go func() { defer close(out) for c := range in { out &lt;- &#34;打包(&#34; + c + &#34;)&#34; } }() return out } 流水线上的三道工序都完成后，就可以通过一个组织者把三道工序组织在一起，形成一条完整的手机组装流水线，这个组织者可以是我们常用的 main 函数，如下面的代码所示：
func main() { coms := buy(10) //采购10套配件 phones := build(coms) //组装10部手机 packs := pack(phones) //打包它们以便售卖 //输出测试，看看效果 for p := range packs { fmt.Println(p) } } 运行结果 打包(组装(配件1)) 打包(组装(配件2)) 打包(组装(配件3)) 打包(组装(配件4)) 打包(组装(配件5)) 打包(组装(配件6)) 打包(组装(配件7)) 打包(组装(配件8)) 打包(组装(配件9)) 打包(组装(配件10)) 从上述例子中，我们可以总结出一个流水线模式的构成：
流水线由一道道工序构成，每道工序通过 channel 把数据传递到下一个工序；
每道工序一般会对应一个函数，函数里有协程和 channel，协程一般用于处理数据并把它放入 channel 中，整个函数会返回这个 channel 以供下一道工序使用；
最终要有一个组织者（示例中的 main 函数）把这些工序串起来，这样就形成了一个完整的流水线，对于数据来说就是数据流。
扇出和扇入模式 手机流水线经过一段时间的运转，组织者发现产能提不上去，经过调研分析，发现瓶颈在工序 2 配件组装。工序 2 过慢，导致上游工序 1 配件采购速度不得不降下来，下游工序 3 没太多事情做，不得不闲下来，这就是整条流水线产能低下的原因。
为了提升手机产能，组织者决定对工序 2 增加两班人手。人手增加后，整条流水线的示意图如下所示： 从改造后的流水线示意图可以看到，工序 2 共有工序 2-1、工序 2-2、工序 2-3 三班人手，工序 1 采购的配件会被工序 2 的三班人手同时组装，这三班人手组装好的手机会同时传给merge 组件汇聚，然后再传给工序 3 打包成品。在这个流程中，会产生两种模式：扇出和扇入。
示意图中红色的部分是扇出，对于工序 1 来说，它同时为工序 2 的三班人手传递数据（采购配件）。以工序 1 为中点，三条传递数据的线发散出去，就像一把打开的扇子一样，所以叫扇出。
示意图中蓝色的部分是扇入，对于 merge 组件来说，它同时接收工序 2 三班人手传递的数据（组装的手机）进行汇聚，然后传给工序 3。以 merge 组件为中点，三条传递数据的线汇聚到 merge 组件，也像一把打开的扇子一样，所以叫扇入。
小提示：扇出和扇入都像一把打开的扇子，因为数据传递的方向不同，所以叫法也不一样，扇出的数据流向是发散传递出去，是输出流；扇入的数据流向是汇聚进来，是输入流。
已经理解了扇出扇入的原理，就可以开始改造流水线了。这次改造中，三道工序的实现函数 buy、build、pack 都保持不变，只需要增加一个 merge 函数即可，如下面的代码所示：
//扇入函数（组件），把多个chanel中的数据发送到一个channel中 func merge(ins ...&lt;-chan string) &lt;-chan string { var wg sync.WaitGroup out := make(chan string) //把一个channel中的数据发送到out中 p:=func(in &lt;-chan string) { defer wg.Done() for c := range in { out &lt;- c } } wg.Add(len(ins)) //扇入，需要启动多个goroutine用于处于多个channel中的数据 for _,cs:=range ins{ go p(cs) } //等待所有输入的数据ins处理完，再关闭输出out go func() { wg.Wait() close(out) }() return out } 新增的 merge 函数的核心逻辑就是对输入的每个 channel 使用单独的协程处理，并将每个协程处理的结果都发送到变量 out 中，达到扇入的目的。总结起来就是通过多个协程并发，把多个 channel 合成一个。
在整条手机组装流水线中，merge 函数非常小，而且和业务无关，不能当作一道工序，而是叫作组件。该 merge 组件是可以复用的，流水线中的任何工序需要扇入的时候，都可以使用 merge 组件。
小提示：这次的改造新增了 merge 函数，其他函数保持不变，符合开闭原则。开闭原则规定“软件中的对象（类，模块，函数等等）应该对于扩展是开放的，但是对于修改是封闭的”。
func main() { coms := buy(100) //采购100套配件 //三班人同时组装100部手机 phones1 := build(coms) phones2 := build(coms) phones3 := build(coms) //汇聚三个channel成一个 phones := merge(phones1,phones2,phones3) packs := pack(phones) //打包它们以便售卖 //输出测试，看看效果 for p := range packs { fmt.Println(p) } } 这个示例采购了 100 套配件，也就是开始增加产能了。于是同时调用三次 build 函数，也就是为工序 2 增加人手，这里是三班人手同时组装配件，然后通过 merge 函数这个可复用的组件将三个 channel 汇聚为一个，然后传给 pack 函数打包。
这样通过扇出和扇入模式，整条流水线就被扩充好了，大大提升了生产效率。因为已经有了通用的扇入组件 merge，所以整条流水中任何需要扇出、扇入提高性能的工序，都可以复用 merge 组件做扇入，并且不用做任何修改。
Futures 模式 Pipeline 流水线模式中的工序是相互依赖的，上一道工序做完，下一道工序才能开始。但是在我们的实际需求中，也有大量的任务之间相互独立、没有依赖，所以为了提高性能，这些独立的任务就可以并发执行。
举个例子，比如我打算自己做顿火锅吃，那么就需要洗菜、烧水。洗菜、烧水这两个步骤相互之间没有依赖关系，是独立的，那么就可以同时做，但是最后做火锅这个步骤就需要洗好菜、烧好水之后才能进行。这个做火锅的场景就适用 Futures 模式。
Futures 模式可以理解为未来模式，主协程不用等待子协程返回的结果，可以先去做其他事情，等未来需要子协程结果的时候再来取，如果子协程还没有返回结果，就一直等待。我用下面的代码进行演示：
//洗菜 func washVegetables() &lt;-chan string { vegetables := make(chan string) go func() { time.Sleep(5 * time.Second) vegetables &lt;- &#34;洗好的菜&#34; }() return vegetables } //烧水 func boilWater() &lt;-chan string { water := make(chan string) go func() { time.Sleep(5 * time.Second) water &lt;- &#34;烧开的水&#34; }() return water } 洗菜和烧水这两个相互独立的任务可以一起做，所以示例中通过开启协程的方式，实现同时做的功能。当任务完成后，结果会通过 channel 返回。
小提示：示例中的等待 5 秒用来描述洗菜和烧火的耗时。 在启动两个子协程同时去洗菜和烧水的时候，主协程就可以去干点其他事情（示例中是眯一会），等睡醒了，要做火锅的时候，就需要洗好的菜和烧好的水这两个结果了。我用下面的代码进行演示：
func main() { vegetablesCh := washVegetables() //洗菜 waterCh := boilWater() //烧水 fmt.Println(&#34;已经安排洗菜和烧水了，我先眯一会&#34;) time.Sleep(2 * time.Second) fmt.Println(&#34;要做火锅了，看看菜和水好了吗&#34;) vegetables := &lt;-vegetablesCh water := &lt;-waterCh fmt.Println(&#34;准备好了，可以做火锅了:&#34;, vegetables, water) } 洗菜和烧水这两个相互独立的任务可以一起做，所以示例中通过开启协程的方式，实现同时做的功能。当任务完成后，结果会通过 channel 返回。 Futures 模式下的协程和普通协程最大的区别是可以返回结果，而这个结果会在未来的某个时间点使用。所以在未来获取这个结果的操作必须是一个阻塞的操作，要一直等到获取结果为止。
如果你的大任务可以拆解为一个个独立并发执行的小任务，并且可以通过这些小任务的结果得出最终大任务的结果，就可以使用 Futures 模式。
总结 并发模式和设计模式很相似，都是对现实场景的抽象封装，以便提供一个统一的解决方案。但和设计模式不同的是，并发模式更专注于异步和并发。
]]></content></entry><entry><title>Go语言Context学习笔记</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-16-%E8%BD%ACgo%E8%AF%AD%E8%A8%80context%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[前言 之前学习了怎么在所有的协程运行结束后让程序停止。这次学一下怎么让运行中的协程停止。比如我们开了1个协程去监控一个程序，如果我们手动取消监控就要让协程主动停止任务，该怎么实现呢？用 select+channel 做检测！
func main() { var wg sync.WaitGroup wg.Add(1) stopCh := make(chan bool) //用来停止监控狗 go func() { defer wg.Done() watchDog(stopCh,&#34;【监控狗1】&#34;) }() time.Sleep(5 * time.Second) //先让监控狗监控5秒 stopCh &lt;- true //发停止指令 wg.Wait() } func watchDog(stopCh chan bool,name string){ //开启for select循环，一直后台监控 for{ select { case &lt;-stopCh: fmt.Println(name,&#34;停止指令已收到，马上停止&#34;) return default: fmt.Println(name,&#34;正在监控……&#34;) } time.Sleep(1*time.Second) } } 初识Context 在实际应用中为了更好的利用资源肯定不会只开一个协程去处理任务，如果开了多个协程去监控，那怎么同时取消多个协程呢？使用多个channel吗？如果是几百上千个协程呢？使用channel的局限性就提现出来了。这时候就要用到Context包了。context不仅可以同时取消多个协程，还可以定时取消！先看下使用Context修改后的代码
func main() { var wg sync.WaitGroup wg.Add(1) ctx,stop:=context.WithCancel(context.Background()) go func() { defer wg.Done() watchDog(ctx,&#34;【监控狗1】&#34;) }() time.Sleep(5 * time.Second) //先让监控狗监控5秒 stop() //发停止指令 wg.Wait() } func watchDog(ctx context.Context,name string) { //开启for select循环，一直后台监控 for { select { case &lt;-ctx.Done(): fmt.Println(name,&#34;停止指令已收到，马上停止&#34;) return default: fmt.Println(name,&#34;正在监控……&#34;) } time.Sleep(1 * time.Second) } } 相比 select+channel 的方案，Context 方案主要有 4 个改动点。
1.watchDog 的 stopCh 参数换成了 ctx，类型为 context.Context。
2.原来的 case &lt;-stopCh 改为 case &lt;-ctx.Done()，用于判断是否停止。
3.使用 context.WithCancel(context.Background()) 函数生成一个可以取消的 Context，用于发送停止指令。这里的 context.Background() 用于生成一个空 Context，一般作为整个 Context 树的根节点。
4.原来的 stopCh &lt;- true 停止指令，改为 context.WithCancel 函数返回的取消函数 stop()。
可以看到，这和修改前的整体代码结构一样，只不过从 channel 换成了 Context。以上示例只是 Context 的一种使用场景，它的能力不止于此，现在来看下什么是 Context。 首先，Context是并发安全的。Context 是一个接口，它具备手动、定时、超时发出取消信号、传值等功能，主要用于控制多个协程之间的协作，尤其是取消操作。一旦取消指令下达，那么被 Context 跟踪的这些协程都会收到取消信号，就可以做清理和退出操作。 Context 接口只有四个方法：
type Context interface { Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct{} Err() error Value(key interface{}) interface{} } Deadline 方法可以获取设置的截止时间，第一个返回值 deadline 是截止时间，到了这个时间点，Context 会自动发起取消请求，第二个返回值 ok 代表是否设置了截止时间。
Done 方法返回一个只读的 channel，类型为 struct{}。在协程中，如果该方法返回的 chan 可以读取，则意味着 Context 已经发起了取消信号。通过 Done 方法收到这个信号后，就可以做清理操作，然后退出协程，释放资源。
Err 方法返回取消的错误原因，即因为什么原因 Context 被取消。
Value 方法获取该 Context 上绑定的值，是一个键值对，所以要通过一个 key 才可以获取对应的值。
Context树 我们不需要自己实现 Context 接口，Go 语言提供了函数可以帮助我们生成不同的 Context，通过这些函数可以生成一颗 Context 树，这样 Context 才可以关联起来，父 Context 发出取消信号的时候，子 Context 也会发出，这样就可以控制不同层级的协程退出。
从使用功能上分，有四种实现好的 Context。
空 Context：不可取消，没有截止时间，主要用于 Context 树的根节点。
可取消的 Context：用于发出取消信号，当取消的时候，它的子 Context 也会取消。
可定时取消的 Context：多了一个定时的功能。
值 Context：用于存储一个 key-value 键值对。
有了根节点 Context 后，这颗 Context 树要怎么生成呢？需要使用 Go 语言提供的四个函数。
1.WithCancel(parent Context)：生成一个可取消的 Context。
2.WithDeadline(parent Context, d time.Time)：生成一个可定时取消的 Context，参数 d 为定时取消的具体时间。
3.WithTimeout(parent Context, timeout time.Duration)：生成一个可超时取消的 Context，参数 timeout 用于设置多久后取消
4.WithValue(parent Context, key, val interface{})：生成一个可携带 key-value 键值对的 Context。
以上四个生成 Context 的函数中，前三个都属于可取消的 Context，它们是一类函数，最后一个是值 Context，用于存储一个 key-value 键值对。
如果一个 Context 有子 Context，在该 Context 取消时会发生什么呢？
当节点 Ctx2 取消时，它的子节点 Ctx4、Ctx5 都会被取消，如果还有子节点的子节点，也会被取消。也就是说根节点为 Ctx2 的所有节点都会被取消，其他节点如 Ctx1、Ctx3 和 Ctx6 则不会。
下面代码是演示验证：
func main() { fmt.Println(&#34;程序启动时间：&#34;, time.Now().Format(&#34;2006-01-02 15:04:05&#34;)) var wg sync.WaitGroup ctx0, stopAll := context.WithCancel(context.Background()) ctx1, stopCtx1 := context.WithCancel(ctx0) //ctx1 手动停止 ctx1_1, _ := context.WithCancel(ctx1) ctx1_2, _ := context.WithCancel(ctx1) endTime := time.Now().Add(time.Second * 10) fmt.Println(&#34;ctx2停止时间为：&#34;, endTime.Format(&#34;2006-01-02 15:04:05&#34;)) ctx2, _ := context.WithDeadline(ctx0, endTime) //指定时间停止 10s后 ctx3, _ := context.WithTimeout(ctx0, time.Second*15) //15秒后停止 wg.Add(6) go func() { defer wg.Done() watchDog(ctx0, &#34;【ctx0】&#34;) }() go func() { defer wg.Done() watchDog(ctx1, &#34;【ctx1】&#34;) }() go func() { defer wg.Done() watchDog(ctx2, &#34;【ctx2】&#34;) }() go func() { defer wg.Done() watchDog(ctx3, &#34;【ctx3】&#34;) }() go func() { defer wg.Done() watchDog(ctx1_1, &#34;【ctx1_1】&#34;) }() go func() { defer wg.Done() watchDog(ctx1_2, &#34;【ctx1_2】&#34;) }() time.Sleep(5 * time.Second) //先让ctx监控5秒 stopCtx1() //发停止指令 手动关闭ctx1 time.Sleep(15 * time.Second) //再让ctx监控15秒 然后关闭根ctx stopAll() wg.Wait() } func watchDog(ctx context.Context, name string) { //开启for select循环，一直后台监控 for { select { case &lt;-ctx.Done(): log.Println(name, &#34;停止指令已收到，马上停止&#34;) return default: log.Println(name, &#34;正在运行……&#34;) } time.Sleep(1000 * time.Millisecond) } } 运行结果： 程序启动时间： 2022-11-04 14:11:38 ctx2停止时间为： 2022-11-04 14:11:48 2022/11/04 14:11:38 【ctx1_2】 正在运行…… 2022/11/04 14:11:38 【ctx3】 正在运行…… 2022/11/04 14:11:38 【ctx1_1】 正在运行…… 2022/11/04 14:11:38 【ctx2】 正在运行…… 2022/11/04 14:11:38 【ctx0】 正在运行…… 2022/11/04 14:11:38 【ctx1】 正在运行…… 2022/11/04 14:11:39 【ctx1_1】 正在运行…… 2022/11/04 14:11:39 【ctx1】 正在运行…… 2022/11/04 14:11:39 【ctx2】 正在运行…… 2022/11/04 14:11:39 【ctx0】 正在运行…… 2022/11/04 14:11:39 【ctx3】 正在运行…… 2022/11/04 14:11:39 【ctx1_2】 正在运行…… 2022/11/04 14:11:40 【ctx1_2】 正在运行…… 2022/11/04 14:11:40 【ctx3】 正在运行…… 2022/11/04 14:11:40 【ctx0】 正在运行…… 2022/11/04 14:11:40 【ctx1】 正在运行…… 2022/11/04 14:11:40 【ctx2】 正在运行…… 2022/11/04 14:11:40 【ctx1_1】 正在运行…… 2022/11/04 14:11:41 【ctx0】 正在运行…… 2022/11/04 14:11:41 【ctx1_1】 正在运行…… 2022/11/04 14:11:41 【ctx3】 正在运行…… 2022/11/04 14:11:41 【ctx1_2】 正在运行…… 2022/11/04 14:11:41 【ctx2】 正在运行…… 2022/11/04 14:11:41 【ctx1】 正在运行…… 2022/11/04 14:11:42 【ctx0】 正在运行…… 2022/11/04 14:11:42 【ctx1】 正在运行…… 2022/11/04 14:11:42 【ctx1_1】 正在运行…… 2022/11/04 14:11:42 【ctx2】 正在运行…… 2022/11/04 14:11:42 【ctx1_2】 正在运行…… 2022/11/04 14:11:42 【ctx3】 正在运行…… 2022/11/04 14:11:43 【ctx3】 正在运行…… 2022/11/04 14:11:43 【ctx2】 正在运行…… 2022/11/04 14:11:43 【ctx1_2】 停止指令已收到，马上停止 2022/11/04 14:11:43 【ctx1】 停止指令已收到，马上停止 2022/11/04 14:11:43 【ctx1_1】 停止指令已收到，马上停止 2022/11/04 14:11:43 【ctx0】 正在运行…… 2022/11/04 14:11:44 【ctx0】 正在运行…… 2022/11/04 14:11:44 【ctx3】 正在运行…… 2022/11/04 14:11:44 【ctx2】 正在运行…… 2022/11/04 14:11:45 【ctx0】 正在运行…… 2022/11/04 14:11:45 【ctx3】 正在运行…… 2022/11/04 14:11:45 【ctx2】 正在运行…… 2022/11/04 14:11:46 【ctx3】 正在运行…… 2022/11/04 14:11:46 【ctx0】 正在运行…… 2022/11/04 14:11:46 【ctx2】 正在运行…… 2022/11/04 14:11:47 【ctx2】 正在运行…… 2022/11/04 14:11:47 【ctx3】 正在运行…… 2022/11/04 14:11:47 【ctx0】 正在运行…… 2022/11/04 14:11:48 【ctx0】 正在运行…… 2022/11/04 14:11:48 【ctx3】 正在运行…… 2022/11/04 14:11:48 【ctx2】 停止指令已收到，马上停止 2022/11/04 14:11:49 【ctx3】 正在运行…… 2022/11/04 14:11:49 【ctx0】 正在运行…… 2022/11/04 14:11:50 【ctx0】 正在运行…… 2022/11/04 14:11:50 【ctx3】 正在运行…… 2022/11/04 14:11:51 【ctx3】 正在运行…… 2022/11/04 14:11:51 【ctx0】 正在运行…… 2022/11/04 14:11:52 【ctx0】 正在运行…… 2022/11/04 14:11:52 【ctx3】 正在运行…… 2022/11/04 14:11:53 【ctx3】 停止指令已收到，马上停止 2022/11/04 14:11:53 【ctx0】 正在运行…… 2022/11/04 14:11:54 【ctx0】 正在运行…… 2022/11/04 14:11:55 【ctx0】 正在运行…… 2022/11/04 14:11:56 【ctx0】 正在运行…… 2022/11/04 14:11:57 【ctx0】 正在运行…… 2022/11/04 14:11:58 【ctx0】 停止指令已收到，马上停止 通过对运行结果的分析可以发现在 stopCtx1 执行前 所有的ctx都在运行
程序的启动时间为2022-11-04 14:11:38 很具代码来看 ctx1及ctx1_1、ctx1_2 都应该在5秒后停止即 2022-11-04 14:11:43
ctx2的停止直接与设置的deadline一致
ctx3与设置的超时时间一致
Context传值 Context 不仅可以取消，还可以传值，通过这个能力，可以把 Context 存储的值供其他协程使用。
代码演示:
func main() { fmt.Println(&#34;程序启动时间：&#34;, time.Now().Format(&#34;2006-01-02 15:04:05&#34;)) var wg sync.WaitGroup wg.Add(1) ctx, stop := context.WithCancel(context.Background()) valCtx := context.WithValue(ctx, &#34;userId&#34;, 123) go func() { defer wg.Done() getUser(valCtx) }() time.Sleep(5 * time.Second) stop() wg.Wait() } func getUser(ctx context.Context) { for { select { case &lt;-ctx.Done(): log.Println(&#34;【获取用户】&#34;, &#34;协程退出&#34;) return default: userId := ctx.Value(&#34;userId&#34;) log.Println(&#34;【获取用户】&#34;, &#34;用户ID为：&#34;, userId) time.Sleep(1 * time.Second) } } } 运行结果: 程序启动时间： 2022-11-04 14:19:36 2022/11/04 14:19:36 【获取用户】 用户ID为： 123 2022/11/04 14:19:37 【获取用户】 用户ID为： 123 2022/11/04 14:19:38 【获取用户】 用户ID为： 123 2022/11/04 14:19:39 【获取用户】 用户ID为： 123 2022/11/04 14:19:40 【获取用户】 用户ID为： 123 2022/11/04 14:19:41 【获取用户】 协程退出 Context 使用原则 Context 是一种非常好的工具，使用它可以很方便地控制取消多个协程。在 Go 语言标准库中也使用了它们，比如 net/http 中使用 Context 取消网络的请求。
要更好地使用 Context，有一些使用原则需要尽可能地遵守。
Context 不要放在结构体中，要以参数的方式传递。
Context 作为函数的参数时，要放在第一位，也就是第一个参数。
要使用 context.Background 函数生成根节点的 Context，也就是最顶层的 Context。
Context 传值要传递必须的值，而且要尽可能地少，不要什么都传。
Context 多协程安全，可以在多个协程中放心使用。
以上原则是规范类的，Go 语言的编译器并不会做这些检查，要靠自己遵守。
]]></content></entry><entry><title>Go语言中使用sync包控制并发</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-15-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%B8%AD%E4%BD%BF%E7%94%A8sync%E5%8C%85%E6%8E%A7%E5%88%B6%E5%B9%B6%E5%8F%91/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[sync.Mutex 和 sync.RWMutex 如果同一块内存被多个 goroutine 同时访问，就会产生不知道谁先访问也无法预料最后结果的情况。这就是资源竞争，这块内存可以称为共享的资源。例如下面的代码
var sum = 0 func main() { for i := 1; i &lt; 5; i++ { go add(i) } time.Sleep(2 * time.Second) fmt.Println(&#34;和为:&#34;, sum) } func add(i int) { fmt.Println(&#34;add前sum=&#34;, sum) sum += i fmt.Println(&#34;add &#34;, i, &#34;后sum=&#34;, sum) } 运行结果: add前sum= 0 add 2 后sum= 2 add前sum= 0 add前sum= 0 add 4 后sum= 7 add 1 后sum= 3 add前sum= 2 add 3 后sum= 10 和为: 10 通过上面的代码我们发现我们创建的4个协程再执行add中的语句时是有可能同时执行的,这就是资源竞争,并没有得到想要结果。那我们有没有什么办法能在同一时刻只有一个协程去读取sum呢？这就要用到sync包了。看下面的代码
var sum = 0 var mutex sync.Mutex func main() { for i := 1; i &lt; 5; i++ { go add(1) } time.Sleep(2 * time.Second) fmt.Println(&#34;和为:&#34;, sum) } func add(i int) { mutex.Lock() defer mutex.Unlock() fmt.Println(&#34;add前sum=&#34;, sum) sum += i fmt.Println(&#34;add &#34;, i, &#34;后sum=&#34;, sum) } 运行结果： add前sum= 0 add 2 后sum= 2 add前sum= 2 add 1 后sum= 3 add前sum= 3 add 4 后sum= 7 add前sum= 7 add 3 后sum= 10 和为: 10 通过上面的代码我们发现虽然协程执行的顺序并不是按照for循环中的顺序来(给出的顺序是2143 只是一种结果，如果按照for循环的顺序来应该是1234),但是没一个协程在执行add函数中的语句时别的协程是没有参与进来的，这就是互斥锁。 但是这样每次读写共享资源都要加锁，会导致性能低下，这该怎么解决呢？
现在我们分析读写这个特殊场景，有以下几种情况：
写的时候不能同时读，因为这个时候读取的话可能读到脏数据（不正确的数据）； 读的时候不能同时写，因为也可能产生不可预料的结果； 读的时候可以同时读，因为数据不会改变，所以不管多少个 goroutine 读都是并发安全的。 所以就可以通过读写锁 sync.RWMutex 来优化这段代码，提升性能。
var mutex sync.RWMutex func add(i int) { mutex.RLock() defer mutex.RUnlock() fmt.Println(&#34;add前sum=&#34;, sum) sum += i fmt.Println(&#34;add &#34;, i, &#34;后sum=&#34;, sum) } 这样多个 goroutine 可以同时读数据，不再相互等待。
sync.Mutex 和 sync.RWMutex 都是悲观锁
sync.WaitGroup 细心的你可能会发现每次运行程序后输出结果前都会等待2秒，这是因为为了等待所有的协程都执行结束，不然main函数结束了程序就退出了，那有些协程可能还没开始就结束了。
但是每次都等2秒或者说如果2s的时间不够那怎么办呢？是不是应该让所有协程执行结束后就输出结果然后程序结束。
这就要用到sync包中的WaitGroup，我们先看下WaitGroup的描述。
A WaitGroup waits for a collection of goroutines to finish. The main goroutine calls Add to set the number of goroutines to wait for. Then each of the goroutines runs and calls Done when finished. At the same time, Wait can be used to block until all goroutines have finished. A WaitGroup must not be copied after first use.
大概意思就是说在协程执行前执行一下Add方法，协程临近结束前执行一下Done方法。 在主程序中执行Wait方法就会阻塞程序，直到所有的协程都完成。 举个🌰
func main() { for i := 1; i &lt; 10000; i++ { go func(i int) { fmt.Println(i) }(i) } time.Sleep(1 * time.Nanosecond) } 上面的代码在一个for循环中执行了10000个匿名函数的协程，协程的内容是输出i 然后程序延迟1毫微秒结束，1毫微秒是时间内能输出多少个数字呢？大概率到不到10000个，那怎么才能让他在正好输出10000个数字后就停止呢？使用WaitGroup，看下面的代码改造
var wg sync.WaitGroup func main() { for i := 1; i &lt; 10000; i++ { wg.Add(1) go func(i int) { fmt.Println(i) wg.Done() }(i) } wg.Wait() } 这样就能在输出10000个数字后结束程序
sync.Cond 现在我们可以在找到所有协程同时完成的时间点了那有没有办法让所有的协程同时开始呢？ 在 Go 语言中，sync.WaitGroup 用于最终完成的场景，关键点在于一定要等待所有协程都执行完毕。而 sync.Cond 可以用于发号施令，一声令下所有协程都可以开始执行，关键点在于协程开始的时候是等待的，要等待 sync.Cond 唤醒才能执行。
sync.Cond 从字面意思看是条件变量，它具有阻塞协程和唤醒协程的功能，所以可以在满足一定条件的情况下唤醒协程，但条件变量只是它的一种使用场景。
下面我以 5 个人赛跑为例来演示 sync.Cond 的用法。在这个示例中有一个裁判，裁判要先等这 5 个人准备就绪，然后一声发令枪响，这 5 个人就可以开始跑了，如下所示：
//5个人赛跑，1个裁判发号施令 func race() { cond := sync.NewCond(&amp;sync.Mutex{}) var wg1, wg2 sync.WaitGroup wg1.Add(5) wg2.Add(5) rand.Seed(time.Now().Unix()) for i := 1; i &lt;= 5; i++ { go func(num int) { log.Println(num, &#34;号已经就位&#34;) wg1.Done() cond.L.Lock() log.Println(num, &#34;号等待发令枪响&#34;) cond.Wait() //等待发令枪响 cond.L.Unlock() go func() { log.Println(num, &#34;号开始跑……&#34;) time.Sleep(time.Second * time.Duration(3+rand.Intn(4))) log.Println(num, &#34;号跑完了&#34;) wg2.Done() }() }(i) } //等待所有goroutine都进入wait状态 wg1.Wait() go func() { log.Println(&#34;裁判已经就位，准备发令枪&#34;) log.Println(&#34;比赛开始，大家准备跑&#34;) cond.Broadcast() //发令枪响 }() //防止函数提前返回退出 wg2.Wait() log.Println(&#34;所有人都跑完了&#34;) } 1.通过 sync.NewCond 函数生成一个 *sync.Cond，用于阻塞和唤醒协程；
2.然后启动 5 个协程模拟 5 个人，准备就位后调用 cond.Wait() 方法阻塞当前协程等待发令枪响，这里需要注意的是调用 cond.Wait() 方法时要加锁；
3.wg1是等待所有人准备完毕后使用 cond.Broadcast() 发号施令，wg2是等待所有人都跑完程序结束；
4.sync.Cond 有三个方法，它们分别是：
①Wait，阻塞当前协程，直到被其他协程调用 Broadcast 或者 Signal 方法唤醒，使用的时候需要加锁，使用 sync.Cond 中的锁即可，也就是 L 字段。
②Signal，唤醒一个等待时间最长的协程。
③Broadcast，唤醒所有等待的协程。
注意：在调用 Signal 或者 Broadcast 之前，要确保目标协程处于 Wait 阻塞状态，不然会出现死锁问题。
sync.Cond 和 Java 的等待唤醒机制很像，它的三个方法 Wait、Signal、Broadcast 就分别对应 Java 中的 wait、notify、notifyAll。
]]></content></entry><entry><title>Go语言使用channel进行goroutine通信</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-15-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%BD%BF%E7%94%A8channel%E8%BF%9B%E8%A1%8Cgoroutine%E9%80%9A%E4%BF%A1/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[声明channel channel是go语言中的一种数据类型，也叫通道 声明方式
ch:=make(chan string, n) ch : channel的变量名 chan : 声明channel的关键字 string : channel中存储额数据类型 n: 缓冲长度(不填时代表无缓冲) 如果给一个 nil 的 channel 发送数据，会造成永远阻塞。
如果从一个 nil 的 channel 中接收数据，也会造成永久阻塞。 给一个已经关闭的 channel 发送数据，会引起 panic
从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零 值。 无缓冲的 channel 是同步的，而有缓冲的 channel 是非同步的。
channel的操作 1.发送数据
ch &lt;- &#34;你好&#34; 2.接受数据
str := &lt;-ch fmt.Println(str) // 你好 3.测试
func main() { ch := make(chan string, 3) // 3 是指channel的缓冲长度为3 i := 0 go func() { for ; i &lt; 10; i++ { ch &lt;- strconv.Itoa(i) log.Println(&#34;向ch中-&gt;发送了 &#34;, i, &#34;此时ch的长度为：&#34;, len(ch)) } }() go func() { for { time.Sleep(time.Second * 2) log.Println(&#34;在ch中&lt;-取出了 &#34;, &lt;-ch, &#34;此时ch的长度为:&#34;, len(ch)) } }() for { time.Sleep(time.Second * 3) if len(ch) == 0 { break } } } 输出结果： 2022/08/15 11:25:28 向ch中-&gt;发送了 0 此时ch的长度为： 1 2022/08/15 11:25:28 向ch中-&gt;发送了 1 此时ch的长度为： 2 2022/08/15 11:25:28 向ch中-&gt;发送了 2 此时ch的长度为： 3 2022/08/15 11:25:30 在ch中&lt;-取出了 0 此时ch的长度为: 3 2022/08/15 11:25:30 向ch中-&gt;发送了 3 此时ch的长度为： 3 2022/08/15 11:25:32 向ch中-&gt;发送了 4 此时ch的长度为： 3 2022/08/15 11:25:32 在ch中&lt;-取出了 1 此时ch的长度为: 3 2022/08/15 11:25:34 在ch中&lt;-取出了 2 此时ch的长度为: 3 2022/08/15 11:25:34 向ch中-&gt;发送了 5 此时ch的长度为： 3 2022/08/15 11:25:36 在ch中&lt;-取出了 3 此时ch的长度为: 3 2022/08/15 11:25:36 向ch中-&gt;发送了 6 此时ch的长度为： 3 2022/08/15 11:25:38 在ch中&lt;-取出了 4 此时ch的长度为: 3 2022/08/15 11:25:38 向ch中-&gt;发送了 7 此时ch的长度为： 3 2022/08/15 11:25:40 在ch中&lt;-取出了 5 此时ch的长度为: 3 2022/08/15 11:25:40 向ch中-&gt;发送了 8 此时ch的长度为： 3 2022/08/15 11:25:42 在ch中&lt;-取出了 6 此时ch的长度为: 3 2022/08/15 11:25:42 向ch中-&gt;发送了 9 此时ch的长度为： 3 2022/08/15 11:25:44 在ch中&lt;-取出了 7 此时ch的长度为: 2 2022/08/15 11:25:46 在ch中&lt;-取出了 8 此时ch的长度为: 1 2022/08/15 11:25:48 在ch中&lt;-取出了 9 此时ch的长度为: 0 4.结果解析
在第一个匿名函数中向channel中发送数据 由于ch的缓冲长度只有3 所以在 11:25:28 这一秒内连续发送了3个字符串进去后ch就开始阻塞
2秒后第二个匿名函数的Sleep结束开始在ch中取数据,取出一个数据后ch不再阻塞，有一个空闲位置，然后第一个匿名函数再往ch中写入一个数据就再次进入阻塞状态
就这样每2秒就取出一个数据然后再写入数据直到11:25:42 此时第一个匿名函数的for循环已经结束，第一个匿名函数已经执行完成了，第二个匿名函数仍在每2秒读取数据，此时ch的长度就开始减少了直到最后长度为0 程序退出
select的使用 假设要从网上下载一个文件，我启动了 3 个 goroutine 进行下载，并把结果发送到 3 个 channel 中。其中，哪个先下载好，就会使用哪个 channel 的结果。这样我怎么知道才能知道那个channel中线有数据呢？通过下面的代码架构实现
select { case i1 = &lt;-c1: //todo case i2 &lt;- c2: //todo default: // default todo } 下面实现刚才的模拟下载的代码
func downloadFile(chanName string) string { //模拟下载文件,可以自己随机time.Sleep点时间试试 rand.Seed(time.Now().Unix()) time.Sleep(time.Second * time.Duration(rand.Intn(5))) return chanName + &#34;:filePath&#34; } func main() { firstCh := make(chan string) secondCh := make(chan string) threeCh := make(chan string) //同时开启3个goroutine下载 go func() { firstCh &lt;- downloadFile(&#34;firstCh&#34;) }() go func() { secondCh &lt;- downloadFile(&#34;secondCh&#34;) }() go func() { threeCh &lt;- downloadFile(&#34;threeCh&#34;) }() //开始select多路复用，哪个channel能获取到值， var finalPath string //就说明哪个最先下载好，就用哪个。 select { case filePath := &lt;-firstCh: finalPath = filePath case filePath := &lt;-secondCh: finalPath = filePath case filePath := &lt;-threeCh: finalPath = filePath } fmt.Println(finalPath) } ]]></content></entry><entry><title>Go语言错误处理笔记</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-14-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[type error interface { Error() string } 一、常见的使用方法 func add(a, b int) (int, error) { if a &lt; 0 || b &lt; 0 { return 0, errors.New(&#34;传入参数不能为负数&#34;) } return a + b, nil } func main() { sum, err := add(1, -2) if err != nil { fmt.Println(err) } else { fmt.Println(sum) } } 二、Error Wrapping func main() { e := errors.New(&#34;原始error&#34;) e1 := fmt.Errorf(&#34;Wrap一个error:%w&#34;, e) fmt.Println(e1) // Wrap一个error:原始error } 使用这种方式可以对原有的error进行修饰 errors.Unwrap(e error) 可以获取被嵌套的error
func main() { e := errors.New(&#34;原始error&#34;) e1 := fmt.Errorf(&#34;Wrap一个error:%w&#34;, e) e2 := errors.Unwrap(e1) fmt.Println(e2) //原始error } errors.IS(e1,e2 error) 可以判断被嵌套的error是不是原有的error
func main() { e := errors.New(&#34;原始error&#34;) e1 := fmt.Errorf(&#34;Wrap一个error:%w&#34;, e) fmt.Println(errors.Is(e, e1)) //false e2 := fmt.Errorf(&#34;又Wrap一个error:%w&#34;, e1) fmt.Println(errors.Is(e2, e1)) //true fmt.Println(errors.Is(e2, e)) //true } ]]></content></entry><entry><title>Go语言接口学习笔记</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-14-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E6%8E%A5%E5%8F%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[一、接口的定义 接口是和调用方的一种约定 是一个高度抽象的类型 不同和具体的实现细节绑定在一起
示例代码： type Person interface { //定义一个Person接口 Speak(msg string) Walk() } type Student struct { name string } type Teacher struct { name string } /** Student实现Person接口的两个方法 */ func (s Student) Speak(msg string) { fmt.Println(s.name, &#34; say &#34;, msg) } func (s Student) Walk() { fmt.Println(s.name, &#34; 会走路 &#34;) } func (t Teacher) Speak(msg string) { fmt.Println(t.name, &#34; say &#34;, msg) } func (t Teacher) Walk() { fmt.Println(t.name, &#34; 会走路 &#34;) } func main() { var p1 Person = Student{name: &#34;小明&#34;} var p2 Person = Teacher{name: &#34;王老师&#34;} p1.Speak(&#34;老师好&#34;) p2.Speak(&#34;同学们好&#34;) } 二、解释说明 一个类型实现了一个接口的所有方法就说明这个类型实现了这个接口
接口就是一个需要实现的方法列表
当我们使用指针实现接口时，只有指针类型的变量才会实现该接口；当我们使用结构体实现接口时，指针类型和结构体类型都会实现该接口。
三、空接口 空interface(interface{})不包含任何的method，正因为如此，所有的类型都实现了空interface
作为数据容器时，空interface可以存储任意类型的数值。
interface{} 类型不是任意类型
空接口作为函数参数 func show(a interface{}) { fmt.Printf(&#34;type:%T value:%v\n&#34;, a, a) } func main() { show(555) show(float64(5.1234567890123456789)) show(float32(5.123456789)) show(&#34;hello&#34;) } //运行结果 type:int value:555 type:float64 value:5.123456789012345 type:float32 value:5.123457 type:string value:hello float32 和 float64 Go语言中提供了两种精度的浮点数 float32 和 float64。
float32，也即我们常说的单精度，存储占用4个字节，也即4*8=32位，其中1位用来符号，8位用来指数，剩下的23位表示尾数
float64，也即我们熟悉的双精度，存储占用8个字节，也即8*8=64位，其中1位用来符号，11位用来指数，剩下的52位表示尾数
那么精度是什么意思？有效位有多少位？
精度主要取决于尾数部分的位数。
对于 float32（单精度）来说，表示尾数的为23位，除去全部为0的情况以外，最小为2-23，约等于1.19*10-7，所以float小数部分只能精确到后面6位，加上小数点前的一位，即有效数字为7位。
同理 float64（单精度）的尾数部分为 52位，最小为2-52，约为2.22*10-16，所以精确到小数点后15位，加上小数点前的一位，有效位数为16位。
空接口作为map值 var studentInfo = make(map[string]interface{}) studentInfo[&#34;name&#34;] = &#34;Wilen&#34; studentInfo[&#34;age&#34;] = 18 studentInfo[&#34;married&#34;] = false fmt.Println(studentInfo) //map[age:18 married:false name:Wilen] //例如gin框架的gin.H{} 四、注意事项 只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要定义接口。不要为了接口而写接口，那样只会增加不必要的抽象，导致不必要的运行时损耗。
]]></content></entry><entry><title>Go语言中函数和方法的区别</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-14-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%B8%AD%E5%87%BD%E6%95%B0%E5%92%8C%E6%96%B9%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[一、函数 1.举个🌰 func sum(a,b int) int{ return a+b } func ： 关键字func
sum ：函数名
(a,b int) int：可以传入两个int类型的形参，返回值为int类型
2.多返回值 func sumAndsub(a,b int) （int,int){ return a+b,a-b } func main(){ sum,sub:=sumAndsub(5,3) fmt.Println(sum,sub) // 8 2 } 3.可变参数 // 可变参数列表需在参数列表中的最后一位，且为切片类型 func operation(op string, params ...int) int { result := 0 switch { case op == &#34;+&#34;: for _, v := range params { result += v } case op == &#34;*&#34;: result = 1 for _, v := range params { result *= v } } return result } func main() { result1 := operation(&#34;+&#34;, 1, 2, 3, 4) result2 := operation(&#34;*&#34;, 1, 2, 3, 4) fmt.Println(result1) // 10 fmt.Println(result2) // 24 } //运行结果 params的类型为[]int params的类型为[]int 10 24 4.匿名函数 func creatFunc1() func() int { i := 0 return func() int { i++ return i } } func creatFunc2() func() int { i := 0 return func() int { defer func() { i++ }() return i } } func main() { addFunc1 := creatFunc1() fmt.Println(addFunc1()) fmt.Println(addFunc1()) fmt.Println(addFunc1()) fmt.Println(&#34;===============&#34;) addFunc2 := creatFunc2() fmt.Println(addFunc2()) fmt.Println(addFunc2()) fmt.Println(addFunc2()) } 运行结果： 1 2 3 =============== 0 1 2 二、方法 type rectangle struct { long int width int } func (r rectangle) getArea() int { return r.long * r.width } func (r rectangle) getGirth() int { return (r.long + r.width) * 2 } func main() { r := rectangle{ long: 3, width: 4, } fmt.Println(r.getArea()) fmt.Println(r.getGirth()) fmt.Println(&#34;=============&#34;) ga := rectangle.getArea fmt.Println(ga(r)) gg := rectangle.getGirth fmt.Println(gg(r)) } 运行结果： 12 14 ============= 12 14 三、总结 二者概念基本相同,区别是二者所属的对象不同
函数属于包,方法属于类型
]]></content></entry><entry><title>记录一个集合相关算法的实现代码</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-08-13-%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E9%9B%86%E5%90%88%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81/</url><categories><category>技巧</category></categories><tags><tag>code</tag></tags><content type="html"><![CDATA[算法说明 讨论个算法 场景一 集合一：1、3 集合二：3、4、5 如何得到 集合 1、4、5 场景二 集合一：1、2、3 集合二：2、3、3、4、5 如何得到 集合 1、3、4、5 文字描述 同事A算法 合并两个集合后将出现偶数次的元素剔除 同事B算法 遍历两个集合，把每个元素出现的次数通过map&lt;元素，次数&gt;记录下来，最后遍历map，把次数为偶数的删除，剩下的拿出来所有的key就是需要的集合 合并两个集合并排序，然后一次遍历去掉重复的元素
代码实现 package main import ( &#34;fmt&#34; &#34;sort&#34; ) func func1(a, b []int) (stack []int) { c := append(a, b...) sort.Ints(c) for _, v := range c { if len(stack) == 0 { stack = append(stack, v) continue } if v != stack[len(stack)-1] { stack = append(stack, v) } else { stack = stack[:len(stack)-1] } } return } func func2(a, b []int) (c []int) { mp := make(map[int]int) for _, n := range append(a, b...) { if _, ok := mp[n]; ok { mp[n]++ } else { mp[n] = 1 } } for k, v := range mp { if v%2 != 0 { c = append(c, k) } } return } func func3(a, b []int) (c []int) { t := append(a, b...) sort.Ints(t) for i := 0; i &lt; len(t); i++ { if i != len(t)-1 &amp;&amp; t[i] == t[i+1] { i++ } else { c = append(c, t[i]) } } return } func main() { var a = []int{1, 1, 2, 3, 5, 6, 9, 78, 5} var b = []int{3, 2, 5, 85, 7, 7, 7, 8, 6, 6, 4} fmt.Println(&#34;func1: &#34;, func1(a, b)) c := func2(a, b) fmt.Println(&#34;func2: &#34;, c) sort.Ints(c) fmt.Println(&#34;func2[sort]:&#34;, c) fmt.Println(&#34;func3: &#34;, func3(a, b)) } 运行结果// func1: [4 5 6 7 8 9 78 85] func2: [6 78 85 5 9 7 8 4] func2[sort]: [4 5 6 7 8 9 78 85] func3: [4 5 6 7 8 9 78 85] ]]></content></entry><entry><title>About Me</title><url>/about.html</url><categories/><tags/><content type="html">学习笔记！</content></entry><entry><title>【转】理解MVCC机制</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-11-%E7%90%86%E8%A7%A3mvcc%E6%9C%BA%E5%88%B6/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">理解MVCC机制的前奏：undo log版本链是个什么东西？ 简单来说呢，我们每条数据其实都有两个隐藏字段，一个是trx_id，一个是roll_pointer，这个trx_id就是最近一次更新这条数据的事务id，roll_pointer就是指向你了你更新这个事务之前生成的undo log
我们给大家举个例子，现在假设有一个事务A（id=50），插入了一条数据，那么此时这条数据的隐藏字段以及指向的undo log如下图所示，插入的这条数据的值是值A，因为事务A的id是50，所以这条数据的txr_id就是50，roll_pointer指向一个空的undo log，因为之前这条数据是没有的。
接着假设有一个事务B跑来修改了一下这条数据，把值改成了值B ，事务B的id是58，那么此时更新之前会生成一个undo log记录之前的值，然后会让roll_pointer指向这个实际的undo log回滚日志，如下图所示。
大家看上图是不是觉得很有意思？事务B修改了值为值B，此时表里的那行数据的值就是值B了，那行数据的txr_id就是事务B的id，也就是58，roll_pointer指向了undo log，这个undo log就记录你更新之前的那条数据的值。
所以大家看到roll_pointer指向的那个undo log，里面的值是值A，txr_id是50，因为undo log里记录的这个值是事务A插入的，所以这个undo log的txr_id就是50，我还特意把表里的那行数据和undo log的颜色弄成不一样的，以示区分。
接着假设事务C又来修改了一下这个值为值C，他的事务id是69，此时会把数据行里的txr_id改成69，然后生成一条undo log，记录之前事务B修改的那个值
我们在上图可以清晰看到，数据行里的值变成了值C，txr_id是事务C的id，也就是69，然后roll_pointer指向了本次修改之前生成的undo log，也就是记录了事务B修改的那个值，包括事务B的id，同时事务B修改的那个undo log还串联了最早事务A插入的那个undo log，如图所示，过程很清晰明了。
所以这就是今天要给大家讲的一点，大家先不管多个事务并发执行是如何执行的，起码先搞清楚一点，就是多个事务串行执行的时候，每个人修改了一行数据，都会更新隐藏字段txr_id和roll_pointer，同时之前多个数据快照对应的undo log，会通过roll_pinter指针串联起来，形成一个重要的版本链！
基于undo log多版本链条实现的ReadView机制，到底是什么？ 执行一个事务的时候，就给你生成一个ReadView，里面比较关键的东西有4个
一个是m_ids，这个就是说此时有哪些事务在MySQL里执行还没提交的； 一个是min_trx_id，就是m_ids里最小的值； 一个是max_trx_id，这是说mysql下一个要生成的事务id，就是最大事务id； 一个是creator_trx_id，就是你这个事务的id 那么现在我们来举个例子，让大家通过例子来理解这个ReadView是怎么用的
假设原来数据库里就有一行数据，很早以前就有事务插入过了，事务id是32，他的值就是初始值，如下图所示。
接着呢，此时两个事务并发过来执行了，一个是事务A（id=45），一个是事务B（id=59），事务B是要去更新这行数据的，事务A是要去读取这行数据的值的，此时两个事务如下图所示。
现在事务A直接开启一个ReadView，这个ReadView里的m_ids就包含了事务A和事务B的两个id，45和59，然后min_trx_id就是45，max_trx_id就是60，creator_trx_id就是45，是事务A自己。
这个时候事务A第一次查询这行数据，会走一个判断，就是判断一下当前这行数据的txr_id是否小于ReadView中的min_trx_id，此时发现txr_id=32，是小于ReadView里的min_trx_id就是45的，说明你事务开启之前，修改这行数据的事务早就提交了，所以此时可以查到这行数据，如下图所示。
接着事务B开始动手了，他把这行数据的值修改为了值B，然后这行数据的txr_id设置为自己的id，也就是59，同时roll_pointer指向了修改之前生成的一个undo log，接着这个事务B就提交了，如下图所示。
这个时候事务A再次查询，此时查询的时候，会发现一个问题，那就是此时数据行里的txr_id=59，那么这个txr_id是大于ReadView里的min_txr_id(45)，同时小于ReadView里的max_trx_id（60）的，说明更新这条数据的事务，很可能就跟自己差不多同时开启的，于是会看一下这个txr_id=59，是否在ReadView的m_ids列表里？
果然，在ReadView的m_ids列表里，有45和59两个事务id，直接证实了，这个修改数据的事务是跟自己同一时段并发执行然后提交的，所以对这行数据是不能查询的！
那么既然这行数据不能查询，那查什么呢？
简单，顺着这条数据的roll_pointer顺着undo log日志链条往下找，就会找到最近的一条undo log，trx_id是32，此时发现trx_id=32，是小于ReadView里的min_trx_id（45）的，说明这个undo log版本必然是在事务A开启之前就执行且提交的。
好了，那么就查询最近的那个undo log里的值好了，这就是undo log多版本链条的作用，他可以保存一个快照链条，让你可以读到之前的快照值，如下图。
看到这里，大家有没有觉得很奇妙？多个事务并发执行的时候，事务B更新的值，通过这套ReadView+undo log日志链条的机制，就可以保证事务A不会读到并发执行的事务B更新的值，只会读到之前最早的值。
接着假设事务A自己更新了这行数据的值，改成值A，trx_id修改为45，同时保存之前事务B修改的值的快照，如下图所示。
此时事务A来查询这条数据的值，会发现这个trx_id=45，居然跟自己的ReadView里的creator_trx_id（45）是一样的，说明什么？
说明这行数据就是自己修改的啊！自己修改的值当然是可以看到的了！如下图。
接着在事务A执行的过程中，突然开启了一个事务C，这个事务的id是78，然后他更新了那行数据的值为值C，还提交了，如下图所示。
这个时候事务A再去查询，会发现当前数据的trx_id=78，大于了自己的ReadView中的max_trx_id（60），此时说明什么？
说明是这个事务A开启之后，然后有一个事务更新了数据，自己当然是不能看到的了！
此时就会顺着undo log多版本链条往下找，自然先找到值A自己之前修改的过的那个版本，因为那个trx_id=45跟自己的ReadView里的creator_trx_id是一样的，所以此时直接读取自己之前修改的那个版本，如下图。
通过undo log多版本链条，加上你开启事务时候生产的一个ReadView，然后再有一个查询的时候，根据ReadView进行判断的机制，你就知道你应该读取哪个版本的数据。
而且他可以保证你只能读到你事务开启前，别的提交事务更新的值，还有就是你自己事务更新的值。假如说是你事务开启之前，就有别的事务正在运行，然后你事务开启之后 ，别的事务更新了值，你是绝对读不到的！或者是你事务开启之后，比你晚开启的事务更新了值，你也是读不到的！
通过这套机制就可以实现多个事务并发执行时候的数据隔离。
Read Committed隔离级别是如何基于ReadView机制实现的？ RC隔离级别，实际上意思就是说你事务运行期间，只要别的事务修改数据还提交了，你就是可以读到人家修改的数据的，所以是会发生不可重复读的问题，包括幻读的问题，都会有的。
所谓的ReadView机制，之前我们讲过，他是基于undo log版本链条实现的一套读视图机制，他意思就是说你事务生成一个ReadView，然后呢，如果是你事务自己更新的数据，自己是可以读到的，或者是在你生成ReadView之前提交的事务修改的值，也是可以读取到的。但是如果是你生成ReadView的时候，就已经活跃的事务，在你生成ReadView之后修改了数据，接着提交了，此时你是读不到的，或者是你生成ReadView以后再开启的事务修改了数据，还提交了，此时也是读不到的。
如何基于ReadView机制来实现RC隔离级别呢？
其实这里的一个非常核心的要点在于，当你一个事务设置他处于RC隔离级别的时候，他是每次发起查询，都重新生成一个ReadView！
首先假设我们的数据库里有一行数据，是事务id=50的一个事务之前就插入进去的，然后现在呢，活跃着两个事务，一个是事务A（id=60），一个是事务B（id=70），此时如下图所示。
现在的情况就是，事务B发起了一次update操作，更新了这条数据，把这条数据的值修改为了值B，所以此时数据的trx_id会变为事务B的id=70，同时会生成一条undo log，由roll_pointer来指向，看下图：
这个时候，事务A要发起一次查询操作，此时他一发起查询操作，就会生成一个ReadView，此时ReadView里的min_trx_id=60，max_trx_id=71，creator_trx_id=60，此时如下图所示。
这个时候事务A发起查询，发现当前这条数据的trx_id是70。也就是说，属于ReadView的事务id范围之间，说明是他生成ReadView之前就有这个活跃的事务，是这个事务修改了这条数据的值，但是此时这个事务B还没提交，所以ReadView的m_ids活跃事务列表里，是有[60, 70]两个id的，所以此时根据ReadView的机制，此时事务A是无法查到事务B修改的值B的。
接着就顺着undo log版本链条往下查找，就会找到一个原始值，发现他的trx_id是50，小于当前ReadView里的min_trx_id，说明是他生成ReadView之前，就有一个事务插入了这个值并且早就提交了，因此可以查到这个原始值，如下图。
接着，咱们假设事务B此时就提交了，好了，那么提交了就说明事务B不会活跃于数据库里了，是不是？可以的，大家一定记住，事务B现在提交了。那么按照RC隔离级别的定义，事务B此时一旦提交了，说明事务A下次再查询，就可以读到事务B修改过的值了，因为事务B提交了。
那么到底怎么让事务A能够读到提交的事务B修改过的值呢？
很简单，就是让事务A下次发起查询，再次生成一个ReadView。此时再次生成ReadView，数据库内活跃的事务只有事务A了，因此min_trx_id是60，mac_trx_id是71，但是m_ids这个活跃事务列表里，只会有一个60了，事务B的id=70不会出现在m_ids活跃事务列表里了，如下图。
此时事务A再次基于这个ReadView去查询，会发现这条数据的trx_id=70，虽然在ReadView的min_trx_id和max_trx_id范围之间，但是此时并不在m_ids列表内，说明事务B在生成本次ReadView之前就已经提交了。
那么既然在生成本次ReadView之前，事务B就已经提交了，就说明这次你查询就可以查到事务B修改过的这个值了，此时事务A就会查到值B，如下图所示。
到此为止，RC隔离级别如何实现的，大家应该就理解了，他的关键点在于每次查询都生成新的ReadView，那么如果在你这次查询之前，有事务修改了数据还提交了，你这次查询生成的ReadView里，那个m_ids列表当然不包含这个已经提交的事务了，既然不包含已经提交的事务了，那么当然可以读到人家修改过的值了。
MySQL最牛的RR隔离级别，是如何基于ReadView机制实现的？ 今天来接着给大家讲解，MySQL中最牛的RR隔离级别，是如何同时避免不可重复读问题和幻读问题的。
其实大家现在应该都知道，在MySQL中让多个事务并发运行的时候能够互相隔离，避免同时读写一条数据的时候有影响，是依托undo log版本链条和ReadView机制来实现的。
上次我们都讲过了，基于ReadView机制可以实现RC隔离级别，即你每次查询的时候都生成一个ReadView，这样的话，只要在你这次查询之前有别的事务提交了，那么别的事务更新的数据，你是可以看到的。
那么如果是RR级别呢？RR级别下，你这个事务读一条数据，无论读多少次，都是一个值，别的事务修改数据之后哪怕提交了，你也是看不到人家修改的值的，这就避免了不可重复读的问题。
同时如果别的事务插入了一些新的数据，你也是读不到的，这样你就可以避免幻读的问题。
那么到底是如何实现的呢？我们今天来看看。
首先我们还是假设有一条数据是事务id=50的一个事务插入的，同时此时有事务A和事务B同时在运行，事务A的id是60，事务B的id是70，如下图所示。
这个时候，事务A发起了一个查询，他就是第一次查询就会生成一个ReadView，此时ReadView里的creator_trx_id是60，min_trx_id是60，max_trx_id是71，m_ids是[60, 70]，此时ReadView如下图所示。
这个时候事务A基于这个ReadView去查这条数据，会发现这条数据的trx_id为50，是小于ReadView里的min_trx_id的，说明他发起查询之前，早就有事务插入这条数据还提交了，所以此时可以查到这条原始值的，如下图。
接着就是事务B此时更新了这条数据的值为值B，此时会修改trx_id为70，同时生成一个undo log，而且关键是事务B此时他还提交了，也就是说此时事务B已经结束了，如下图所示。
这个时候大家思考一个问题，ReadView中的m_ids此时还会是60和70吗？
那必然是的，因为ReadView一旦生成了就不会改变了，这个时候虽然事务B已经结束了，但是事务A的ReadView里，还是会有60和70两个事务id。
他的意思其实就是，在你事务A开启查询的时候，事务B当时是在运行的，就是这个意思。
那么好，接着此时事务A去查询这条数据的值，他会惊讶的发现此时数据的trx_id是70了，70一方面是在ReadView的min_trx_id和max_trx_id的范围区间的，同时还在m_ids列表中
这说明什么？
说明起码是事务A开启查询的时候，id为70的这个事务B还是在运行的，然后由这个事务B更新了这条数据，所以此时事务A是不能查询到事务B更新的这个值的，因此这个时候继续顺着指针往历史版本链条上去找，如下图。
接着事务A顺着指针找到下面一条数据，trx_id为50，是小于ReadView的min_trx_id的，说明在他开启查询之前，就已经提交了这个事务了，所以事务A是可以查询到这个值的，此时事务A查到的是原始值，如下图。
大家看到这里有什么感想？是不是感觉到这一下子就避免了不可重复读的问题？
你事务A多次读同一个数据，每次读到的都是一样的值，除非是他自己修改了值，否则读到的一直会一样的值。
不管别的事务如何修改数据，事务A的ReadView始终是不变的，他基于这个ReadView始终看到的值是一样的！
接着我们来看看幻读的问题他是如何解决的。假设现在事务A先用select * from x where id&amp;gt;10来查询，此时可能查到的就是一条数据，而且读到的是这条数据的原始值的那个版本，至于原因，上面都解释过了，如下图。
现在有一个事务C插入了一条数据，然后提交了，此时如下图所示。
接着，此时事务A再次查询，此时会发现符合条件的有2条数据，一条是原始值那个数据，一条是事务C插入的那条数据，但是事务C插入的那条数据的trx_id是80，这个80是大于自己的ReadView的max_trx_id的，说明是自己发起查询之后，这个事务才启动的，所以此时这条数据是不能查询的。
因此事务A本次查询，还是只能查到原始值一条数据，如下图。
所以大家可以看到，在这里，事务A根本不会发生幻读，他根据条件范围查询的时候，每次读到的数据都是一样的，不会读到人家插入进去的数据，这都是依托ReadView机制实现的！
梳理一下数据库的多事务并发运行的隔离机制 今天给大家简单梳理一下MySQL中的多事务并发运行的隔离原理，其实这套隔离原理，说白了就是MVCC机制，也就是multi-version concurrent control，就是多版本并发控制机制，专门控制多个事务并发运行的时候，互相之间会如何影响。
首先我们先要明白，多个事务并发运行的时候，同时读写一个数据，可能会出现脏写、脏读、不可重复读、幻读几个问题
所谓的脏写，就是两个事务都更新一个数据，结果有一个人回滚了把另外一个人更新的数据也回滚没了。
脏读，就是一个事务读到了另外一个事务没提交的时候修改的数据，结果另外一个事务回滚了，下次读就读不到了。
不可重复读，就是多次读一条数据，别的事务老是修改数据值还提交了，多次读到的值不同。
幻读，就是范围查询，每次查到的数据不同，有时候别的事务插入了新的值，就会读到更多的数据。
针对这些问题，所以才有RU、RC、RR和串行四个隔离级别
RU隔离级别，就是可以读到人家没提交的事务修改的数据，只能避免脏写问题；
RC隔离级别，可以读到人家提交的事务修改过的数据，可以避免脏写和脏读问题。
RR是不会读到别的已经提交事务修改的数据，可以避免脏读、脏写和不可重复读的问题；
串行是让事务都串行执行，可以避免所有问题。
然后MySQL实现MVCC机制的时候，是基于undo log多版本链条+ReadView机制来做的，默认的RR隔离级别，就是基于这套机制来实现的，依托这套机制实现了RR级别，除了避免脏写、脏读、不可重复读，还能避免幻读问题。因此一般来说我们都用默认的RR隔离级别就好了
这就是数据库的隔离机制以及底层的原理，希望大家好好理解，可以复习一下之前的内容，把这套机制理解清楚了，接下来我们就要开始讲解锁机制了。
锁机制，解决的就是多个事务同时更新一行数据，此时必须要有一个加锁的机制</content></entry><entry><title>【转】SQL标准中对事务的4个隔离级别</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-11-sql%E6%A0%87%E5%87%86%E4%B8%AD%E5%AF%B9%E4%BA%8B%E5%8A%A1%E7%9A%844%E4%B8%AA%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">SQL标准中对事务的4个隔离级别 这4种级别包括了：
**read uncommitted（读未提交）**不允许发生脏写,也就是说，不可能两个事务在没提交的情况下去更新同一行数据的值，但是在这种隔离级别下，可能发生脏读，不可重复读，幻读。
**read committed（读已提交）这个级别下，不会发生脏写和脏读,也就是说，人家事务没提交的情况下修改的值，你是绝对读不到的！但是呢，可能会发生不可重复读和幻读问题，因为一旦人家事务修改了值然后提交了，你事务是会读到的，所以可能你多次读到的值是不同的！有点骚气的简写名词，就是RC，一般如果你在公司里做开发，有个其他团队的兄弟讨论技术方案的时候，跟你来了句，把事务隔离级别设置成RC！这个时候你不要目瞪口呆，知道是读已提交级别就行了。
***repeatable read（可重复读）***这个级别下，不会发生脏写、脏读和不可重复读的问题，因为你一个事务多次查询一个数据的值，哪怕别的事务修改了这个值还提交了，没用，你不会读到人家提交事务修改过的值，你事务一旦开始，多次查询一个值，会一直读到同一个值！RR级别保证你不会读到人家已经提交的事务修改过的值！但是他还是会发生幻读的
**serializable（串行化）**这种级别，根本就不允许你多个事务并发执行，只能串行起来执行，先执行事务A提交，然后执行事务B提交，接着执行事务C提交，所以此时你根本不可能有幻读的问题，因为事务压根儿都不并发执行！
但是这种级别一般除非脑子坏了，否则更不可能设置了，因为多个事务串行，那数据库很可能一秒并发就只有几十了，性能会极差的。
MySQL是如何支持4种事务隔离级别的？Spring事务注解是如何设置的？ MySQL默认设置的事务隔离级别，都是RR级别的，而且MySQL的RR级别是可以避免幻读发生的。
这点是MySQL的RR级别的语义跟SQL标准的RR级别不同的，毕竟SQL标准里规定RR级别是可以发生幻读的，但是MySQL的RR级别避免了！
也就是说，MySQL里执行的事务，默认情况下不会发生脏写、脏读、不可重复读和幻读的问题，事务的执行都是并行的，大家互相不会影响，我不会读到你没提交事务修改的值，即使你修改了值还提交了，我也不会读到的，即使你插入了一行值还提交了，我也不会读到的，总之，事务之间互相都完全不影响！
当然，要做到这么神奇和牛叉的效果，MySQL是下了苦功夫的，后续我们接着就要讲解MySQL里的MVCC机制，就是多版本并发控制隔离机制，依托这个MVCC机制，就能让RR级别避免不可重复读和幻读的问题。
然后给大家说一下，假设你要修改MySQL的默认事务隔离级别，是下面的命令，可以设置级别为不同的level，level的值可以是REPEATABLE READ，READ COMMITTED，READ UNCOMMITTED，SERIALIZABLE几种级别。
SET [GLOBAL|SESSION] TRANSACTION ISOLATION LEVEL level;
但是一般来说，真的其实不用修改这个级别，就用默认的RR其实就特别好，保证你每个事务跑的时候都没人干扰，何乐而不为呢？
另外，给大家说一下，假设你在开发业务系统的时候，比如用Spring里的@Transactional注解来做事务这块，假设某个事务你就是有点手痒痒，就想给弄成RC级别，你就想读到人家已经提交事务修改过的值，好，那么没问题。
在@Transactional注解里是有一个isolation参数的，里面是可以设置事务隔离级别的，具体的设置方式如下：
@Transactional(isolation=Isolation.DEFAULT)，然后默认的就是DEFAULT值，这个就是MySQL默认支持什么隔离级别就是什么隔离级别。
那MySQL默认是RR级别，自然你开发的业务系统的事务也都是RR级别的了。
但是你可以手动改成Isolation.READ_UNCOMMITTED级别，此时你就可以读到人家没提交事务修改的值了，够坑的！估计一般没人自己坑自己吧！
也可以改成Isolation.READ_COMMITTED，Isolation.REPEATABLE_READ，Isolation.SERIALIZABLE几个级别，都是可以的。
但是再次提醒，其实默认的RR隔离机制挺好的，真的没必要去修改，除非你一定要在你的事务执行期间多次查询的时候，必须要查到别的已提交事务修改过的最新值，那么此时你的业务有这个要求，你就把Spring的事务注解里的隔离级别设置为Isolation.READ_COMMITTED级别，偶尔可能也是有这种需求的。</content></entry><entry><title>【转】什么是脏写、脏读、不可重复读和幻读？</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-10-%E4%BB%80%E4%B9%88%E6%98%AF%E8%84%8F%E5%86%99%E8%84%8F%E8%AF%BB%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E5%92%8C%E5%B9%BB%E8%AF%BB/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">多个事务并发执行时候的另外两种问题：一个是不可重复读，一个是幻读 多个事务并发执行时候，对MySQL的缓存页里的同一行数据同时进行更新或者查询的时候，可能发生的脏写和脏读的问题
先来说说这个不可重复读的问题，这个问题是这样的：假设我们有一个事务A开启了，在这个事务A里会多次对一条数据进行查询
然后呢，另外有两个事务，一个是事务B，一个是事务C，他们俩都是对一条数据进行更新的。
然后我们假设一个前提，就是比如说事务B更新数据之后，如果还没提交，那么事务A是读不到的，必须要事务B提交之后，他修改的值才能被事务A给读取到，其实这种情况下，就是我们首先避免了脏读的发生。
因为脏读的意思就是事务A可以读到事务B修改过还没提交的数据，此时事务B一旦回滚，事务A再次读就读不到了，那么此时就会发生脏读问题。
我们现在假设的前提是事务A只能在事务B提交之后读取到他修改的数据，所以此时必然是不会发生脏读的
好了，但是你以为没有脏读就万事大吉了吗？绝对不是，此时会有另外一个问题，叫做不可重复读
假设缓存页里一条数据原来的值是A值，此时事务A开启之后，第一次查询这条数据，读取到的就是A值。
接着事务B更新了那行数据的值为B值，同时事务B立马提交了，然后事务A此时可是还没提交！
大家注意，此时事务A是没提交的，他在事务执行期间第二次查询数据，此时查到的是事务B修改过的值，B值，因为事务B已经提交了，所以事务A可以读到的了，
紧接着事务C再次更新数据为C值，并且提交事务了，此时事务A在没提交的情况下，第三次查询数据，查到的值为C值，
好，那么上面的场景有什么问题呢？
其实要说没问题也可以是没问题，毕竟事务B和事务C都提交之后，事务A多次查询查到他们修改的值，是ok的。
但是你要说有问题，也可以是有问题的，就是事务A可能第一次查询到的是A值，那么他可能希望的是在事务执行期间，如果多次查询数据，都是同样的一个A值，他希望这个A值是他重复读取的时候一直可以读到的！他希望这行数据的值是可重复读的！
但是此时，明显A值不是可重复读的，因为事务B和事务C一旦更新了值并且提交了，事务A会读到别的值，所以此时这行数据的值是不可重复读的！此时对于你来说，这个不可重复读的场景，就是一种问题了！
上面描述的，其实就是不可重复读的问题，其实这个问题你说是问题也不一定就是什么大问题，但是说他有问题，确实是有问题的。
因为这取决于你自己想要数据库是什么样子的，如果你希望看到的场景就是不可重复读，也就是事务A在执行期间多次查询一条数据，每次都可以查到其他已经提交的事务修改过的值，那么就是不可重复读的，如果你希望这样子，那也没问题。
但是如果你希望的是，假设你事务A刚开始执行，第一次查询读到的是值A，然后后续你希望事务执行期间，读到的一直都是这个值A，不管其他事务如何更新这个值，哪怕他们都提交了，你就希望你读到的一直是第一次查询到的值A，那么你就是希望可重复读的。
如果你期望的是可重复读，但是数据库表现的是不可重复读，让你事务A执行期间多次查到的值都不一样，都是别的提交过的事务修改过的值，那么此时你就可以认为，数据库有问题，这个问题就是“不可重复读”的问题！
不可重复读简单来说，就是一个事务多次查询一条数据，结果每次读到的值都不一样，这个过程中可能别的事务会修改这条数据的值，而且修改值之后事务都提交了，结果导致人家每次查到的值都不一样，都查到了提交事务修改过的值，这就是所谓的不可重复读。
脏写：就是两个事务没提交的状况下，都修改同一条数据，结果一个事务回滚了，把另外一个事务修改的值也给撤销了，一句话，两个事务没提交状态下修改同一个值。
脏读：就是一个事务修改了一条数据的值，结果还没提交呢，另外一个事务就读到了你修改的值，然后你回滚了，人家事务再次读，就读不到了，也就是说别人读到了你修改之后还没提交的值
不可重复读：针对的是已经提交的事务修改的值，被你事务给读到了，你事务内多次查询，多次读到的是别的已经提交的事务修改过的值，这就导致不可重复读了。
什么是幻读？ 场景如下：
你一个事务A，先发送一条SQL语句，里面有一个条件，要查询一批数据出来，比如“select * from table where id&amp;gt;10”，类似这种SQL,然后一开始查询出来了10条数据
接着这个时候，别的事务B往表里插入了几条数据，而且事务B还提交了，此时多了几行数据出来。
接着事务A此时第三次查询，再次按照之前的一模一样的条件执行“select * from table where id&amp;gt;10”这条SQL语句，由于其他事务插入了几条数据，导致这次他查询出来了12条数据
于是此时事务A开始怀疑自己的双眼了，为什么一模一样的SQL语句，第一次查询是10条数据，第二次查询是12条数据？难道刚才出现了幻觉？导致我刚才幻读了？这就是幻读这个名词的由来。
幻读:指的就是你一个事务用一样的SQL多次查询，结果每次查询都会发现查到了一些之前没看到过的数据,特指的是你查询到了之前查询没看到过的数据
脏写、脏读、不可重复读、幻读，都是因为业务系统会多线程并发执行，每个线程可能都会开启一个事务，每个事务都会执行增删改查操作。
然后数据库会并发执行多个事务，多个事务可能会并发的对缓存页里的同一批数据进行增删改查操作，于是这个并发增删改查同一批数据的问题，可能就会导致我们说的脏写、脏读、不可重复读、幻读，这些问题。
所以这些问题的本质，都是数据库的多事务并发问题，那么为了解决多事务并发问题，数据库才设计了事务隔离机制、MVCC多版本隔离机制、锁机制，用一整套机制来解决多事务并发问题</content></entry><entry><title>【转】重新回顾redo日志对于事务提交后，数据绝对不会丢失的意义 1</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-%E9%87%8D%E6%96%B0%E5%9B%9E%E9%A1%BEredo%E6%97%A5%E5%BF%97%E5%AF%B9%E4%BA%8E%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4%E5%90%8E%E6%95%B0%E6%8D%AE%E7%BB%9D%E5%AF%B9%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1%E7%9A%84%E6%84%8F%E4%B9%89-1/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">在更新完Buffer Pool中的缓存页之后，必须要写一条redo log，这样才能记录下来我们对数据库做的修改。 redo log可以保证我们事务提交之后，如果事务中的增删改SQL语句更新的缓存页还没刷到磁盘上去，此时MySQL宕机了，那么MySQL重启过后，就可以把redo log重做一遍，恢复出来事务当时更新的缓存页，然后再把缓存页刷到磁盘就可以了
redo log本质是保证事务提交之后，修改的数据绝对不会丢失。
所以接下来一段时间我们会深入研究redo log的底层实现原理，今天就承上启下，简单回顾一下redo log这个机制存在的意义。
首先我们都知道，执行增删改SQL语句的时候，都是针对一个表中的某些数据去执行的，此时的话，首先必须找到这个表对应的表空间，然后找到表空间对应的磁盘文件，接着从磁盘文件里把你要更新的那批数据所在的数据页从磁盘读取出来，放到Buffer Pool的缓存页里去 接着实际上你的增删改SQL语句就会针对Buffer Pool中的缓存页去执行你的更新逻辑，比如插入一行数据，或者更新一行数据，或者是删除一行数据。 那么学习过之前的Buffer Pool底层原理之后都知道，其实你更新缓存页的时候，会更新free链表、flush链表、lru链表，然后有专门的后台IO线程，不定时的根据flush链表、lru链表，会把你更新过的缓存页刷新回磁盘文件的数据页里去 所以大家都知道这个机制里最大的漏洞就在于，万一你一个事务里有增删改SQL更新了缓存页，然后事务提交了，结果万一你还没来得及让IO线程把缓存页刷新到磁盘文件里，此时MySQL宕机了，然后内存数据丢失，你事务更新的数据就丢失了！ 但是也不可能每次你事务一提交，就把你事务更新的缓存页都刷新回磁盘文件里去，因为大家之前也都知道，缓存页刷新到磁盘文件里，是随机磁盘读写，性能是相当的差！这会导致你数据库性能和并发能力都很弱的！
所以此时才会引入一个redo log机制，这个机制就是说，你提交事务的时候，绝对是保证把你对缓存页做的修改以日志的形式，写入到redo log日志文件里去的
这种日志大致的格式如下：对表空间XX中的数据页XX中的偏移量为XXXX的地方更新了数据XXX
只要你事务提交的时候保证你做的修改以日志形式写入redo log日志，那么哪怕你此时突然宕机了，也没关系！
因为你MySQL重启之后，把你之前事务更新过做的修改根据redo log在Buffer Pool里重做一遍就可以了，就可以恢复出来当时你事务对缓存页做的修改，然后找时机再把缓存页刷入磁盘文件里去。
那么有人会问了，你事务提交的时候把修改过的缓存页都刷入磁盘，跟你事务提交的时候把你做的修改的redo log都写入日志文件，他们不都是写磁盘么？差别在哪里？
这是本文一个关键的问题。
实际上，如果你把修改过的缓存页都刷入磁盘，这首先缓存页一个就是16kb，数据比较大，刷入磁盘比较耗时，而且你可能就修改了缓存页里的几个字节的数据，难道也把完整的缓存页刷入磁盘吗？
而且你缓存页刷入磁盘是随机写磁盘，性能是很差的，因为他一个缓存页对应的位置可能在磁盘文件的一个随机位置，比如偏移量为45336这个地方。
但是如果是写redo log，第一个一行redo log可能就占据几十个字节，就包含表空间号、数据页号、磁盘文件偏移量、更新值，这个写入磁盘速度很快。
此外，redo log写日志，是顺序写入磁盘文件，每次都是追加到磁盘文件末尾去，速度也是很快的。
所以你提交事务的时候，用redo log的形式记录下来你做的修改，性能会远远超过刷缓存页的方式，这也可以让你的数据库的并发能力更强。
在Buffer Pool执行完增删改之后，写入日志文件的redo log长什么样？ 接下来我们就要深入研究一下redo log的一些技术细节了，今天就来看看写入磁盘上的日志文件的redo log，大致长个什么样，里面都包含一些什么东西。
之前略微给大家提到过，就是redo log里本质上记录的就是在对某个表空间的某个数据页的某个偏移量的地方修改了几个字节的值，具体修改的值是什么，他里面需要记录的就是表空间号+数据页号+偏移量+修改几个字节的值+具体的值
所以根据你修改了数据页里的几个字节的值，redo log就划分为了不同的类型，MLOG_1BYTE类型的日志指的就是修改了1个字节的值，MLOG_2BYTE类型的日志指的就是修改了2个字节的值，以此类推，还有修改了4个字节的值的日志类型，修改了8个字节的值的日志类型。
当然，如果你要是一下子修改了一大串的值，类型就是MLOG_WRITE_STRING，就是代表你一下子在那个数据页的某个偏移量的位置插入或者修改了一大串的值。
所以其实一条redo log看起来大致的结构如下所示：
日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，具体修改的数据
大致就是一条redo log中依次排列上述的一些东西，这条redo log表达的语义就很明确了，他的类型是什么，类型就告诉了你他这次增删改操作修改了多少字节的数据；
然后在哪个表空间里操作的，这个就是跟你SQL在哪个表里执行的是对应的；接着就是在这个表空间的哪个数据页里执行的，在数据页的哪个偏移量开始执行的，具体更新的数据是哪些呢。
有了上述信息，就可以精准完美的还原出来一次数据增删改操作做的变动了。
只不过如果是MLOG_WRITE_STRING类型的日志，因为不知道具体修改了多少字节的数据，所以其实会多一个修改数据长度，就告诉你他这次修改了多少字节的数据，如下所示他的格式：
日志类型（就是类似MLOG_1BYTE之类的），表空间ID，数据页号，数据页中的偏移量，修改数据长度，具体修改的数据
因此今天就简单给大家讲解一下redo log的日志的格式，其实没大家想的那么复杂，当然如果往深了说，那可能也比你想的复杂很多，比如redo log日志里面可能会记录你更新了哪些索引之类的，那就复杂了去了，但是这些东西就等我们讲到索引那块的时候再说好了！
redo log是直接一条一条写入文件的吗？非也，揭秘redo log block！ 其实MySQL内有另外一个数据结构，叫做redo log block，大概你可以理解为，平时我们的数据不是存放在数据页了的么，用一页一页的数据页来存放数据。
那么对于redo log也不是单行单行的写入日志文件的，他是用一个redo log block来存放多个单行日志的。
一个redo log block是512字节，这个redo log block的512字节分为3个部分，一个是12字节的header块头，一个是496字节的body块体，一个是4字节的trailer块尾
在这里面，12字节的header头又分为了4个部分。
包括4个字节的block no，就是块唯一编号； 2个字节的data length，就是block里写入了多少字节数据； 2个字节的first record group。这个是说每个事务都会有多个redo log，是一个redo log group，即一组redo log。那么在这个block里的第一组redo log的偏移量，就是这2个字节存储的； 4个字节的checkpoint on 我们看下图，这个header可以进行进一步的区分。
所以我们看到上图就知道，其实对于我们的redo log而言，他确实是不停的追加写入到redo log磁盘文件里去的，但是其实每一个redo log都是写入到文件里的一个redo log block里去的，一个block最多放496自己的redo log日志。
此时可能有人会有疑问了，到底一个一个的redo log block在日志文件里是怎么存在的？那么一条一条的redo log又是如何写入日志文件里的redo log block里去的呢？估计很多人都很奇怪这个问题。
所以我们接下来就给大家解答这个问题。
大家先想一下，假设你有一个redo log日志文件，平时我们往里面写数据，你大致可以认为是从第一行开始，从左往右写，可能会有很多行 好，那么所以现在既然如此，假设你要写第一个redo log了，是不是应该起码是先在内存里把这个redo log给弄到一个redo log block数据结构里去？
然后似乎你应该是等内存里的一个redo log block的512字节都满了，再一次性把这个redo log block写入磁盘文件
然后其实按照我们所说的，一个redo log block就是512字节，那么是不是真正写入的时候，把这个redo log block的512字节的数据，就写入到redo log文件里去就可以了？那么redo log文件里就多了一个block 所以大家看到上图演示之后，对于这个所谓的redo log和redo log block的关系，以及redo log block如何进入日志文件，日志文件里是如何存放一个又一个的redo log block的，应该都很清楚了！
其实有一定开发经验的朋友都知道，写文件的时候，可以按照字节，一个字节一个字节的写入的，文件里存放的东西就是很多很多字节，依次排开，然后其中可能512个字节组合起来，就固定代表了一个redo log block。
这其实就是任何一个中间件系统，数据库系统，底层依赖磁盘文件存储数据的一个共同的原理，所以大家也不用把这个复杂数据写入磁盘文件想象的太复杂了。
那么如果依次在磁盘文件里的末尾追加不停的写字节数据，就是磁盘顺序写；但是假设现在磁盘文件里已经有很多很多的redo log block了，此时要在磁盘里某个随机位置找到一个redo log block去修改他里面几个字节的数据，这就是磁盘随机写
直接强行把redo log写入磁盘？非也，揭秘redo log buffer！ 这个redo log到底是如何通过内存缓冲之后，再进入磁盘文件里去的，这就涉及到了一个新的组件，redo log buffer，他就是MySQL专门设计了用来缓冲redo log写入的。
这个redo log buffer其实就是MySQL在启动的时候，就跟操作系统申请的一块连续内存空间，大概可以认为相当于是buffer pool吧。那个buffer pool是申请之后划分了N多个空的缓存页和一些链表结构，让你把磁盘上的数据页加载到内存里来的。
redo log buffer也是类似的，他是申请出来的一片连续内存，然后里面划分出了N多个空的redo log block
通过设置mysql的innodb_log_buffer_size可以指定这个redo log buffer的大小，默认的值就是16MB，其实已经够大了，毕竟一个redo log block才512字节而已，每一条redo log其实也就几个字节到几十个字节罢了。
所以大家看到这里就明白了，上一讲我们就说了，其实redo log都是先写入内存里的redo log block数据结构里去的，然后完事儿了才会把redo log block写入到磁盘文件里去的
这里我们看到了redo log buffer的结构，就很清晰的知道，当你要写一条redo log的时候，就会先从第一个redo log block开始写入
写满了一个redo log block，就会继续写下一个redo log block，以此类推，直到所有的redo log block都写满。
那么此时肯定有人会问了，万一要是redo log buffer里所有的redo log block都写满了呢？
那此时必然会强制把redo log block刷入到磁盘中去的！
我们上一次讲到了redo log block刷入磁盘文件中的示意，其实就是把512字节的redo log block追加到redo log日志文件里去就可以了 另外还要给大家讲一点的是，其实在我们平时执行一个事务的过程中，每个事务会有多个增删改操作，那么就会有多个redo log，这多个redo log就是一组redo log，其实每次一组redo log都是先在别的地方暂存，然后都执行完了，再把一组redo log给写入到redo log buffer的block里去的。
如果一组redo log实在是太多了，那么就可能会存放在两个redo log block中,但是反之，如果说一个redo log group比较小，那么也可能多个redo log group是在一个redo log block里的
redo log buffer中的缓冲日志，到底什么时候可以写入磁盘？ redo log在写的时候，都是一个事务里的一组redo log，先暂存在一个地方，完事儿了以后把一组redo log写入redo log buffer。
写入redo log buffer的时候，是写入里面提前划分好的一个一个的redo log block的，选择有空闲空间的redo log block去写入，然后redo log block写满之后，其实会在某个时机刷入到磁盘里去
到底redo log buffer里的redo log block什么时候可以刷入到磁盘文件里去呢？
磁盘上到底有几个redo log日志文件？
不可能大量的redo log日志都放一个文件里吧？
磁盘空间会占用的越来越多吗？
首先，我们先来看看redo log block是哪些时候会刷入到磁盘文件里去：
***（1）***如果写入redo log buffer的日志已经占据了redo log buffer总容量的一半了，也就是超过了8MB的redo log在缓冲里了，此时就会把他们刷入到磁盘文件里去
***（2）***一个事务提交的时候，必须把他的那些redo log所在的redo log block都刷入到磁盘文件里去，只有这样，当事务提交之后，他修改的数据绝对不会丢失，因为redo log里有重做日志，随时可以恢复事务做的修改
（PS：当然，之前最早最早的时候，我们讲过，这个redo log哪怕事务提交的时候写入磁盘文件，也是先进入os cache的，进入os的文件缓冲区里，所以是否提交事务就强行把redo log刷入物理磁盘文件中，这个需要设置对应的参数，我们之前都讲过的 ，大家回过头去看看 ）
***（3）***后台线程定时刷新，有一个后台线程每隔1秒就会把redo log buffer里的redo log block刷到磁盘文件里去
***（4）***MySQL关闭的时候，redo log block都会刷入到磁盘里去
忽略上面的第四条不说，因为关闭MySQL的时候必然会刷redo log到磁盘，其他三条其实我们都看到了，也就是说，如果你瞬间执行大量的高并发的SQL语句，1秒内就产生了超过8MB的redo log，此时占据了redo log buffer一半的空间了，必然会直接把你的redo log刷入磁盘里去
在MySQL承载高并发请求的时候比较常见，比如每秒执行上万个增删改SQL语句，每个SQL产生的redo log假设有几百个字节，此时却是会在瞬间生成超过8MB的redo log日志，必然会触发立马刷新redo log到磁盘
其次，第二种情况，其实就是平时执行一个事务，这个事务一般都是在几十毫秒到几百毫秒执行完毕的，说实在的，一般正常性能情况下，MySQL单事务性能一般不会超过1秒，否则数据库操作就太慢了。
那么如果在几十毫秒，或者几百毫秒的时候，执行完毕了一个事务，此时必然会立马把这个事务的redo log都刷入磁盘
第一种情况其实是不常见的，第二种情况是比较常见的，往往redo log刷盘都是以一个短事务提交时候发生的，第三种情况就是后台线程每秒自动刷新redo log到磁盘去，这个就是说假设没有别的情况触发，后台线程自己都会不停的刷新redo log到磁盘。
但是不管怎么说，主要是保证一个事务执行的时候，redo log都进入redo log buffer，提交事务的时候，事务对应的redo log必须是刷入磁盘文件，接着才算是事务提交成功，否则事务提交就是失败，保证这一点，就能确保事务提交之后，数据不会丢，有redo log在磁盘里就行了。
当然，绝对保证数据不丢，还得配置一个参数，提交事务把redo log刷入磁盘文件的os cache之后，还得强行从os cache刷入物理磁盘。</content></entry><entry><title>【转】重新回顾redo日志对于事务提交后，数据绝对不会丢失的意义 2</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-%E9%87%8D%E6%96%B0%E5%9B%9E%E9%A1%BEredo%E6%97%A5%E5%BF%97%E5%AF%B9%E4%BA%8E%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4%E5%90%8E%E6%95%B0%E6%8D%AE%E7%BB%9D%E5%AF%B9%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1%E7%9A%84%E6%84%8F%E4%B9%89-2/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">如果事务执行到一半要回滚怎么办？再探undo log回滚日志原理！ redo log都是先进入redo log buffer中的一个block，然后事务提交的时候就会刷入磁盘文件里去。
这样万一要是你提交事务了，结果事务修改的缓存页还没来得及刷入磁盘上的数据文件，此时你MySQL关闭了或者是宕机了，那么buffer pool里被事务修改过的数据就全部都丢失了！
但是只要有redo log，你重启MySQL之后完全是可以把那些修改了缓存页，但是缓存页还没来得及刷入磁盘的事务，他们所对应的redo log都加载出来，在buffer pool的缓存页里重做一遍，就可以保证事务提交之后，修改的数据绝对不会丢！
相信之前讲解了redo log日志之后，大家对这块都理解的更加深刻了，那么今天我们就带着大家来探索另外一种日志，就是undo log日志，也就是回滚日志，这种日志要应对的场景，就是事务回滚的场景！
那么首先大家先思考一个问题，假设现在我们一个事务里要执行一些增删改的操作，那么必然是先把对应的数据页从磁盘加载出来放buffer pool的缓存页里，然后在缓存页里执行一通增删改，同时记录redo log日志
但是现在问题来了，万一要是一个事务里的一通增删改操作执行到了一半，结果就回滚事务了呢？
比如一个事务里有4个增删改操作，结果目前为止已经执行了2个增删改SQL了，已经更新了一些buffer pool里的数据了，但是还有2个增删改SQL的逻辑还没执行，此时事务要回滚了怎么办？
这个时候就很尴尬了，如果你要回滚事务的话，那么必须要把已经在buffer pool的缓存页里执行的增删改操作给回滚了
但是怎么回滚呢？毕竟无论是插入，还是更新，还是删除，该做的都已经做了啊！
所以在执行事务的时候，才必须引入另外一种日志，就是undo log回滚日志
这个回滚日志，他记录的东西其实非常简单，比如你要是在缓存页里执行了一个insert语句，那么此时你在undo log日志里，对这个操作记录的回滚日志就必须是有一个主键和一个对应的delete操作，要能让你把这次insert操作给回退了。
那么比如说你要是执行的是delete语句，那么起码你要把你删除的那条数据记录下来，如果要回滚，就应该执行一个insert操作把那条数据插入回去。
如果你要是执行的是update语句，那么起码你要把你更新之前的那个值记录下来，回滚的时候重新update一下，把你之前更新前的旧值给他更新回去。
如果你要是执行的是select语句呢？不好意思，select语句压根儿没有在buffer pool里执行任何修改，所以根本不需要undo log！
好，所以我们来看下图，其实你在执行事务期间，之前我们最开始的几篇文章就讲过，你除了写redo log日志还必须要写undo log日志，这个undo log日志是至关重要的，没有他，你根本都没办法回滚事务！
一起来看看INSRET语句的undo log回滚日志长什么样？ INSERT语句的undo log的类型是TRX_UNDO_INSERT_REC，这个undo log里包含了以下一些东西：
这条日志的开始位置 主键的各列长度和值 表id undo log日志编号 undo log日志类型 这条日志的结束位置 接下来我们来给大家解释一下，首先，一条日志必须得有自己的一个开始位置，这个没什么好说的是吧？
那么主键的各列长度和值是什么意思？大家都知道，你插入一条数据，必然会有一个主键！
如果你自己指定了一个主键，那么可能这个主键就是一个列，比如id之类的，也可能是多个列组成的一个主键，比如“id+name+type”三个字段组成的一个联合主键，也是有可能的。
所以这个主键的各列长度和值，意思就是你插入的这条数据的主键的每个列，他的长度是多少，具体的值是多少。即使你没有设置主键，MySQL自己也会给你弄一个row_id作为隐藏字段，做你的主键。
接着是表id，这个就不用多说了，你插入一条数据必然是往一个表里插入数据的，那当然得有一个表id，记录下来是在哪个表里插入的数据了。
undo log日志编号，这个意思就是，每个undo log日志都是有自己的编号的。
而在一个事务里会有多个SQL语句，就会有多个undo log日志，在每个事务里的undo log日志的编号都是从0开始的，然后依次递增。
至于undo log日志类型，就是TRX_UNDO_INSERT_REC，insert语句的undo log日志类型就是这个东西。
最后一个undo log日志的结束位置，这个自然也不用多说了，他就是告诉你undo log日志结束的位置是什么。
那么接着我们用一个图画一下这个INSERT语句的undo log回滚日志的结构，大家来看一眼，感受一下。
万一要是你现在在buffer pool的一个缓存页里插入了一条数据了，执行了insert语句，然后你写了一条上面的那种undo log，现在事务要是回滚了，你直接就把这条insert语句的undo log拿出来。
然后在undo log里就知道在哪个表里插入的数据，主键是什么，直接定位到那个表和主键对应的缓存页，从里面删除掉之前insert语句插入进去的数据就可以了，这样就可以实现事务回滚的效果了！
回顾总结 平时我们执行增删改的时候，无非就是从磁盘加载数据页到buffer pool的缓存页里去，对缓存页进行更新，同时记录下来undo log回滚日志和redo log重做日志，应对的是事务提交之后MySQL挂了恢复数据的场景，以及事务回滚的场景。
每个事务里面的多个SQL语句都是如何执行的呢？
从磁盘加载数据页到buffer pool的缓存页里去，然后更新buffer pool里的缓存页，同时记录redo log和undo log
每个事务如果提交了，那么就皆大欢喜，这个提交的过程我之前最早就讲过了，他有一些步骤，包括在redo log里记录事务提交标识之类的。
如果事务提交之后，redo log刷入磁盘，结果MySQL宕机了，是可以根据redo log恢复事务修改过的缓存数据的。
如果要回滚事务，那么就基于undo log来回滚就可以了，把之前对缓存页做的修改都给回滚了就可以了。
但是这里就有很多问题了：
多个事务并发执行的时候，可能会同时对缓存页里的一行数据进行更新，这个冲突怎么处理？是否要加锁？ 可能有的事务在对一行数据做更新，有的事务在查询这行数据，这里的冲突怎么处理？ 下一章预告 解决多个事务并发运行的时候，同时写和同时读写的一些并发冲突的处理机制，包括了MySQL事务的隔离级别、MVCC多版本隔离、锁机制，等等。</content></entry><entry><title>【转】如何解决经典的Too many connections故障？背后原理是什么</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BB%8F%E5%85%B8%E7%9A%84too-many-connections%E6%95%85%E9%9A%9C%E8%83%8C%E5%90%8E%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">其实核心就是一行命令：
ulimit -HSn 65535
然后就可以用如下命令检查最大文件句柄数是否被修改了
cat /etc/security/limits.conf 如果都修改好之后，可以在MySQL的my.cnf里确保max_connections参数也调整好了，然后可以重启服务器，然后重启MySQL，这样的话，linux的最大文件句柄就会生效了，MySQL的最大连接数也会生效了。
设置之后，我们要确保变更落地到/etc/security/limits.conf文件里，永久性的设置进程的资源限制
所以执行ulimit -HSn 65535命令后，要用如下命令检查一下是否落地到配置文件里去了。
cat /etc/security/limits.conf</content></entry><entry><title>【转】一个真实的生产优化案例</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-%E4%B8%80%E4%B8%AA%E7%9C%9F%E5%AE%9E%E7%9A%84%E7%94%9F%E4%BA%A7%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"><![CDATA[MySQL数据库的日志顺序读写以及数据文件随机读写的原理 先给大家剖析一下MySQL在实际工作时候的两种数据读写机制，一种是对redo log、binlog这种日志进行的磁盘顺序读写，一种是对表空间的磁盘文件里的数据页进行的磁盘随机读写。 简单来说，MySQL在工作的时候，尤其是执行增删改操作的时候，肯定会先从表空间的磁盘文件里读取数据页出来，这个过程其实就是典型的磁盘随机读操作
我们先看下面的图，图里有一个磁盘文件的示意，里面有很多数据页，然后你可能需要在一个随机的位置读取一个数据页到缓存，这就是磁盘随机读
因为你要读取的这个数据页可能在磁盘的任意一个位置，所以你在读取磁盘里的数据页的时候只能是用随机读的这种方式。
磁盘随机读的性能是比较差的，所以不可能每次更新数据都进行磁盘随机读，必须是读取一个数据页之后放到Buffer Pool的缓存里去，下次要更新的时候直接更新Buffer Pool里的缓存页。
对于磁盘随机读来说，主要关注的性能指标是IOPS和响应延迟
IOPS就是底层的存储系统每秒可以执行多少次磁盘读写操作，比如你底层磁盘支持每秒执行1000个磁盘随机读写操作和每秒执行200个磁盘随机读写操作，对你的数据库的性能影响其实是非常大的。
这个指标实际上对数据库的crud操作的QPS影响是非常大的，因为他在某种程度上几乎决定了你每秒能执行多少个SQL语句，底层存储的IOPS越高，数据库的并发能力就越高。
另外一个就是磁盘随机读写操作的响应延迟，也是对数据库的性能有很大的影响。因为假设底层磁盘支持每秒执行200个随机读写操作，但是每个操作是耗费10ms完成呢，还是耗费1ms完成呢，这个其实也是有很大的影响的，决定了对数据库执行的单个crud SQL语句的性能。
比如一个SQL语句发送过去，他磁盘要执行随机读操作加载多个数据页，此时每个磁盘随机读响应时间是50ms，那么此时可能你的SQL语句要执行几百ms，但是如果每个磁盘随机读仅仅耗费10ms，可能SQL就执行100ms就行了。
所以其实一般对于核心业务的数据库的生产环境机器规划，我们都是推荐用SSD固态硬盘的，而不是机械硬盘，因为SSD固态硬盘的随机读写并发能力和响应延迟要比机械硬盘好的多，可以大幅度提升数据库的QPS和性能。
接着我们来看磁盘顺序读写，之前我们都知道，当你在Buffer Pool的缓存页里更新了数据之后，必须要写一条redo log日志，这个redo log日志，其实就是走的顺序写
所谓顺序写，就是说在一个磁盘日志文件里，一直在末尾追加日志，我们看下图。
所以上图可以清晰看到，写redo log日志的时候，其实是不停的在一个日志文件末尾追加日志的，这就是磁盘顺序写。
磁盘顺序写的性能其实是很高的，某种程度上来说，几乎可以跟内存随机读写的性能差不多，尤其是在数据库里其实也用了os cache机制，就是redo log顺序写入磁盘之前，先是进入os cache，就是操作系统管理的内存缓存里。
所以对于这个写磁盘日志文件而言，最核心关注的是磁盘每秒读写多少数据量的吞吐量指标，就是说每秒可以写入磁盘100MB数据和每秒可以写入磁盘200MB数据，对数据库的并发能力影响也是极大的。
因为数据库的每一次更新SQL语句，都必然涉及到多个磁盘随机读取数据页的操作，也会涉及到一条redo log日志文件顺序写的操作。所以磁盘读写的IOPS指标，就是每秒可以执行多少个随机读写操作，以及每秒可以读写磁盘的数据量的吞吐量指标，就是每秒可以写入多少redo log日志，整体决定了数据库的并发能力和性能。
包括你磁盘日志文件的顺序读写的响应延迟，也决定了数据库的性能，因为你写redo log日志文件越快，那么你的SQL语句性能就越高。
生产经验：Linux操作系统的存储系统软件层原理剖析以及IO调度优化原理 简单来说，Linux的存储系统分为VFS层、文件系统层、Page Cache缓存层、通用Block层、IO调度层、Block设备驱动层、Block设备层，如下图：
当MySQL发起一次数据页的随机读写，或者是一次redo log日志文件的顺序读写的时候，实际上会把磁盘IO请求交给Linux操作系统的VFS层
这一层的作用，就是根据你是对哪个目录中的文件执行的磁盘IO操作，把IO请求交给具体的文件系统。
举个例子，在linux中，有的目录比如/xx1/xx2里的文件其实是由NFS文件系统管理的，有的目录比如/xx3/xx4里的文件其实是由Ext3文件系统管理的，那么这个时候VFS层需要根据你是对哪个目录下的文件发起的读写IO请求，把请求转交给对应的文件系统
接着文件系统会先在Page Cache这个基于内存的缓存里找你要的数据在不在里面，如果有就基于内存缓存来执行读写，如果没有就继续往下一层走，此时这个请求会交给通用Block层，在这一层会把你对文件的IO请求转换为Block IO请求
接着IO请求转换为Block IO请求之后，会把这个Block IO请求交给IO调度层，在这一层里默认是用CFQ公平调度算法的
也就是说，可能假设此时你数据库发起了多个SQL语句同时在执行IO操作。
有一个SQL语句可能非常简单，比如update xxx set xx1=xx2 where id=1，他其实可能就只要更新磁盘上的一个block里的数据就可以了
但是有的SQL语句，比如说select * from xx where xx1 like &ldquo;%xx%&ldquo;可能需要IO读取磁盘上的大量数据。
那么此时如果基于公平调度算法，就会导致他先执行第二个SQL语句的读取大量数据的IO操作，耗时很久，然后第一个仅仅更新少量数据的SQL语句的IO操作，就一直在等待他，得不到执行的机会。
所以在这里，其实一般建议MySQL的生产环境，需要调整为deadline IO调度算法，他的核心思想就是，任何一个IO操作都不能一直不停的等待，在指定时间范围内，都必须让他去执行。
所以基于deadline算法，上面第一个SQL语句的更新少量数据的IO操作可能在等待一会儿之后，就会得到执行的机会，这也是一个生产环境的IO调度优化经验。
查看当前系统支持的磁盘IO调度算法 [root@alpha-mongo-140-52 ~]# dmesg | grep -i scheduler io scheduler noop registered io scheduler anticipatory registered io scheduler deadline registered io scheduler cfq registered (default) default代表当前设备使用的缺省的IO调度算法 也可以用以下命令查看： [root@test ~]# more /sys/block/sda/queue/scheduler noop anticipatory deadline [cfq] 备注:括号里括起来的即为当前调度算法值 修改当前块设备使用的io调度算法为deadline: [root@test ~]# echo &#34;deadline&#34; &gt; /sys/block/sda/queue/scheduler 备注:修改立即生效 最后IO完成调度之后，就会决定哪个IO请求先执行，哪个IO请求后执行，此时可以执行的IO请求就会交给Block设备驱动层，然后最后经过驱动把IO请求发送给真正的存储硬件，也就是Block设备层 然后硬件设备完成了IO读写操作之后，要不然是写，要不然是读，最后就把响应经过上面的层级反向依次返回，最终MySQL可以得到本次IO读写操作的结果
]]></content></entry><entry><title>【转】MySQL物理数据模型2</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-mysql%E7%89%A9%E7%90%86%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B2/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">磁盘上的一行数据到底如何读取出来的？ 我们结合上面的磁盘上的数据存储格式来思考一下，一行数据到底是如何读取出来的呢？
再看上面的磁盘数据存储格式：
0x09 0x04 00000101 头信息 column1=value1 column2=value2 &amp;hellip; columnN=valueN
首先他必然要把变长字段长度列表和NULL值列表读取出来，通过综合分析一下，就知道有几个变长字段，哪几个变长字段是NULL，因为NULL值列表里谁是NULL谁不是NULL都一清二楚。
此时就可以从变长字段长度列表中解析出来不为NULL的变长字段的值长度，然后也知道哪几个字段是NULL的，此时根据这些信息，就可以从实际的列值存储区域里，把你每个字段的值读取出来了。
如果是变长字段的值，就按照他的值长度来读取，如果是NULL，就知道他是个NULL，没有值存储，如果是定长字段，就按照定长长度来读取，这样就可以完美的把你一行数据的值都读取出来了！
磁盘文件中， 40个bit位的数据头以及真实数据是如何存储的？ 之前我们已经给大家讲到了在磁盘上存储数据的时候，每一行数据都会有变长字段长度列表，逆序存放这行数据里的变长字段的长度，然后会有NULL值列表，对于允许为NULL的字段都会有一个bit位标识那个字段是否为NULL，也是逆序排列的。
今天我们接着给大家讲每一行数据存储的时候，还得有40个bit位的数据头，这个数据头是用来描述这行数据的。
这40个bit位里，第一个bit位和第二个bit位，都是预留位，是没任何含义的。
然后接下来有一个bit位是delete_mask，他标识的是这行数据是否被删除了，其实看到这个bit位，很多人可能已经反映过来了，这么说在MySQL里删除一行数据的时候，未必是立马把他从磁盘上清理掉，而是给他在数据头里搞1个bit标记他已经被删了？
没错，其实大家现在看这些数据头，只要先留有一个印象就可以了，知道每一行数据都有一些数据头，不同的数据头都是用来描述这行数据的一些状态和附加信息的。
然后下一个bit位是min_rec_mask，这个bit位大家现在先不用去关注，他的含义以后我们讲到对应的内容的时候再说，他其实就是说在B+树里每一层的非叶子节点里的最小值都有这个标记。
接下来有4个bit位是n_owned，这个暂时我们也先不用去管他，他其实就是记录了一个记录数，这个记录数的作用，后续我们讲到对应的概念时会告诉大家的。
接着有13个bit位是heap_no，他代表的是当前这行数据在记录堆里的位置，现在大家可能也很难去理解他，这些概念都要结合后续的一些内容才能理解的，这里只能是初步的给大家介绍下。
然后是3个bit位的record_type，这就是说这行数据的类型
0代表的是普通类型，1代表的是B+树非叶子节点，2代表的是最小值数据，3代表的是最大值数据
很多朋友可能也不理解这些什么意思，其实我们也现在不用在乎他，因为很多这些概念都是往后在讲解索引之类的技术的时候才会涉及到的。
最后是16个bit的next_record，这个是指向他下一条数据的指针。
我们每一行的实际数据在磁盘上是如何存储的？ 之前我们已经给大家讲过了，一行数据在磁盘文件里存储的时候，实际上首先会包含自己的变长字段的长度列表，然后是NULL值列表，接着是数据头，然后接着才是真实数据，所以这一次我们就讲讲真实数据是如何存储的。
首先我们在存储真实数据的时候，并没什么特别的，无非就是按照我们那个字段里的数据值去存储就行了
比如我们之前说了一个例子，有一行数据是“jack NULL m NULL xx_school”，那么他真实存储大致如下所示：
0x09 0x04 00000101 0000000000000000000010000000000000011001 jack m xx_school
刚开始先是他的变长字段的长度，用十六进制来存储，然后是NULL值列表，指出了谁是NULL，接着是40个bit位的数据头，然后是真实的数据值，就放在后面。
在读取这个数据的时候，他会根据变长字段的长度，先读取出来jack这个值，因为他的长度是4，就读取4个长度的数据，jack就出来了；
然后发现第二个字段是NULL，就不用读取了；
第三个字段是定长字段，直接读取1个字符就可以了，就是m这个值；
第四个字段是NULL，不用读取了；
第五个字段是变长字段长度是9，读取出来xx_school就可以了。
但是等等，大家觉得真正在磁盘上存储的时候，我们那些字符串就是直接这么存储在磁盘上吗？
显然不是的！
实际上字符串这些东西都是根据我们数据库指定的字符集编码，进行编码之后再存储的，所以大致看起来一行数据是如下所示的：
0x09 0x04 00000101 0000000000000000000010000000000000011001 616161 636320 6262626262
大家会看到上面，我们的字符串和其他类型的数值最终都会根据字符集编码，搞成一些数字和符号存储在磁盘上
所以其实一行数据是如何存储的，我相信大家就都已经了解的很清晰了，那么我们今天来给大家简单提一下，在实际存储一行数据的时候，会在他的真实数据部分，加入一些隐藏字段，这个隐藏字段跟后续的一些内容是有关联的，大家先了解一下。
首先有一个DB_ROW_ID字段，这就是一个行的唯一标识，是他数据库内部给你搞的一个标识，不是你的主键ID字段。如果我们没有指定主键和unique key唯一索引的时候，他就内部自动加一个ROW_ID作为主键。
接着是一个DB_TRX_ID字段，这是跟事务相关的，他是说这是哪个事务更新的数据，这是事务ID，这个后续我们讲解到事务的时候会跟大家说的。
最后是DB_ROLL_PTR字段，这是回滚指针，是用来进行事务回滚的，也是我们后续在讲解事务的时候再详细说。
所以如果你加上这几个隐藏字段之后，实际一行数据可能看起来如下所示：
0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR） 616161 636320 6262626262
我给上面几个隐藏字段都加了括号说明了，上面那基本就是最终在磁盘上一行数据是长成什么样的了
我们再看看下面的图，大家回忆一下之前我们给大家讲解的，当你执行crud的时候，先会把磁盘上的数据加载到Buffer Pool里缓存，然后更新的时候也是更新Buffer Pool的缓存，同时维护一堆链表。
然后定时或者不定时的，根据flush链表和lru链表，Buffer Pool里的更新过的脏数据就会刷新到磁盘上去。
好，现在我们再结合最近讲解的一些内容思考一下，那么在磁盘上的数据，每一行数据是不是就是类似“0x09 0x04 00000101 0000000000000000000010000000000000011001 00000000094C（DB_ROW_ID）00000000032D（DB_TRX_ID） EA000010078E（DB_ROL_PTR） 616161 636320 6262626262”这样的东西？
行溢出是什么东西？ 我们之前已经初步了解到，实际上我们每一行数据都是放在一个数据页里的，这个数据页默认的大小是16KB，那么之前就有人在后台提过一个问题：万一 一行数据的大小超过了页的大小怎么办呢？
比如有一个表的字段类型是VARCHAR(65532)，意思就是最大可以包含65532个字符，那也就是65532个字节，这就远大于16kb的大小了，也就是说这一行数据的这个字段都远超一个数据页的大小了！
这个时候实际上会在那一页里存储你这行数据，然后在那个字段中，仅仅包含他一部分数据，同时包含一个20个字节的指针，指向了其他的一些数据页，那些数据页用链表串联起来，存放这个VARCHAR(65532)超大字段里的数据。 我们看下图，就给出了这个示意。
上面说的这个过程，其实就叫做行溢出，就是说一行数据存储的内容太多了，一个数据页都放不下了，此时只能溢出这个数据页，把数据溢出存放到其他数据页里去，那些数据页就叫做溢出页。
包括其他的一些字段类型都是一样的，比如TEXT、BLOB这种类型的字段，都有可能出现溢出，然后一行数据就会存储在多个数据页里。
讲到这里，其实就已经把我们的行数据的物理存储相关的内容都已经讲完了，很多琐碎和细节的东西，其实不需要我们在这里来死扣他，大家其实要理解的，就是一行数据的物理存储结构，然后这个数据其实是在一个数据页里的，如果一个数据页里放不下一行数据，就会有行溢出问题，存放到多个数据页里去。
讲到这里，我们可以做一点总结，当我们在数据库里插入一行数据的时候，实际上是在内存里插入一个有复杂存储结构的一行数据，然后随着一些条件的发生，这行数据会被刷到磁盘文件里去。
在磁盘文件里存储的时候，这行数据也是按照复杂的存储结构去存放的。
而且每一行数据都是放在数据页里的，如果一行数据太大了，就会产生行溢出问题，导致一行数据溢出到多个数据页里去，那么这行数据在Buffer Pool可能就是存在于多个缓存页里的，刷入到磁盘的时候，也是用磁盘上的多个数据页来存放这行数据的。
希望大家能够把最近几天学到的行数据物理存储结构，与之前学到的Buffer Pool缓存机制结合起来去理解，把他们有机的融合为一体。
接下来，我们就会开始讲解数据页的物理存储结构，然后是表空间的物理存储结构，最后是讲解这些数据以物理存储结构的方式，在磁盘上存储的时候，是放在哪些磁盘文件里的。
只要把后续那些内容讲完，那么大家就对数据库的Buffer Pool缓冲读写机制，以及磁盘上的物理存储机制，就完全理解了，而且这两个机制都是有机结合在一起的，Buffer Pool的数据是从磁盘上读取出来的，Buffer Pool里更新的数据又会刷新到磁盘上去。
在这个过程中，整个数据的物理存储机制，包括行数据、数据页、表空间、磁盘文件，这些概念，大家也都会理解了，到时候自然理解了数据在磁盘上如何存储的，加载到Buffer Pool缓存页之后如何存储的
用于存放磁盘上的多行数据的数据页到底长个什么样子？ 之前我们老是给大家提到一个概念，就是数据页，大家都知道平时我们执行crud的时候，都会从磁盘上加载数据页到Buffer Pool的缓存页里去，然后更新了缓存页后，又会刷新回磁盘上的数据页里去。
所以其实MySQL中进行数据操作的最小单位应该是数据页，那么我们之前已经给大家分析过了一行一行的数据在磁盘和缓存中存储的时候，他真正的格式是什么样子的
现在我们都知道，一行一行的数据是放在数据页里的，所以接下来就该分析分析，数据页到底是长什么样子的了。
之前介绍过，每个数据页，实际上是默认有16kb的大小，那么这16kb的大小就是存放大量的数据行吗？
明显不是的，其实一个数据页拆分成了很多个部分，大体上来说包含了文件头、数据页头、最小记录和最大记录、多个数据行、空闲空间、数据页目录、文件尾部。
我下面有一个图，在图里包含了一个数据页的各个部分，大家可以看一下
这个数据页就跟每一行数据一样，都是由MySQL开发人员设计出来的一个特殊的存储格式。
也就是说通过这种特殊的存储格式在磁盘文件里去存放一个又一个的数据页，每个数据页在磁盘里实际存储的时候，就是包含了上述一些特殊的数据，然后每个数据页里还有专门的区域包含了多个数据行，至于每个数据行，那就是用我们之前讲解的那套存储格式来存储的了。
接着我们给大家讲一下这个把数据插入数据页的一个过程，因为大家都知道，刚开始一个数据页可能是空的，没有一行数据的，此时这个数据页实际上是没有数据行那个区域的
假设我们现在要插入一行数据，此时数据库里可是一行数据都没有的，那么此时应该先是从磁盘上加载一个空的数据页到缓存页里去
记住，缓存页跟数据页是一 一对应的，他在磁盘上的时候就是数据页，数据页加载到缓存页里了，我们就叫他缓存页了！ 所以此时在缓存页里插入一条数据，实际上就是在数据行那个区域里插入一行数据，然后空闲区域的空间会减少一些 接着你就可以不停的插入数据到这个缓存页里去，直到他的空闲区域都耗尽了，就是这个页满了，此时数据行区域内可能有很多行数据，空闲区域就没了。
表空间和数据区的概念 上一次我们讲完了数据页的具体存储结构，当然里面有很多的细节我们还没讲，实际上现在也确实没必要去说那些细节，因为很多数据页的一些细节性的东西，都是要在后续讲解的内容中涉及到的，比如说数据的删除，查询的一些原理。
现在我们在大致了解了数据页的结构和使用之后，我们可以继续来了解下一个概念，就是表空间和数据区的概念
首先我们先说一下，什么是表空间？
简单来说，就是我们平时创建的那些表，其实都是有一个表空间的概念，在磁盘上都会对应着“表名.ibd”这样的一个磁盘数据文件
所以其实在物理层面，表空间就是对应一些磁盘上的数据文件。
有的表空间，比如系统表空间可能对应的是多个磁盘文件，有的我们自己创建的表对应的表空间可能就是对应了一个“表名.ibd”数据文件。
然后在表空间的磁盘文件里，其实会有很多很多的数据页，因为大家都知道一个数据页不过就是16kb而已，总不可能一个数据页就是一个磁盘文件吧。
所以一个表空间的磁盘文件里，其实是有很多的数据页的。
但是现在有一个问题，就是一个表空间里包含的数据页实在是太多了，不便于管理，所以在表空间里又引入了一个数据区的概念，英文就是extent
一个数据区对应着连续的64个数据页，每个数据页是16kb，所以一个数据区是1mb，然后256个数据区被划分为了一组。
对于表空间而言，他的第一组数据区的第一个数据区的前3个数据页，都是固定的，里面存放了一些描述性的数据。比如FSP_HDR这个数据页，他里面就存放了表空间和这一组数据区的一些属性。
IBUF_BITMAP数据页，里面存放的是这一组数据页的所有insert buffer的一些信息。
INODE数据页，这里也是存放了一些特殊的信息
大家暂时先不用了解这些东西具体是干什么的，你只要知道每一个组数据区的第一个数据区的前3个数据页，都是存放一些特殊的信息的。
然后这个表空间里的其他各组数据区，每一组数据区的第一个数据区的头两个数据页，都是存放特殊信息的，比如XDES数据页就是用来存放这一组数据区的一些相关属性的，其实就是很多描述这组数据区的东西，现在大家也不用去知道是什么。
其实今天的内容讲到这里就差不多了，讲太多大家可能就被绕晕了，大家只要知道，我们平时创建的那些表都是有对应的表空间的，每个表空间就是对应了磁盘上的数据文件，在表空间里有很多组数据区，一组数据区是256个数据区，每个数据区包含了64个数据页，是1mb
然后表空间的第一组数据区的第一个数据区的头三个数据页，都是存放特殊信息的；
表空间的其他组数据区的第一个数据区的头两个数据页，也都是存放特殊信息的。大家今天只要了解到这个程度就可以了。
所以磁盘上的各个表空间的数据文件里是通过数据区的概念，划分了很多很多的数据页的，因此当我们需要执行crud操作的时候，说白了，就是从磁盘上的表空间的数据文件里，去加载一些数据页出来到Buffer Pool的缓存页里去使用。
我下面给出了一张图，图里就给出了一个表空间内部的存储结构，包括一组一组的数据区，每一组数据区是256个数据区，然后一个数据区是64个数据页。
总结 今天我们来用一篇文章初步总结一下我们近期学习到的MySQL存储模型以及对应的读写机制，其实大家通过近期的学习也仅仅是初步了解了MySQL底层数据的存储模型而已，因为后续我们还要讲解MySQL的增删改查执行背后的深入底层的各种存储数据读写细节，现在仅仅是初步把存储模型的结构给建立起来罢了。
好，那么我们现在应该都知道了，最终MySQL的数据都是放在磁盘文件里的，这个大家应该都没什么问题吧
那么数据在磁盘文件里是怎么存放的呢？我们都知道我们平时数据都是插入一个一个的表中的，而表是个逻辑概念，其实在物理层面，他对应的是表空间这个概念。
所以其实在MySQL的磁盘上，表空间就对应着磁盘文件，在磁盘文件里就存放着数据！
那么这个表空间的磁盘文件里，数据是如何组织的呢？
这个就非常的复杂了！因为你可以想象一下，假如让你把数据直接一行一行的写入一个磁盘文件，当然很简单了！
但是问题是你现在要存储的是数据库里的如此复杂的数据！他里面是有各种字段类型的，还有索引这个概念，当后面我们讲到索引的时候，就会详细分析这个索引在磁盘里的数据组织结构，这也是相当的复杂。
所以其实在磁盘文件里存放的数据，他从最基本的角度来看的话，就是被拆分为一个一个的数据区（extent）分组，以后我们干脆就用他的英文名叫做extent组好了，每个extent组中包含256个extent，然后每个extent里包含64个数据页！然后每个数据页里都包含了一行一行的数据！ 今天我们来用一篇文章初步总结一下我们近期学习到的MySQL存储模型以及对应的读写机制，其实大家通过近期的学习也仅仅是初步了解了MySQL底层数据的存储模型而已，因为后续我们还要讲解MySQL的增删改查执行背后的深入底层的各种存储数据读写细节，现在仅仅是初步把存储模型的结构给建立起来罢了。
好，那么我们现在应该都知道了，最终MySQL的数据都是放在磁盘文件里的，这个大家应该都没什么问题吧
那么数据在磁盘文件里是怎么存放的呢？我们都知道我们平时数据都是插入一个一个的表中的，而表是个逻辑概念，其实在物理层面，他对应的是表空间这个概念。
所以其实在MySQL的磁盘上，表空间就对应着磁盘文件，在磁盘文件里就存放着数据！
那么这个表空间的磁盘文件里，数据是如何组织的呢？
这个就非常的复杂了！因为你可以想象一下，假如让你把数据直接一行一行的写入一个磁盘文件，当然很简单了！
但是问题是你现在要存储的是数据库里的如此复杂的数据！他里面是有各种字段类型的，还有索引这个概念，当后面我们讲到索引的时候，就会详细分析这个索引在磁盘里的数据组织结构，这也是相当的复杂。
所以其实在磁盘文件里存放的数据，他从最基本的角度来看的话，就是被拆分为一个一个的数据区（extent）分组，以后我们干脆就用他的英文名叫做extent组好了，每个extent组中包含256个extent，然后每个extent里包含64个数据页！然后每个数据页里都包含了一行一行的数据！ 当然，这个时候有人会问了，这个从磁盘文件里读取一个数据页，是怎么读取的啊？
其实这个很简单了，你可以想一下，磁盘文件里放的数据都是紧挨在一起的，类似于下面的那种样子。
0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds 0xdfs3439399abc0sfsdkslf9sdfpsfds0xdfs3439399abc0sfsdkslf9sdfpsfds
其实上述字符完全无任何意义，就是我为了演示随便搞出来的一段东西而已，但是大致来说磁盘里存放的数据看起来就是那样的，可能先是有一个extent组开始的一些东西，然后里面是一个一个的extent，每个extent开始的时候会写一些特殊的信息，然后再是一个一个的数据页，里面是一个一个的数据行。
那么在读取一个数据页的时候，你就可以通过随机读写的方式来了，举个例子，我们下面有一个伪代码，大家看看。就是设置一下要从一个数据文件的哪个位置开始读取，一直到哪个位置就结束。
dataFile.setStartPosition(25347) dataFile.setEndPosition(28890) dataPage = dataFile.read()
通过上面伪代码那种方式，你指定磁盘文件里的开始和截止的位置，就能读取出来指定位置的一段数据，比如读取出来一大坨东西：psfds0xdfs343939。也许这坨东西就是一个数据页包含的内容了。
然后把数据页放到内存的缓存页里即可。
接着crud操作都可以直接针对缓存页去执行了，会自动把更新的缓存页加入flush链表，然后更新他在lru链表里的位置，包括更新过的缓存页会从free链表里拿出来，等等，后续一系列操作，都是之前我们分析过的了。
此时对于那些被更新过的缓存页来说，都会由后台线程刷入磁盘的，那么刷磁盘的时候是怎么刷呢？我们也是写一段伪代码给大家看看。
dataFile.setStartPosition(25347) dataFile.setEndPosition(28890) dataFile.write(cachePage) 因为一个数据页的大小其实是固定的，所以一个数据页固定就是可能在一个磁盘文件里占据了某个开始位置到结束位置的一段数据，此时你写回去的时候也是一样的，选择好固定的一段位置的数据，直接把缓存页的数据写回去，就覆盖掉了原来的那个数据页了，就如上面的伪代码示意。</content></entry><entry><title>【转】MySQL物理数据模型</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-mysql%E7%89%A9%E7%90%86%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B1/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"><![CDATA[为什么不能直接更新磁盘上的数据？ 因为来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据，虽然技术上是可以做到的，但是那必然导致执行请求的性能极差。 因为磁盘随机读写的性能是最差的，所以直接更新磁盘文件，必然导致我们的数据库完全无法抗下任何一点点稍微高并发一点的场景。
所以MySQL才设计了如此复杂的一套机制，通过内存里更新数据，然后写redo log以及事务提交，后台线程不定时刷新内存里的数据到磁盘文件里。 通过这种方式保证，你每个更新请求，尽量就是更新内存，然后顺序写日志文件。 更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是比较高的，因为顺序写磁盘文件，他的性能要远高于随机读写磁盘文件。 也正是通过这套机制，才能让我们的MySQL数据库在较高配置的机器上，每秒可以抗下几千的读写请求。
MySQL为什么要引入数据页这个概念？ 当我们要执行update之类的SQL语句的时候，并不是直接去更新磁盘文件，而是要把磁盘上的一些数据加载到内存里来，然后对内存里的数据进行更新，同时写redo log到磁盘上去。 但是这里就有一个问题了，难道我们每次都是把磁盘里的一条数据加载到内存里去进行更新，然后下次要更新别的数据的时候，再从磁盘里加载另外一条数据到内存里去？ 这样每次都是一条数据一条数据的加载到内存里去更新，很明显是效率不高的 所以innodb存储引擎在这里引入了一个数据页的概念，也就是把数据组织成一页一页的概念，每一页有16kb，然后每次加载磁盘的数据到内存里的时候，是至少加载一页数据进去，甚至是多页数据进去 假设我们有一次要更新一条id=1的数据： update xxx set xxx=xxx where id=1 那么此时他会把id=1这条数据所在的一页数据都加载到内存里去，这一页数据里，可能还包含了id=2，id=3等其他数据。 然后我们更新完id=1的数据之后，接着更新id=2的数据，那么此时是不是就不用再次读取磁盘里的数据了？ 因为id=2本身就跟id=1在一页里，之前这一页数据就加载到内存里去了，你直接更新内存里的数据页中的id=2这条数据就可以了。 我们看下图，这就是数据页的意义，磁盘和内存之间的数据交换通过数据页来执行，包括内存里更新后的脏数据，刷回磁盘的时候，也是至少一个数据页刷回去。 当IO线程把内存里的脏数据刷到磁盘上去的时候，也是以数据页为单位来刷回去的
一行数据在磁盘上存储的时候，包含哪些东西？ 变长字段的长度列表，null值列表，数据头，column01的值，column02的值，column0n的值&hellip;&hellip; 说白了，就是除了每一个字段的值以外，他还包含了一些额外的信息，这些额外的信息就是用来描述这一行数据的。今天我们就详细给大家说说这些额外的信息里都是放了什么东西。
变长字段在磁盘中是怎么存储的？ 大家都知道，在MySQL里有一些字段的长度是变长的，是不固定的，比如VARCHAR(10)之类的这种类型的字段，实际上他里面存放的字符串的长度是不固定的，有可能是“hello”这么一个字符串，也可能是“a”这么一个字符串。
好，那么现在我们来假设一下，现在有一行数据，他的几个字段的类型为VRACHAR(10)，CHAR(1)，CHAR(1)，那么他第一个字段是VARCHAR(10)，这个长度是可能变化的，所以这一行数据可能就是类似于：hello a a，这样子，第一个字段的值是“hello”，后面两个字段的值都是一个字符，就是一个a
然后另外一行数据，同样也是这几个字段，他的第一个字段的值可能是“hi”，后面两个字段也是“a”，所以这一行数据可能是类似于：hi a a。一共三个字段，第一个字段的长度是是不固定的，后面两个字段的长度都是固定的1个字符。
想必这个道理大家都能理解吧？
那么现在，我们来假设你把上述两条数据写入了一个磁盘文件里，两行数据是挨在一起的，那么这个时候在一个磁盘文件里可能有下面的两行数据：
hello a a hi a a
大家可以看到，两行数据在底层磁盘文件里是不是挨着存储的？
没错！其实平时你看到的表里的很多行数据，最终落地到磁盘里的时候，都是上面那种样子的，一大坨数据放在一个磁盘文件里都挨着存储的。
存储在磁盘文件里的变长字段，为什么难以读取？ 现在我们来继续思考一个问题，假设现在我们要读取上面的磁盘文件里的数据，要读取出来hello a a这一行数据。那你觉得是那么容易的吗？
当然不是了！这个过程比你想象的可能要困难一些。
假如现在你要读取hello a a这行数据，第一个问题就是，从这个磁盘文件里读取的时候，到底哪些内容是一行数据？我不知道啊！
因为这个表里的第一个字段是VARCHAR(10)类型的，第一个字段的长度是多少我们是不知道的！
所以有可能你读取出来“hello a a hi”是一行数据，也可能是你读取出来“hello a”是一行数据，你在不知道一行数据的每个字段到底是多少长度的情况下，胡乱的去读取是不现实的，根本不知道磁盘文件里混成一坨的数据里，哪些数据是你要读取的一行？
引入变长字段的长度列表，解决一行数据的读取问题 所以说才要在存储每一行数据的时候，都保存一下他的变长字段的长度列表，这样才能解决一行数据的读取问题。
也就是说，你在存储“hello a a”这行数据的时候，要带上一些额外的附加信息，比如第一块就是他里面的变长字段的长度列表
也就是说，这个hello是VARCHAR(10)类型的变长字段的值，那么这个“hello”字段值的长度到底是多少？
我们看到“hello”的长度是5，十六进制就是0x05，所以此时会在“hello a a”前面补充一些额外信息，首先就是变长字段的长度列表，你会看到这行数据在磁盘文件里存储的时候，其实是类似如下的格式：0x05 null值列表 数据头 hello a a。
你这行数据存储的时候应该是如上所示的！
这个时候假设你有两行数据，还有一行数据可能就是：0x02 null值列表 数据头 hi a a，两行数据放在一起存储在磁盘文件里，看起来是如下所示的：
0x05 null值列表 数据头 hello a a 0x02 null值列表 数据头 hi a a
引入变长字段长度列表后，如何解决变长字段的读取问题？ 所以假设此时你要读取“hello a a”这行数据，你首先会知道这个表里的三个字段的类型是VARCHAR(10) CHAR(1) CHAR(1)，那么此时你先要读取第一个字段的值，那么第一个字段是变长的，到底他的实际长度是多少呢？
此时你会发现第一行数据的开头有一个变长字段的长度列表，里面会读取到一个0x05这个十六进制的数字，发现第一个变长字段的长度是5，于是按照长度为5，读取出来第一个字段的值，就是“hello”
接着你知道后续两个字段都是CHAR(1)，长度都是固定的1个字符，于是此时就依次按照长度为1读取出来后续两个字段的值，分别是“a”“a”，于是最终你会读取出来“hello a a”这一行数据！
接着假设你要读取第二行数据，你先看一下第二行数据后的变长字段长度列表，发现他第一个变长字段的长度是0x02，于是就读取长度为2的字段值，就是“hi”，再读取两个长度固定为1的字符值，都是“a”，此时读取出来“hi a a”这行数据。
如果有多个变长字段，如何存放他们的长度？ 接着我们假设，如果说有多个变长字段，如何存放他们的长度？
比如一行数据有VARCHAR(10) VARCHAR(5) VARCHAR(20) CHAR(1) CHAR(1)，一共5个字段，其中三个是变长字段，此时假设一行数据是这样的：hello hi hao a a
此时在磁盘中存储的，必须在他开头的变长字段长度列表中存储几个变长字段的长度，一定要注意一点，他这里是逆序存储的！
也就是说先存放VARCHAR(20)这个字段的长度，然后存放VARCHAR(5)这个字段的长度，最后存放VARCHAR(10)这个字段的长度。
现在hello hi hao三个字段的长度分别是0x05 0x02 0x03，但是实际存放在变长字段长度列表的时候，是逆序放的，所以一行数据实际存储可能是下面这样的：
0x03 0x02 0x05 null值列表 头字段 hello hi hao a a
为什么一行数据里的NULL值不能直接存储？ 之前我们已经给大家讲了在数据库里一行数据中如果有VARCHAR(10)之类的变长字段，那么他的存储和读取会有什么问题，以及为了解决这个问题，为什么要给磁盘上存储的每一行数据都加入变长字段长度列表。
今天我们继续给大家讲解在磁盘上存储的一行数据里另外一块特殊的数据区域，就是NULL值列表。
这个所谓的NULL值列表，顾名思义，说的就是你一行数据里可能有的字段值是NULL，比如你有一个name字段，他是允许为NULL的，那么实际上在存储的时候，如果你没给他赋值，他这个字段的值就是NULL。
好，那么假设这个字段的NULL值我们在磁盘上存储的时候，就是按照“NULL”这么个字符串来存储，是不是很浪费存储空间？
本来他就是个NULL，说明什么值都没有，你还给他存个“NULL”字符串，你说你这是干什么呢？
所以实际在磁盘上存储数据的时候，一行数据里的NULL值是肯定不会直接按照字符串的方式存放在磁盘上浪费空间的。
NULL值是以二进制bit位来存储的 我们接着看，那么NULL值列表在磁盘上到底应该如何存储呢？
很简单，对所有的NULL值，不通过字符串在磁盘上存储，而是通过二进制的bit位来存储，一行数据里假设有多个字段的值都是NULL，那么这多个字段的NULL，就会以bit位的形式存放在NULL值列表中。
现在我们来给大家举个例子，假设你有一张表，他的建表语句如下所示：
CREATE TABLE customer ( name VARCHAR(10) NOT NULL, address VARCHAR(20), gender CHAR(1), job VARCHAR(30), school VARCHAR(50) ) ROW_FORMAT=COMPACT;
上面那个表就是一个假想出来的客户表，里面有5个字段，分别为name、address、genderjob、school，就代表了客户的姓名、地址、性别、工作以及学校。
其中有4个变长字段，还有一个定长字段，然后第一个name字段是声明了NOT NULL的，就是不能为NULL，其他4个字段都可能是NULL的。
那么现在我们来假设这个表里有如下一行数据，现在来看看，他在磁盘上是怎么来存储的：“jack NULL m NULL xx_school”，他的5个字段里有两个字段都是NULL
结合小小案例来思考一行数据的磁盘存储格式 接着我们来思考上面那个表里的那行案例数据，在磁盘上应该如何存储呢，因为他有多个变长字段，还有多个字段允许为NULL。首先我们先回顾一下，一行数据在磁盘上的存储格式应该是下面这样的：
变长字段长度列表 NULL值列表 头信息 column1=value1 column2=value2 &hellip; columnN=valueN
所以先看变长字段长度列表应该放什么东西，他一共有4个变长字段，那么按照我们上次说的，是不是应该按照逆序的顺序，先放school字段的长度，再放job、address、name几个字段的值长度？
说起来是这样，但是其实这里要区分一个问题，那就是如果这个变长字段的值是NULL，就不用在变长字段长度列表里存放他的值长度了，所以在上面那行数据中，只有name和school两个变长字段是有值的，把他们的长度按照逆序放在变长字段长度列表中就可以了，如下所示：
0x09 0x04 NULL值列表 头信息 column1=value1 column2=value2 &hellip; columnN=valueN
接着来看NULL值列表，这个NULL值列表是这样存放的，你所有允许值为NULL的字段，注意，是允许值为NULL，不是说一定值就是NULL了，只要是允许你为NULL的字段，在这里每个字段都有一个二进制bit位的值，如果bit值是1说明是NULL，如果bit值是0说明不是NULL。
比如上面4个字段都允许为NULL，每个人都会有一个bit位，这一行数据的值是“jack NULL m NULL xx_school”，然后其中2个字段是null，2个字段不是null，所以4个bit位应该是：1010
但是实际放在NULL值列表的时候，他是按逆序放的，所以在NULL值列表里，放的是：0101，整体这一行数据看着是下面这样的
0x09 0x04 0101 头信息 column1=value1 column2=value2 &hellip; columnN=valueN
另外就是他实际NULL值列表存放的时候，不会说仅仅是4个bit位，他一般起码是8个bit位的倍数，如果不足8个bit位就高位补0，所以实际存放看起来是如下的：
0x09 0x04 00000101 头信息 column1=value1 column2=value2 &hellip; columnN=valueN
]]></content></entry><entry><title>【转】LRU算法优化和性能优化</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-04-18-lru%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96%E5%92%8C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">MYSQL的预读机制 MySQL设计了一个预读机制，要把相邻的一些数据页一次性读入到Buffer Pool缓存里去
假设你读取了数据页01到缓存页里去，那么好，接下来有可能会接着顺序读取数据页01相邻的数据页02到缓存页里去，这个时候，是不是可能在读取数据页02的时候要再次发起一次磁盘IO？
所以为了优化性能，MySQL才设计了预读机制，也就是说如果在一个区内，你顺序读取了好多数据页了，比如数据页01~数据页56都被你依次顺序读取了，MySQL会判断，你可能接着会继续顺序读取后面的数据页。
那么此时他就干脆提前把后续的一大堆数据页（比如数据页57~数据页72）都读取到Buffer Pool里去，那么后续你再读取数据页60的时候，是不是就可以直接从Buffer Pool里拿到数据了？
当然理想是上述那样，很丰满，但是现实可能很骨感。你预读的一大堆数据页要是占据了LRU链表的前面部分，可能这些预读的数据页压根儿后续没人会使用，那你这个预读机制就是在捣乱了。
基于冷热数据分离的思想设计LRU链表 所以为了解决上一讲我们说的简单的LRU链表的问题，真正MySQL在设计LRU链表的时候，采取的实际上是冷热数据分离的思想。
所以真正的LRU链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据，这个冷热数据的比例是由innodb_old_blocks_pct参数控制的，他默认是37，也就是说冷数据占比37%。
而且数据页第一次被加载到缓存的时候，缓存页会被放在冷数据区域的链表头部
冷数据区域的缓存页什么时候会被放入到热数据区域？ 冷数据区域的缓存页肯定是会被使用的，那么冷数据区域的缓存页什么时候会放到热数据区域呢？
MySQL设定了一个规则，他设计了一个innodb_old_blocks_time参数，默认值1000，也就是1000毫秒。
也就是说，必须是一个数据页被加载到缓存页之后，在1s之后，你访问这个缓存页，他才会被挪动到热数据区域的链表头部去。
因为假设你加载了一个数据页到缓存去，然后过了1s之后你还访问了这个缓存页，说明你后续很可能会经常要访问它，这个时间限制就是1s，因此只有1s后你访问了这个缓存页，他才会给你把缓存页放到热数据区域的链表头部去。
在这样的一个LRU链表方案下，预读机制以及全表扫描加载进来的一大堆缓存页是放在LRU链表的冷数据区域的前面
预读机制和全表扫描加载进来的一大堆缓存页，此时都在冷数据区域里，跟热数据区域里的频繁访问的缓存页是没关系的
如果此时缓存页不够了，需要淘汰一些缓存，会怎么样？
直接就是可以找到LRU链表中的冷数据区域的尾部的缓存页，他们肯定是之前被加载进来的，而且加载进来1s过后都没人访问过，说明这个缓存页压根儿就没人愿意去访问他！他就是冷数据！
所以此时就直接淘汰冷数据区域的尾部的缓存页，刷入磁盘，就可以了
刚加载数据的缓存页都是放冷数据区域的头部的，1s过后被访问了才会放热数据区域的头部，热数据区域的缓存页被访问了，就会自动放到头部去。
这样的话，实际上冷数据区域放的都是加载进来的缓存页，最多在1s内被访问过，之后就再也没访问过的冷数据缓存页！
而加载进来之后在1s过后还经常被访问的缓存页，都放在了热数据区域里，他们进行了冷热数据的隔离！
这样的话，在淘汰缓存的时候，一定是优先淘汰冷数据区域几乎不怎么被访问的缓存页的！这种冷热数据隔离的思想，尽可能让热数据和冷数据分开，避免冷数据影响热数据的访问！
LRU链表的热数据区域是如何进行优化的？ LRU链表的热数据区域的一个性能优化的点，就是说，在热数据区域中，如果你访问了一个缓存页，是不是应该要把他立马移动到热数据区域的链表头部去？
LRU链表的热数据区域的访问规则被优化了一下，即你只有在热数据区域的后3/4部分的缓存页被访问了，才会给你移动到链表头部去。
如果你是热数据区域的前面1/4的缓存页被访问，他是不会移动到链表头部去的。
举个例子，假设热数据区域的链表里有100个缓存页，那么排在前面的25个缓存页，他即使被访问了，也不会移动到链表头部去的。但是对于排在后面的75个缓存页，他只要被访问，就会移动到链表头部去。
这样的话，他就可以尽可能的减少链表中的节点移动了。
定时把LRU尾部的部分缓存页刷入磁盘
有一个后台线程，他会运行一个定时任务，这个定时任务每隔一段时间就会把LRU链表的冷数据区域的尾部的一些缓存页，刷入磁盘里去，清空这几个缓存页，把他们加入回free链表去！所以实际上在缓存页没用完的时候，可能就会清空一些缓存页了
把flush链表中的一些缓存页定时刷入磁盘 如果仅仅是把LRU链表中的冷数据区域的缓存页刷入磁盘，大家觉得够吗？
明显不够啊，因为在lru链表的热数据区域里的很多缓存页可能也会被频繁的修改，难道他们永远都不刷入磁盘中了吗？
所以这个后台线程同时也会在MySQL不怎么繁忙的时候，找个时间把flush链表中的缓存页都刷入磁盘中，这样被你修改过的数据，迟早都会刷入磁盘的！
只要flush链表中的一波缓存页被刷入了磁盘，那么这些缓存页也会从flush链表和lru链表中移除，然后加入到free链表中去！
所以你可以理解为，你一边不停的加载数据到缓存页里去，不停的查询和修改缓存数据，然后free链表中的缓存页不停的在减少，flush链表中的缓存页不停的在增加，lru链表中的缓存页不停的在增加和移动。
另外一边，你的后台线程不停的在把lru链表的冷数据区域的缓存页以及flush链表的缓存页，刷入磁盘中来清空缓存页，然后flush链表和lru链表中的缓存页在减少，free链表中的缓存页在增加。
这就是一个动态运行起来的效果！
实在没有空闲缓存页了怎么办？
此时可能所有的free链表都被使用了，然后flush链表中有一大堆被修改过的缓存页，lru链表中有一大堆的缓存页，根据冷热数据进行了分离，大致是如此的效果。
这个时候如果要从磁盘加载数据页到一个空闲缓存页中，此时就会从LRU链表的冷数据区域的尾部找到一个缓存页，他一定是最不经常使用的缓存页！然后把他刷入磁盘和清空，然后把数据页加载到这个腾出来的空闲缓存页里去！
这就是MySQL的Buffer Pool缓存机制的一整套运行原理！我们已经完整的讲完了缓存页的加载和使用，以及free链表、flush链表、lru链表是怎么使用的，包括缓存页是如何刷入磁盘腾出来空闲缓存页的，以及缓存页没有空闲的时候应该怎么处理。
生产环境下配置多个Buffer Pool提升性能 一般来说，MySQL默认的规则是，如果你给Buffer Pool分配的内存小于1GB，那么最多就只会给你一个Buffer Pool。
但是如果你的机器内存很大，那么你必然会给Buffer Pool分配较大的内存，比如给他个8G内存，那么此时你是同时可以设置多个Buffer Pool的，比如说下面的MySQL服务器端的配置。
[server] innodb_buffer_pool_size = 8589934592 innodb_buffer_pool_instances = 4 我们给buffer pool设置了8GB的总内存，然后设置了他应该有4个Buffer Pool，此时就是说，每个buffer pool的大小就是2GB
通过chunk来支持数据库运行期间的Buffer Pool动态调整 MySQL实际上设计了一个chunk机制，也就是说buffer pool是由很多chunk组成的，他的大小是innodb_buffer_pool_chunk_size参数控制的，默认值就是128MB。
所以实际上我们可以来做一个假设，比如现在我们给buffer pool设置一个总大小是8GB，然后有4个buffer pool，那么每个buffer pool就是2GB，此时每个buffer pool是由一系列的128MB的chunk组成的，也就是说每个buffer pool会有16个chunk。
然后每个buffer pool里的每个chunk里就是一系列的描述数据块和缓存页，每个buffer pool里的多个chunk共享一套free、flush、lru这些链表，此时的话，看起来可能大致如下图所示。
那么现在有了上面讲的这套chunk机制，就可以支持动态调整buffer pool大小了。
比如我们buffer pool现在总大小是8GB，现在要动态加到16GB，那么此时只要申请一系列的128MB大小的chunk就可以了，只要每个chunk是连续的128MB内存就行了。然后把这些申请到的chunk内存分配给buffer pool就行了。</content></entry><entry><title>【转】Buffer Pool的内存数据结构</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-04-18-buffer-pool%E7%9A%84%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">Buffer Pool Buffer Pool本质其实就是数据库的一个内存组件，可以理解为他就是一片内存数据结构. Buffer Pool默认情况下是128MB
比如我们的数据库如果是16核32G的机器，那么你就可以给Buffer Pool分配个2GB的内存
[server] innodb_buffer_pool_size = 2147483648 数据页 数据页：MySQL中抽象出来的数据单位 接着我们要了解下一个概念，对于每个缓存页，他实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓存页的
比如包含如下的一些东西：这个数据页所属的表空间、数据页的编号、这个缓存页在Buffer Pool中的地址以及别的一些杂七杂八的东西。
每个缓存页都会对应一个描述信息，这个描述信息本身也是一块数据，在Buffer Pool中，每个缓存页的描述数据放在最前面，然后各个缓存页放在后面
所以此时我们看下面的图，Buffer Pool实际看起来大概长这个样子。
而且这里我们要注意一点，Buffer Pool中的描述数据大概相当于缓存页大小的5%左右，也就是每个描述数据大概是800个字节左右的大小，然后假设你设置的buffer pool大小是128MB，实际上Buffer Pool真正的最终大小会超出一些，可能有个130多MB的样子，因为他里面还要存放每个缓存页的描述数据。
Buffer Pool的初始化 数据库只要一启动，就会按照你设置的Buffer Pool大小，稍微再加大一点，去找操作系统申请一块内存区域，作为Buffer Pool的内存区域。
然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的16KB的大小以及对应的800个字节左右的描述数据的大小，在Buffer Pool中划分出来一个一个的缓存页和一个一个的他们对应的描述数据。
然后当数据库把Buffer Pool划分完毕之后，看起来就是之前我们看到的那张图。
只不过这个时候，Buffer Pool中的一个一个的缓存页都是空的，里面什么都没有，要等数据库运行起来之后，当我们要对数据执行增删改查的操作的时候，才会把数据对应的页从磁盘文件里读取出来，放入Buffer Pool中的缓存页中。
怎么知道哪些缓存页是空闲的呢？ 数据库会为Buffer Pool设计一个free链表，他是一个双向链表数据结构，这个free链表里，每个节点就是一个空闲的缓存页的描述数据块的地址，也就是说，只要你一个缓存页是空闲的，那么他的描述数据块就会被放入这个free链表中。
刚开始数据库启动的时候，可能所有的缓存页都是空闲的，因为此时可能是一个空的数据库，一条数据都没有，所以此时所有缓存页的描述数据块，都会被放入这个free链表中
这个free链表，他本身其实就是由Buffer Pool里的描述数据块组成的，你可以认为是每个描述数据块里都有两个指针，一个是free_pre，一个是free_next，分别指向自己的上一个free链表的节点，以及下一个free链表的节点。
通过Buffer Pool中的描述数据块的free_pre和free_next两个指针，就可以把所有的描述数据块串成一个free链表。上面为了画图需要，所以把描述数据块单独画了一份出来，表示他们之间的指针引用关系。
对于free链表而言，只有一个基础节点是不属于Buffer Pool的，他是40字节大小的一个节点，里面就存放了free链表的头节点的地址，尾节点的地址，还有free链表里当前有多少个节点
如何将磁盘上的页读取到Buffer Pool的缓存页中去？ 首先，我们需要从free链表里获取一个描述数据块，然后就可以对应的获取到这个描述数据块对应的空闲缓存页
接着我们就可以把磁盘上的数据页读取到对应的缓存页里去，同时把相关的一些描述数据写入缓存页的描述数据块里去，比如这个数据页所属的表空间之类的信息，最后把那个描述数据块从free链表里去除就可以了
怎么知道数据页有没有被缓存？ 我们在执行增删改查的时候，肯定是先看看这个数据页有没有被缓存，如果没被缓存就走上面的逻辑，从free链表中找到一个空闲的缓存页，从磁盘上读取数据页写入缓存页，写入描述数据，从free链表中移除这个描述数据块。
但是如果数据页已经被缓存了，那么就会直接使用了。
所以其实数据库还会有一个哈希表数据结构，他会用表空间号+数据页号，作为一个key，然后缓存页的地址作为value。
当你要使用一个数据页的时候，通过“表空间号+数据页号”作为key去这个哈希表里查一下，如果没有就读取数据页，如果已经有了，就说明数据页已经被缓存了。
脏数据页到底为什么会脏？ 执行增删改的时候，如果发现数据页没缓存，那么必然会基于free链表找到一个空闲的缓存页，然后读取到缓存页里去，但是如果已经缓存了，那么下一次就必然会直接使用缓存页。
反正不管怎么样，你要更新的数据页都会在Buffer Pool的缓存页里，供你在内存中直接执行增删改的操作。
接着你肯定会去更新Buffer Pool的缓存页中的数据，此时一旦你更新了缓存页中的数据，那么缓存页里的数据和磁盘上的数据页里的数据，是不是就不一致了？
这个时候，我们就说缓存页是脏数据，脏页
哪些缓存页是脏页呢？ 其实通过之前的学习，我们都是知道一点的，最终这些在内存里更新的脏页的数据，都是要被刷新回磁盘文件的。
但是这里就有一个问题了，不可能所有的缓存页都刷回磁盘的，因为有的缓存页可能是因为查询的时候被读取到Buffer Pool里去的，可能根本没修改过！
所以数据库在这里引入了另外一个跟free链表类似的flush链表，这个flush链表本质也是通过缓存页的描述数据块中的两个指针，让被修改过的缓存页的描述数据块，组成一个双向链表。
凡是被修改过的缓存页，都会把他的描述数据块加入到flush链表中去，flush的意思就是这些都是脏页，后续都是要flush刷新到磁盘上去的
所以flush链表的结构如下图所示，跟free链表几乎是一样的。
如果Buffer Pool中的缓存页不够了怎么办？ 随着你不停的把磁盘上的数据页加载到空闲的缓存页里去，free链表中的空闲缓存页是不是会越来越少？因为只要你把一个数据页加载到一个空闲缓存页里去，free链表中就会减少一个空闲缓存页。
所以，当你不停的把磁盘上的数据页加载到空闲缓存页里去，free链表中不停的移除空闲缓存页，迟早有那么一瞬间，你会发现free链表中已经没有空闲缓存页了
这个时候，当你还要加载数据页到一个空闲缓存页的时候，怎么办呢？
那么此时你只有一个办法，就是淘汰掉一些缓存页
那什么叫淘汰缓存页呢？
顾名思义，你必须把一个缓存页里被修改过的数据，给他刷到磁盘上的数据页里去，然后这个缓存页就可以清空了，让他重新变成一个空闲的缓存页。
接着你再把磁盘上你需要的新的数据页加载到这个腾出来的空闲缓存页中去
如果要把一个缓存页里的数据刷入磁盘，腾出来一个空闲缓存页，那么应该把哪个缓存页的数据给刷入磁盘呢？
缓存命中率 假设现在有两个缓存页，一个缓存页的数据，经常会被修改和查询，比如在100次请求中，有30次都是在查询和修改这个缓存页里的数据。那么此时我们可以说这种情况下，缓存命中率很高
为什么呢？因为100次请求中，30次都可以操作缓存，不需要从磁盘加载数据，这个缓存命中率就比较高了。
另外一个缓存页里的数据，就是刚从磁盘加载到缓存页之后，被修改和查询过1次，之后100次请求中没有一次是修改和查询这个缓存页的数据的，那么此时我们就说缓存命中率有点低，因为大部分请求可能还需要走磁盘查询数据，他们要操作的数据不在缓存中。
所以针对上述两个缓存页，假设此时让你做一个抉择，要把其中缓存页的数据刷入到磁盘去，腾出来一个空闲的缓存页，此时你会选择谁？
那还用想么，当然是选择第二个缓存页刷入磁盘中了！
因为第二个缓存页，压根儿就没什么人来使用他里面的数据，结果这些数据还空占据了一个缓存页，这不是占着茅坑不拉屎么？
引入LRU链表来判断哪些缓存页是不常用的 接着我们就要解决下一个问题了，就是你怎么知道哪些缓存页经常被访问，哪些缓存页很少被访问？
此时就要引入一个新的LRU链表了，这个所谓的LRU就是Least Recently Used，最近最少使用的意思。
通过这个LRU链表，我们可以知道哪些缓存页是最近最少被使用的，那么当你缓存页需要腾出来一个刷入磁盘的时候，不就可以选择那个LRU链表中最近最少被使用的缓存页了么？
这个LRU链表大致是怎么个工作原理呢？
简单来说，我们看下图，假设我们从磁盘加载一个数据页到缓存页的时候，就把这个缓存页的描述数据块放到LRU链表头部去，那么只要有数据的缓存页，他都会在LRU里了，而且最近被加载数据的缓存页，都会放到LRU链表的头部去。
然后假设某个缓存页的描述数据块本来在LRU链表的尾部，后续你只要查询或者修改了这个缓存页的数据，也要把这个缓存页挪动到LRU链表的头部去，也就是说最近被访问过的缓存页，一定在LRU链表的头部</content></entry><entry><title>【转】InnoDB引擎更新数据过程</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-04-13-innodb%E5%BC%95%E6%93%8E%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E8%BF%87%E7%A8%8B/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">
SQL语句执行阶段 1.缓冲池（Buffer Pool）中查找记录，若找不到就去磁盘中查找然后加载到缓冲池
2.写undo日志文件 便于回滚
3.更新Buffer Pool中的数据（更新后Buffer Pool中的数据为脏数据）
4.Redo Log Buffer中写入修改日志
innodb_flush_log_at_trx_commit的值对应的情况: 0：提交事务的时候，不会把redo log buffer里的数据刷入磁盘文件 1：提交事务的时候，就必须把redo log从内存刷入到磁盘文件里去 2：提交事务的时候，把redo日志写入磁盘文件对应的os cache缓存里去，而不是直接进入磁盘文件，可能1秒后才会把os cache里的数据写入到磁盘文件里去 事务提交阶段 &amp;gt; MySQL binlog是什么？和Redo Log 的区别？ &amp;gt; redo log，他是一种偏向物理性质的重做日志，因为他里面记录的是类似这样的东西，“对哪个数据页中的什么记录，做了个什么修改”。 binlog叫做归档日志，他里面记录的是偏向于逻辑性的日志，类似于“对users表中的id=10的一行数据做了更新操作，更新以后的值是什么” 5.准备提交事务，将redo log buffer里的数据刷入磁盘文件 6.准备提交事务，将binlog日志写入磁盘文件中去
sync_binlog参数可以控制binlog的刷盘策略 0：把binlog日志写入磁盘文件对应的os cache缓存里去，而不是直接进入磁盘文件 1：把binlog日志进入磁盘文件 7:完成最终的事务提交
此时会把本次更新对应的binlog文件名称和这次更新的binlog日志在文件里的位置，都写入到redo log日志文件里去，同时在redo log日志文件里写入一个commit标记。
最后一步在redo日志中写入commit标记的意义是什么？ 是用来保持redo log日志与binlog日志一致的。 我们来举个例子，假设我们在提交事务的时候，一共有上图中的5、6、7三个步骤，必须是三个步骤都执行完毕，才算是提交了事务。那么在我们刚完成步骤5的时候，也就是redo log刚刷入磁盘文件的时候，mysql宕机了，此时怎么办？ 这个时候因为没有最终的事务commit标记在redo日志里，所以此次事务可以判定为不成功。不会说redo日志文件里有这次更新的日志，但是binlog日志文件里没有这次更新的日志，不会出现数据不一致的问题。 如果要是完成步骤6的时候，也就是binlog写入磁盘了，此时mysql宕机了，怎么办？ 同理，因为没有redo log中的最终commit标记，因此此时事务提交也是失败的。 必须是在redo log中写入最终的事务commit标记了，然后此时事务提交成功，而且redo log里有本次更新对应的日志，binlog里也有本次更新对应的日志 ，redo log和binlog完全是一致的。 8.后台IO线程随机将内存更新后的脏数据刷回磁盘</content></entry><entry><title>使用ProGuard混淆你的JAVA代码</title><url>/posts/java/2020-06-14-%E5%9C%A8maven%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%BD%BF%E7%94%A8proguard%E6%B7%B7%E6%B7%86%E4%BD%A0%E7%9A%84java%E4%BB%A3%E7%A0%81/</url><categories><category>Java</category></categories><tags><tag>Java</tag></tags><content type="html"><![CDATA[在Maven项目中使用Proguard十分简单 只要在pom文件的标签内添加如下代码即可
&lt;!-- ProGuard混淆插件--&gt; &lt;plugin&gt; &lt;groupId&gt;com.github.wvengen&lt;/groupId&gt; &lt;artifactId&gt;proguard-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;!-- 混淆时刻，这里是打包的时候混淆--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- 使用插件的什么功能，当然是混淆--&gt; &lt;goal&gt;proguard&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 是否将生成的PG文件安装部署--&gt; &lt;attach&gt;true&lt;/attach&gt; &lt;!-- 是否混淆--&gt; &lt;obfuscate&gt;true&lt;/obfuscate&gt; &lt;!-- 指定生成文件分类 --&gt; &lt;attachArtifactClassifier&gt;pg&lt;/attachArtifactClassifier&gt; &lt;options&gt; &lt;!-- JDK目标版本1.8--&gt; &lt;option&gt;-target 1.8&lt;/option&gt; &lt;!-- 不做收缩（删除注释、未被引用代码）--&gt; &lt;option&gt;-dontshrink&lt;/option&gt; &lt;!-- 不做优化（变更代码实现逻辑）--&gt; &lt;option&gt;-dontoptimize&lt;/option&gt; &lt;!-- 不路过非公用类文件及成员--&gt; &lt;option&gt;-dontskipnonpubliclibraryclasses&lt;/option&gt; &lt;option&gt;-dontskipnonpubliclibraryclassmembers&lt;/option&gt; &lt;!--不用大小写混合类名机制--&gt; &lt;option&gt;-dontusemixedcaseclassnames&lt;/option&gt; &lt;!-- 优化时允许访问并修改有修饰符的类和类的成员 --&gt; &lt;option&gt;-allowaccessmodification&lt;/option&gt; &lt;!-- 确定统一的混淆类的成员名称来增加混淆--&gt; &lt;option&gt;-useuniqueclassmembernames&lt;/option&gt; &lt;!-- 不混淆所有包名--&gt; &lt;option&gt;-keeppackagenames&lt;/option&gt; &lt;!-- 需要保持的属性：异常，注解等--&gt; &lt;option&gt;-keepattributes Exceptions,InnerClasses,Signature,Deprecated,SourceFile,*Annotation*,Synthetic,EnclosingMethod&lt;/option&gt; &lt;!-- 不混淆所有的set/get方法 --&gt; &lt;option&gt;-keepclassmembers public class * {void set*(***);*** get*();}&lt;/option&gt; &lt;!-- 不混淆所有的services.dao.ChargeDAO类内的所有方法方法 --&gt; &lt;option&gt;-keep class services.dao.ChargeDAO { *; }&lt;/option&gt; &lt;/options&gt; &lt;!--class 混淆后输出的jar包--&gt; &lt;outjar&gt;hx.jar&lt;/outjar&gt; &lt;!-- 添加依赖，这里你可以按你的需要修改，这里测试只需要一个JRE的Runtime包就行了 --&gt; &lt;libs&gt; &lt;lib&gt;${java.home}/lib/rt.jar&lt;/lib&gt; &lt;lib&gt;${java.home}/lib/jce.jar&lt;/lib&gt; &lt;/libs&gt; &lt;!-- 对什么东西进行加载，这里仅有classes成功，毕竟你也不可能对配置文件及JSP混淆吧--&gt; &lt;injar&gt;classes&lt;/injar&gt; &lt;!-- 输出目录--&gt; &lt;outputDirectory&gt;${project.build.directory}&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/plugin&gt; ]]></content></entry><entry><title>Hexo博客之Valine评论系统及邮件通知插件</title><url>/posts/blog/2020-02-22-hexo%E5%8D%9A%E5%AE%A2%E4%B9%8Bvaline%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E5%8F%8A%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5%E6%8F%92%E4%BB%B6/</url><categories><category>blog</category></categories><tags><tag>blog</tag></tags><content type="html">在之前的文章中曾经提到过Valine的评论系统，今天来系统的介绍一下使用方法和添加邮件提醒功能。 首先要感谢 Valine 开发好用的项目和DesertsP开发的 Valine-Admin 插件。
启用Valine评论系统 1.注册 LeanCloud 2.进入控制台创建应用 3.点击应用-设置-安全中心-Web安全域名，填入你的域名 4.点击应用-设置-应用Keys找到AppID、AppKey 5.找到hexo目录内主题文件夹（每个人都不同，我的是next）的_config.yml文件找到Valine，大概在633行附近，修改对应值 6.hexo三连就可以在文章页面看到评论系统了。
启用启用Valine评论系统 原作者的教程很详细了，这里就不简单搬运了，记录一下我遇到的一下小问题吧。 这是链接 1.提前弄明白邮箱的STMP 2.设置好变量后部署，修改变量后要重启实例才可以</content></entry><entry><title>Mac、PC常用软件分享</title><url>/posts/%E6%8A%80%E5%B7%A7/2019-12-23-macpc%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%88%86%E4%BA%AB/</url><categories><category>技巧</category></categories><tags><tag>常用软件</tag></tags><content type="html">记录在PC和Mac平台下常用的软件自己常用的几款软件
Mac Beyong Compare 文件及目录对比工具 PicGo 图床软件 Notepad&amp;ndash; Notepad++ 替代品 INNA 视频播放器 Motrix 配合油猴实现哔哩哔哩视频下载 Inspect 键盘测试和屏幕测试工具 Kap 屏幕录制工具 PasteNow 剪切板工具 Keka zip，rar打包解压工具 Parallels Desktop 虚拟机工具 Mos mac鼠标优化工具 github地址 fliqlo 时钟屏保工具 官网地址 PC 录屏软件-Captura Github 主页： https://github.com/MathewSachin/Captura/ 音乐软件-Listen1 Github 主页： https://github.com/listen1 磁盘分区-DiskGenius5.0 磁盘清理工具-CCleaner_Pro 电脑文件图形化-SpaceSniffer 解压缩软件-winrar 文件批量改名王1.3 图标提取BeCyIconGrabber Xshell and WinSCP win10优化工具-Dism++ 官网链接 https://www.chuyu.me/zh-Hans/index.html 下载工具-IDM</content></entry><entry><title>Python笔记之模拟键盘鼠标操作</title><url>/posts/python/2019-12-04-python%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%A8%A1%E6%8B%9F%E9%94%AE%E7%9B%98%E9%BC%A0%E6%A0%87%E6%93%8D%E4%BD%9C/</url><categories><category>python</category></categories><tags><tag>python</tag></tags><content type="html">前言：因为手上有两张电话卡，一张是接收验证码用的，而短信转发用的软件是mysms，不巧的是这款软件在ios端无法批量删除短信，好在可以在PC上的web页面处理，可惜仍无法批量操作，所以就有了下面这个简单的小脚本 程序内容：
from pykeyboard import * from pymouse import * import time m=PyMouse() k=PyKeyboard() for i in range(50): m.click(254,642,2) time.sleep(1) m.click(304,728,1) time.sleep(1) k.tap_key(k.enter_key) time.sleep(4) 很简单的一段程序，但是可以批量的完成一些重复的工作。
脚本使用前提 安装pyhook https://www.lfd.uci.edu/~gohlke/pythonlibs/ 根据Python版本下载对于的whl文件 pyHook‑1.5.1‑cp37‑cp37m‑win_amd64.whl pip install pyHook‑1.5.1‑cp37‑cp37m‑win_amd64.whl
安装pyuserinput pip install pyuserinput
一些方法介绍（搬运） 鼠标操作： m.click(x,y,button,n) 鼠标点击 x,y 是坐标位置 buttong 1表示左键，2表示点击右键 n 点击次数，默认是1次，2表示双击
m.move(x,y) –鼠标移动到坐标(x,y) 坐标可以通过QQ截图获取，在左上角开始点击，然后移动到需要点击位置就可以获取了 x_dim, y_dim = m.screen_size() –获得屏幕尺寸
键盘操作： k.type_string(‘Hello, World!’) –模拟键盘输入字符串 k.press_key(‘H’) –模拟键盘按H键 k.release_key(‘H’) –模拟键盘松开H键 k.tap_key(“H”) –模拟点击H键 k.tap_key(‘H’,n=2,interval=5) –模拟点击H键，2次，每次间隔5秒 k.tap_key(k.function_keys[5]) –点击功能键F5 k.tap_key(k.numpad_keys[5],3) –点击小键盘5,3次
联合按键模拟 例如同时按alt+tab键盘 k.press_key(k.alt_key) –按住alt键 k.tap_key(k.tab_key) –点击tab键 k.release_key(k.alt_key) –松开alt键</content></entry><entry><title>华硕ZX50JX4200黑苹果DSDT/SSDT修补总结(持续更新)</title><url>/posts/hackintosh/2019-10-19-%E9%BB%91%E8%8B%B9%E6%9E%9C%E4%B9%8B%E5%8D%8E%E7%A1%95zx50jx4200%E9%BB%91%E8%8B%B9%E6%9E%9Cdsdt-ssdt%E4%BF%AE%E8%A1%A5%E6%80%BB%E7%BB%93/</url><categories><category>hackintosh</category></categories><tags><tag>DSDT</tag><tag>hackintosh</tag></tags><content type="html"><![CDATA[提取 建议制作Ubuntu的U盘启动提取
反编译 使用iasl 联合反编译 将提取的原始 dsdt和ssdt文件重命名为xxx.aml（xxx为原始文件名）
一键改名命令 for i in *;do mv &quot;$i&quot; &quot;$i.aml&quot;;done
反编译命令 iasl -da -dl *.aml 删除所有aml文件，只保留dsl文件 rm *.aml
改错 不同设备或不同版本的bios可能提取的到文件反编译后错误不同，这里只总结了我遇到的错误
dsdt文件错误修复 1.PARSEOP_ZERO错误 使用Rehubman补丁源的“Fix PARSEOP_ZERO Error” 2.提示‘}&lsquo;错误 删除对应行的行Arg0 然后就没有错误了 但提示警告，不用理会
SSDT2错误修复 package (0x06) { 0x80000000, 0x80000000, 0x80000000, 0x80000000, 0x80000000, 0x80000000 } 这种错误使用派奇的补丁源的”SSDT_Package(){0x80000000}_Eror_Fix“修复 补丁地址
派奇 http://raw.github.com/Yuki-Judai/dxxs-DSDT-Patch/master SSDT3错误修复 cpupm变频文件 删除该dsl 使用脚本生成并代替该文件 脚本GitHub地址 https://github.com/Piker-Alpha/ssdtPRGen.sh SSDT9错误修复 PARSEOP_NAMESEG错误 使用[gfx0]Cleanup/Fix Errors(SSDT)修复
打补丁 除补充说明外，默认补丁源在RehubMan的笔记本补丁源
改名补丁(理论上需要所有的文件都要改名) 1.GFX0-&gt;IGPU 需要的文件（DSDT、SSDT5、SSDT6、SSDT9） 2.B0D3-&gt;HDAU 需要的文件（SSDT、SSDT5) 3._DSM-&gt;XDSM
显卡补丁 位于ssdt5 “[igpu]Haswell HD4400/HD4600/HD5000“
DSDT通用补丁 1.屏蔽独显 Disable fromm _REG(DSDT) Disable/Enable on _WAK/_PTS(DSDT)
2.修复睡眠 [sys]Fix _WAK Arg0 v2 [sys]Fix _WAK IAOE
3.电源管理 [sys]Haswell LPC
4.电量修复 [sys]Fix Mutex with non-zero Synclevel 派奇： [bat]ASUS N550/N551(JX JV)
5.USB内建 [usb]7-series/8-series USB
6.键盘灯(快捷键) 点击这里的 链接 7.其他修复 HPET fix IRQ fix RTC fix
]]></content></entry><entry><title>黑苹果之华硕笔记本键盘灯和Fn快捷键</title><url>/posts/hackintosh/2019-10-18-%E9%BB%91%E8%8B%B9%E6%9E%9C%E4%B9%8B%E5%8D%8E%E7%A1%95%E7%AC%94%E8%AE%B0%E6%9C%AC%E9%94%AE%E7%9B%98%E7%81%AF%E5%92%8Cfn%E5%BF%AB%E6%8D%B7%E9%94%AE/</url><categories><category>hackintosh</category></categories><tags><tag>hackintosh</tag></tags><content type="html">驱动华硕笔记本的键盘灯和快捷键需要两步
第一步：修改DSDT Haswell机型 打开反编译好的DSDT,搜索“Device (ATKD)”，在其定义下加入以下代码（包含关系）：
Name (BOFF, Zero) Method (SKBL, 1, NotSerialized) { If (Or (LEqual (Arg0, 0xED), LEqual (Arg0, 0xFD))) { If (And (LEqual (Arg0, 0xED), LEqual (BOFF, 0xEA))) { Store (Zero, Local0) Store (Arg0, BOFF) } Else { If (And (LEqual (Arg0, 0xFD), LEqual (BOFF, 0xFA))) { Store (Zero, Local0) Store (Arg0, BOFF) } Else { Return (BOFF) } } } Else { If (Or (LEqual (Arg0, 0xEA), LEqual (Arg0, 0xFA))) { Store (KBLV, Local0) Store (Arg0, BOFF) } Else { Store (Arg0, Local0) Store (Arg0, KBLV) } } Store (DerefOf (Index (PWKB, Local0)), Local1) ^^PCI0.LPCB.EC0.WRAM (0x04B1, Local1) // Haswell/Ivy ^^PCI0.LPCB.EC0.WRAM (0x044B, Local1) // Sandy/Ivy Return (Local0) } Method (GKBL, 1, NotSerialized) { If (LEqual (Arg0, 0xFF)) { Return (BOFF) } Return (KBLV) } Skylake机型 打开反编译好的DSDT,搜索“Method (SCDG, 1, NotSerialized)”，在这个method下方加入以下代码（注并列关系）：
Name (BOFF, Zero) Method (SKBL, 1, NotSerialized) { If (Or (LEqual (Arg0, 0xED), LEqual (Arg0, 0xFD))) { If (And (LEqual (Arg0, 0xED), LEqual (BOFF, 0xEA))) { Store (Zero, Local0) Store (Arg0, BOFF) } Else { If (And (LEqual (Arg0, 0xFD), LEqual (BOFF, 0xFA))) { Store (Zero, Local0) Store (Arg0, BOFF) } Else { Return (BOFF) } } } Else { If (Or (LEqual (Arg0, 0xEA), LEqual (Arg0, 0xFA))) { Store (KBLV, Local0) Store (Arg0, BOFF) } Else { Store (Arg0, Local0) Store (Arg0, KBLV) } } Store (DerefOf (Index (KBPW, Local0)), Local1) ^^PCI0.LPCB.EC0.WRAM (0x04B1, Local1) Return (Local0) } Name (KBPW, Buffer (0x10) { 0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99, 0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF }) Method (GKBL, 1, NotSerialized) { If (LEqual (Arg0, 0xFF)) { Return (BOFF) } Return (KBLV) } 第二步 加载驱动 将AsusNBFnKeys.kext放到Clover/kexts/other内
重启即可</content></entry><entry><title>Git技巧总结(持续更新)</title><url>/posts/%E6%8A%80%E5%B7%A7/2019-10-17-git%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/</url><categories><category>技巧</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[1.git设置快捷脚本 git config --global alias.bp &#39;!hexo clean;hexo g;gulp g;hexo d&#39; 然后使用 git bpush 就可以一键更新博客并发布了(cd 后面的目录为你的博客文件目录） 取消方式
git config --global --unset alias.bpush 2.git快速push(推荐使用方法二) 方法一 git config --global alias.fp &#39;!git add .;git commit -m &#34;快速push&#34;;git push&#39; 使用方式输入 git fp 就可以直接三连，但是无法手写commit信息
方法二 更新 2020年04月20日23:36:29
在win系统下可以 在项目目录添加一个批处理文件来实现一键推送，同时可以输入commit信息（推荐使用n++或者sublime工具编辑，并且将编码修改为ANSI) bat内容如下
git add . set /p m=输入更新内容 git commit -m %m% git push pause ####mac系统或则linux系统 添加一个shell脚本来实现同样的功能。 代码如下
git add . echo 输入更新内容 read m git commit -m $m git push 此时我们的项目目录就会多出我们添加的脚本文件，如何忽略它呢，其实很简单，只需要打开项目目录的 .gitignore 文件（隐藏文件，没有就新建一个）添加我们的脚本工具的文件名就可以。
3.让git显示颜色 git config --global color.ui true ]]></content></entry><entry><title>黑苹果之仿冒白苹果鼠标</title><url>/posts/hackintosh/2019-10-17-%E9%BB%91%E8%8B%B9%E6%9E%9C%E4%B9%8B%E4%BB%BF%E5%86%92%E7%99%BD%E8%8B%B9%E6%9E%9C%E9%BC%A0%E6%A0%87/</url><categories><category>hackintosh</category></categories><tags><tag>hackintosh</tag></tags><content type="html"><![CDATA[仿冒好处 如果你的鼠标有侧键，可以启用部分侧键的功能
需要工具 1.PlistEdit 2.Clover Configurator
正式过程 1.查看关于本机-硬件-USB 查找鼠标对应的产品ID(idProduct)和厂商ID(idVendor),记录下来并转为10进制 2.新建一个1.plist。 3.将下面内容复制到1.plist。并修改记录的10进制填入下面文本对应的地方（每个值对应2个地方,第22、24行和239、241行）。保存后鼠标右键点击1.plist，打开方式选择PlistEdit &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt; &lt;!DOCTYPE plist PUBLIC &#34;-//Apple//DTD PLIST 1.0//EN&#34; &#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd&#34;&gt; &lt;plist version=&#34;1.0&#34;&gt; &lt;dict&gt; &lt;key&gt;IOKitPersonalities&lt;/key&gt; &lt;dict&gt; &lt;key&gt;WiredMouse-1&lt;/key&gt; &lt;dict&gt; &lt;key&gt;CFBundleIdentifier&lt;/key&gt; &lt;string&gt;com.apple.driver.AppleUSBHIDMouse&lt;/string&gt; &lt;key&gt;HIDDefaultBehavior&lt;/key&gt; &lt;string&gt;Mouse&lt;/string&gt; &lt;key&gt;IOClass&lt;/key&gt; &lt;string&gt;AppleHIDMouse&lt;/string&gt; &lt;key&gt;IOProviderClass&lt;/key&gt; &lt;string&gt;IOUSBInterface&lt;/string&gt; &lt;key&gt;bConfigurationValue&lt;/key&gt; &lt;integer&gt;1&lt;/integer&gt; &lt;key&gt;bInterfaceNumber&lt;/key&gt; &lt;integer&gt;0&lt;/integer&gt; &lt;key&gt;idProduct&lt;/key&gt; &lt;integer&gt;100&lt;/integer&gt; &lt;key&gt;idVendor&lt;/key&gt; &lt;integer&gt;7847&lt;/integer&gt; &lt;/dict&gt; &lt;key&gt;WiredMouseAccel-1&lt;/key&gt; &lt;dict&gt; &lt;key&gt;AppleHIDMouseVersion&lt;/key&gt; &lt;integer&gt;256&lt;/integer&gt; &lt;key&gt;CFBundleIdentifier&lt;/key&gt; &lt;string&gt;com.apple.iokit.IOHIDFamily&lt;/string&gt; &lt;key&gt;HIDAccelCurves&lt;/key&gt; &lt;array&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;65536&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;0&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;524288&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;5243&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;70124&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;26214&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;8192&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;537395&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;1245184&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;6554&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;74711&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;36045&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;32768&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;543949&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;1179648&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;7864&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;79299&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;46531&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;45056&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;550502&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;1114112&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;9830&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;83886&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;57672&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;57344&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;557056&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;1048576&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;11796&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;88474&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;69468&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;65536&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;563610&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;983040&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;14418&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;93061&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;81920&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;98304&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;570163&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;917504&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;17695&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;97649&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;95027&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;131072&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;576717&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;851968&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;21627&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;102236&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;108790&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;163840&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;583270&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;786432&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;26214&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;104858&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;123208&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;196608&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;589824&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;786432&lt;/integer&gt; &lt;/dict&gt; &lt;/array&gt; &lt;key&gt;HIDDisallowRemappingOfPrimaryClick&lt;/key&gt; &lt;true/&gt; &lt;key&gt;HIDScrollAccelerationTable&lt;/key&gt; &lt;data&gt; AACAAFVTQioACAAAAAAAAQABAAAAAKAAAAAgAAARAACAAAABITgA APd3AAMEhQABkREABbM1AAIzMwAIjM8AAxmaAA0+ggAECIkAExyh AAT3dwAZ0VcABiIiACKz/AAHm7kAL60rAAkL5ABAlHUACubxAFm3 6AAMzfUAcQCiAA8nmwCKvFgAEdQ+AKNZoQAUyDoAwOAEABfUJwDY opEAG0+XAPCMwAAAUAAAEQAAgAAAAkgLAADu7wAFB4kAAWZmAAg2 +QACGZoADROXAALERAARml4AA5ERABciqAAEqqsAH4SMAAXVVQAp EtwAB1gvADlNsAAI+gEASsYnAArm8QBkfA4ADM31AH6QEgAPJ5sA m2JOABHUPgC2878AFQGcANyUtgAYFoAA+RU7ABtPlwENanAAAIAA ABEAAHd3AAP8iwAA5mYAB2dLAAFMzQALY9UAAczNAA+pRQACgAAA Fez7AANVVQAceZUABMzNACjcjQAGREQANfVWAAd3dwBC3IcACPd3 AFP6RgAK5vEAcIrxAAzN9QCNwBQADyebAK4HtAAR1D4AzOgJABUO wgD2msAAGCOmARWVwAAbT5cBLb7kAACwAAARAACIiQAHrbYAAPd3 AA0+ggABd3cAExyhAAIIiQAZUJYAAszNACGyegADzM0AKxXgAATu 7wA1pbIABhERAEDhMAAHme8AUcnXAAkQqwBjyIMACs/hAIEhmgAM zfUAnsKmAA8nmwDC6egAEgcEAOyw1QAVDsIBExtGABg8dQE2zfoA GwY+AUv0OgAA4AAAEQAAgAAACyXBAAD6sQAXwo4AAXgJACAlVgAC HyoAKTsFAALwEwAztn8AA/ixAD+XxgAFAVAAShNBAAYztgBV9IgA B1gvAGM7mgAI3d4AdvcJAAqzMwCV8gkADOQyALnh/gAPJ5sA2k2o ABHUPgEBCNoAFP1bASmGugAYJnkBUgSeABrppwFjp94AAQAAABEA ACqrAA2aKgAAbu8AG1SSAADd3gApDvoAAYiJADUF/QAClmEAQF4p AAOLXgBMUmQABKSmAFkyBgAF0BUAZSZBAAcx9AB2nuYACK+5AIkC 8QAKszMAp/BcAAzkMgDQMFAADyebAPR/7wAR1D4BH+D0ABT9WwFN OrwAGCZ5AXqUiAAa6acBjlWcAAGzMwARAAAqqwAPPAYAAG7vAB6c KQAA3d4ALfxLAAGIiQA7Yt4AApZhAEgXigADi14AVXsAAASkpgBj 5hsABdAVAHFJkQAHMfQAhNrtAAivuQCZc+8ACrMzALwXcQAM5DIA 6SvfAA8nmwER1vgAEdQ+AUJslgAU/VsBdTeKABgmeQGoAoQAGumn Ab4icg== &lt;/data&gt; &lt;key&gt;HIDScrollAccelerationTableX&lt;/key&gt; &lt;data&gt; AACAAFVTQioACAAAAAAAAQABAAAAAQAAAAAgAAARAACAAAACGcMA AQAAAAQq2wABd3cAB4BXAAIzMwAPfbMAAyqrABki6QAEEREAIeel AAUZmgAqYY4ABmZmADX7bgAHzM0AQ3pJAAlVVQBUNk8ACwAAAGel TQAM3d4AfcwjAA8zMwCaeMkAEd3eALqW3AAU5mYA23dyABfd3gD5 ZcEAGyIiARiOHAAAUAAADwAAgAAABDOHAAEAAAAKdCgAAgAAABkc CQADREQAKISDAASiIgA1EogABhERAER7AgAHzM0AVivaAAkZmgBm JmwACqIiAHqxuQAMZmYAkYVkAA73dwCw6G8AEZERANDdkgAVCIkA +D3nABgREQEXoPIAGxmaATakNgAAgAAADwAAgAAACBo6AAEIiQAU eswAAfd3ACNrCwADEREAM3TgAARMzQBC06EABcREAFQznQAHZmYA Zj6tAAk7vAB8TDEACxERAJRa8AANGZoArxX9AA87vADKfB4AEhER AO/oZAAVGZoBFVSqABgiIgE1aFIAGxmaAVS6UAAAsAAADwAAgAAA EDR1AAEIiQAeVxsAAczNAC2CqQAC1VUAPvS/AAP3dwBRKQMABYAA AGZl/AAHVVUAfel+AAk7vACW8VsACvd3AKzwggAM93cAyD7nAA9E RADl09UAEgiJAQyC5AAVEREBMzH0ABgIiQFTDWoAGxmaAXLQagAA 4AAADwAAgAAAGAHcAAEIiQAoNlEAAaqrADghJgACmZoAS9nEAAOz MwBhFr4ABTMzAHlcbQAG5mYAkyZ4AAiZmgCsLlQACoiJAMd8ugAM oiIA5RGoAA8REQEEKvAAEgAAASxeWgAVEREBUYkQABgzMwF0bTwA GxERAZDmhAABAAAADwAAgAAAIBwXAAEAAAA0Nz8AAZmaAEVwCwAC d3cAWkTbAAN3dwBvGasABPd3AIxrGwAGmZoAqPcIAAhu7wDHDfwA CkREAOLUZwAMZmYBAzviAA8ZmgEqlPoAEgiJAVUEHAAVGZoBfSK2 ABg7vAGke84AGwAAAcKK/AABszMAEAAAgAAAKB1XAAEAAABALvIA AXd3AFK8yQACEREAZBh0AAMZmgB/3fAABHd3AJ0zfQAFmZoAtISe AAbERADMlkwACCIiAObpowAJ1VUBBD8wAAwiIgErW+wADqqrAU92 cgARszMBfJeaABT3eAGpuMAAF+7vAdDVfAAbAAAB9C90 &lt;/data&gt; &lt;key&gt;HIDScrollResolution&lt;/key&gt; &lt;integer&gt;2818048&lt;/integer&gt; &lt;key&gt;HIDScrollResolutionX&lt;/key&gt; &lt;integer&gt;2818048&lt;/integer&gt; &lt;key&gt;IOClass&lt;/key&gt; &lt;string&gt;IOHIDEventDriver&lt;/string&gt; &lt;key&gt;IOHIDScrollReportRate&lt;/key&gt; &lt;integer&gt;8192000&lt;/integer&gt; &lt;key&gt;IOProviderClass&lt;/key&gt; &lt;string&gt;IOHIDInterface&lt;/string&gt; &lt;key&gt;ProductID&lt;/key&gt; &lt;integer&gt;100&lt;/integer&gt; &lt;key&gt;VendorID&lt;/key&gt; &lt;integer&gt;7847&lt;/integer&gt; &lt;/dict&gt; &lt;/dict&gt; &lt;/dict&gt; &lt;/plist&gt; 4.如下图所示，复制WiredMouse-1和WiredMouseAccel-1 5.如下图所示，用PlistEdit打开FakeSMC.kext，找到IOKitPersonalities，然后看下图提示 6.插入后应该是下图的样子 7.保存放入clover/kexts/other替换-重建缓存-重启即可 成功效果图 ]]></content></entry><entry><title>修改transmission配置，实现远程访问transmission</title><url>/posts/%E7%BE%A4%E6%99%96/2019-09-03-%E4%BF%AE%E6%94%B9transmission%E9%85%8D%E7%BD%AE%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/</url><categories><category>群晖</category></categories><tags><tag>transmission</tag><tag>远程</tag><tag>防痴呆</tag></tags><content type="html"><![CDATA[前言 如果没有修改下面设置也是能打开transmission的web界面，但是你会发现一片空白，提示正在连接服务器。 transmission实现远程访问要开启rpc-authentication-required
设置方法 找到transmission安装目录内的settings.json文件 使用notepad++或者sublime等文本编辑软件打开 修改以下地方：（大约在第43行开始） 1.将rpc-authentication-required和rpc-enabled修改为true，启用认证功能 2.rpc-username后设置为你的登录用户名 3.rpc-password后设置为你的密码 4.其他的就按下面的配置修改即可
&#34;rpc-authentication-required&#34;: true, &#34;rpc-bind-address&#34;: &#34;0.0.0.0&#34;, &#34;rpc-enabled&#34;: true, &#34;rpc-host-whitelist&#34;: &#34;&#34;, &#34;rpc-host-whitelist-enabled&#34;: true, &#34;rpc-password&#34;: &#34;123456&#34;, &#34;rpc-port&#34;: 9091, &#34;rpc-url&#34;: &#34;/transmission/&#34;, &#34;rpc-username&#34;: &#34;admin&#34;, &#34;rpc-whitelist&#34;: &#34;&#34;, &#34;rpc-whitelist-enabled&#34;: false, 这个配置的用户名为admin 密码为123456 注：密码修改后重启transmission，然后打开settings.json文件，rpc-password会变成了一串加密密钥。
]]></content></entry><entry><title>CentOS更换国内yum源</title><url>/posts/linux/2019-08-28-centos%E6%9B%B4%E6%8D%A2%E5%9B%BD%E5%86%85yum%E6%BA%90/</url><categories><category>linux</category></categories><tags><tag>Linux</tag></tags><content type="html">每次都去百度地址太费劲了，所以整理一下地址
更换方法 1.备份默认yum源
cd /etc/yum.repos.d mv CentOS-Base.repo CentOS-Base.repo.bak 2.下载更换国内yum源 阿里
wget http://mirrors.aliyun.com/repo/Centos-7.repo mv Centos-7.repo CentOS-Base.repo 网易
wget http://mirrors.163.com/.help/CentOS7-Base-163.repo mv CentOS7-Base-163.repo CentOS-Base.repo 3.清理缓存
yum clean all 4.重建缓存
yum makecache</content></entry><entry><title>清除Win10系统Windows Defender中病毒扫描记录</title><url>/posts/%E6%8A%80%E5%B7%A7/2019-06-23-%E6%B8%85%E9%99%A4win10%E7%B3%BB%E7%BB%9Fwindowsdefender%E4%B8%AD%E7%97%85%E6%AF%92%E6%89%AB%E6%8F%8F%E8%AE%B0%E5%BD%95/</url><categories><category>技巧</category></categories><tags><tag>防痴呆</tag></tags><content type="html">在使用一些小工具，小软件的时候 ⁨Windows Defender⁩经常提示木马或者病毒，而扫描到的病毒记录又没有清除按钮，让一些强迫症患者很难受。终于找到了扫描的历史记录位置，终于可以告别右下角的黄色叹号了。 文件位置： C:\ProgramData⁩\Microsoft⁩\Windows Defender⁩\Scans⁩\History⁩\Service⁩\DetectionHistory⁩ ProgramData⁩十个隐藏目录，查看隐藏目录也很简单，鼠标点两下就可以。</content></entry><entry><title>Centos配置本地yum源</title><url>/posts/linux/2019-06-19-centos%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0yum%E6%BA%90/</url><categories><category>linux</category></categories><tags><tag>Linux</tag></tags><content type="html">一、挂载镜像文件
mkdir /mnt/cdrom mount /dev/cdrom /mnt/cdrom 二、修改yum源配置文件
cd /etc/yum.repo.d rm -rf *.repo vi /etc/yum.repo.d/Localyum.repo 内容为：
[localyum] name=localyum baseurl=file:///mnt/cdrom gpgcheck=0 enabled=1 三、清空并重建缓存
yum clean all yum makecache</content></entry><entry><title>Linux下LVM及磁盘配额管理</title><url>/posts/linux/2019-04-22-linux%E4%B8%8Blvm%E5%8F%8A%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D%E7%AE%A1%E7%90%86/</url><categories><category>linux</category></categories><tags><tag>Linux</tag></tags><content type="html">一、实验目的 1.理解磁盘配额管理的概念和应用；掌握磁盘配额管理的命令； 2.理解LVM与普通磁盘分区的区别，掌握逻辑卷的创建、扩容等。
二、实验内容 1.LVM练习： （1） 新添加2块SCSI硬盘设备（每块8G），每块硬盘创建两个分区，每个分区4G（假设为sdb1,sdb2,sdc1,sdc2）； （2） 每个分区创建物理卷PV； （3） 创建卷组myvg,包含分区sdb1和sdc1； （4） 在卷组myvg上创建逻辑卷mylv（大小为4G），并基于该逻辑卷建立EXT4文件系统； （5） 扩充mylv逻辑卷到大小为6G，并查看该逻辑卷；
2.磁盘配额管理 （1） 将上题中的文件系统设置开机后自动挂载，并开启用户、组磁盘配额管理； （2） 添加用户组accp，以及该组中的用户jerry（密码为jerry） （3） 限制用户jerry最多只能使用50M磁盘空间， 当使用磁盘空间超过30M时，10天内给出警告；限制accp组的用户合计最多只能使用500M磁盘空间 （4） 使用dd命令创建文件验证用户jerry的配额限制； （5） 使用quota –u ……和repquota ….查看用户配额设置和磁盘使用情况。
##三、实验命令
LVM练习： 详情见 上一篇博客 每个分区创建物理卷PV； pvcreate /dev/sdb1 pvcreate /dev/sdb2 pvcreate /dev/sdc1 pvcreate /dev/sdc2 或者 pvcreate /dev/sdb1 /dev/sdb2 /dev/sdc1 /dev/sdc2 创建卷组myvg,包含分区sdb1和sdc1； vgcreate myvg /dev/sdb1 /dev/sdc1 在卷组myvg上创建逻辑卷mylv（大小为4G），并基于该逻辑卷建立EXT4文件系统； lvcreate -L 4G -n mylv myvg mkfs.ext4 /dev/myvg/mylv 扩充mylv逻辑卷到大小为6G，并查看该逻辑卷； lvextend -L +2G /dev/myvg/mylv lvscan 磁盘配额管理 将上题中的文件系统设置开机后自动挂载，并开启用户、组磁盘配额管理； mkdir /mnt/mylv vi /etc/fstab 在最后一行添加下面内容 /dev/myvg/mylv /mnt/mylv ext4 defaults,usrquota,grpquota 1 2 添加用户组accp，以及该组中的用户jerry（密码为jerry） groupadd accp useradd -g accp -p jerry jerry 限制用户jerry最多只能使用50M磁盘空间， 当使用磁盘空间超过30M时，10天内给出警告；限制accp组的用户合计最多只能使用500M磁盘空间 先创建磁盘配额管理文件 quotacheck -avug 本别编辑用户和用户组的磁盘配额管理文件 edquota -u jerry 修改soft下值为 30720 修改hard下值为 51200 edquota -g accp 修改hard下值为 512000 edquota -t 修改Block grace period下值为10days 使用dd命令创建文件验证用户jerry的配额限制； dd if=/dev/zero bs=1M count=33 of=/mnt/mylv/testfile1 使用quota –u和repquota查看用户配额设置和磁盘使用情况。 略</content></entry><entry><title>Hexo博客添加Live2D小宠物</title><url>/posts/blog/2019-04-18-hexo%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0live2d%E5%B0%8F%E5%AE%A0%E7%89%A9/</url><categories><category>blog</category></categories><tags><tag>博客</tag><tag>hexo</tag></tags><content type="html">在博客搭建之初这个插件我就用上了，时间久了，难免有些视觉疲劳，所以打算换个宠物。
项目地址 预览地址 一、安装Live2D插件 npm install --save hexo-helper-live2d npm install xxxxx //xxxxx是包名 下面是提供安装的列表，
live2d-widget-model-chitose live2d-widget-model-epsilon2_1 live2d-widget-model-gf live2d-widget-model-haru/01 (use npm install --save live2d-widget-model-haru) live2d-widget-model-haru/02 (use npm install --save live2d-widget-model-haru) live2d-widget-model-haruto live2d-widget-model-hibiki live2d-widget-model-hijiki live2d-widget-model-izumi live2d-widget-model-koharu live2d-widget-model-miku live2d-widget-model-ni-j live2d-widget-model-nico live2d-widget-model-nietzsche live2d-widget-model-nipsilon live2d-widget-model-nito live2d-widget-model-shizuku live2d-widget-model-tororo live2d-widget-model-tsumiki live2d-widget-model-unitychan live2d-widget-model-wanko live2d-widget-model-z16 二、修改配置文件 在博客根目录的_config.yml配置文件中添加下面的内容
#Live2D动画 live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-shizuku display: position: right width: 150 height: 300 mobile: show: true 主要参数说明
enable //是否使用 model: use: live2d-widget-model-shizuku //要使用的模型名称 display: position: right //显示的位置 width: 150 //宽度 height: 150 //高度 mobile: show: true //移动端是否显示 ##三、重新编译静态页面 下面的步骤就是Hexo三连 hexo clean hexo g hexo d</content></entry><entry><title>Linux下磁盘分区格式化</title><url>/posts/linux/2019-04-15-linux%E4%B8%8B%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E6%A0%BC%E5%BC%8F%E5%8C%96/</url><categories><category>linux</category></categories><tags><tag>Linux</tag></tags><content type="html">一、实验目的 了解linux系统支持的常用文件系统 掌握磁盘分区、格式化，以及磁盘分区挂载的相关命令和操作。 二、实验内容 背景：某公司中的Linux服务器中新增了一块硬盘/dev/sdb（大小6G），练习Linux系统下磁盘分区、文件系统的创建、挂载与卸载及自动挂载的实现。 在RHEL的虚拟机中添加一个新硬盘（6G大小），进行如下操作：
查看/dev目录下的磁盘文件情况； 使用fdisk命令新建/dev/sdb1主分区和/dev/sdb2扩展分区，并在扩展分区中新建逻辑分区/dev/sdb5和/dev/sdb6（每个分区大小为2G），分区完成后查看分区信息； 删除逻辑分区sdb6, 然后查看分区情况； 使用mkfs命令为sdb1主分区创建xfs文件系统，为sdb5创建ext4文件系统， 用fsck命令检查这两个文件系统； 用mount命令挂载sdb1到/mnt目录下的同名文件夹/mnt/sdb1中； 查看挂载情况，并卸载sdb1分区； 设置把这两个文件系统每次启动系统时自动挂载到/mnt中的同名文件夹/mnt/sdb1和/mnt/sdb5下。 三、实验步骤和实验过程(包含关键截图) 查看/dev目录下的磁盘文件情况 ls /dev 创建2G的主分区 fdisk /dev/sdb n p +2G //这里的命令是交互式的 注意屏幕的输出提示 创建拓展分区 n e +4G //这里的命令是交互式的 注意屏幕的输出提示 创建2个大小为2G的逻辑分区 n l +2G //这里的命令是交互式的 注意屏幕的输出提示 查看分区情况 p 删除sdb6 分区 d 6 //这里的命令是交互式的 注意屏幕的输出提示 格式化分区 mkfs -c type /dev/sdb1 mkfs.ext /dev/sdb1 //两者均可 检查分区 fsck /dev/sdb1 xfs_repair -f /dev/sdb1 //fsck不可检查xfs分区 挂载分区 mkdir /mnt/sdb1 mount /dev/sdb1 /mnt/sdb1 //要挂载到一个空文件夹 卸载分区 umount /dev/sdb1 umount /mnt/sdb1 配置开机自动挂载 vi /etc/fstab 添加 /dev/sdb1 /mnt/sdb1 xfs default 0 0</content></entry><entry><title>Docker神器之迅雷远程下载(群辉 Linux)</title><url>/posts/%E7%BE%A4%E6%99%96/2019-04-15-docker%E7%A5%9E%E5%99%A8%E4%B9%8B%E8%BF%85%E9%9B%B7%E8%BF%9C%E7%A8%8B%E4%B8%8B%E8%BD%BD%E7%BE%A4%E8%BE%89linux/</url><categories><category>群晖</category></categories><tags><tag>迅雷</tag><tag>Docker</tag><tag>经验</tag></tags><content type="html">镜像作者Docker 链接 2022年08月13日19:36:14 现在群晖已经有迅雷的官方客户端了&amp;hellip;
2019-10-16 19:45:58 更新 现在迅雷远程速度很慢，而且设备code也不一定能获取到了，所以不推荐使用了！
群辉下安装和使用 一、Docker下载迅雷远程镜像 注册表搜索 thunder-xware 并下载箭头指向的镜像:yinheli/docker-thunder-xware 二、安装镜像 勾选使用高权限执行容器 点击高级设置 在卷属性卡中点击添加文件，并选择你期望远程迅雷的下载位置（自定义） 装载路径为 /TDDOWNLOAD （不可更改！！！） 网络选择左下角的与Docker Host使用相同的网络 点击应用创建容器 点开Docker页面左侧的容器选项卡，点击刚创建的容器，然后点击左上角的详情 在弹出的页面中选择日志选项卡，找到最下面的THE ACTIVE CODE IS: aabbcc ,记录后面的代码 点击这个链接 http://yuancheng.xunlei.com) 登陆迅雷后输入刚才得到的代码即可。 Linux系统下安装和使用 一、安装Docker下载迅雷远程镜像 关于Docker的安装不在多说，请自行搜索安装教程 在终端中输入docker pull yinheli/docker-thunder-xware:latest 下载镜像
二、安装镜像 mkdir data 创建一个文件夹用于存放迅雷下载的资源
docker run -d --privileged=true \ --name=xware \ --net=host \ -v &amp;lt;自己选择要存放的位置&amp;gt;:/app/TDDOWNLOAD \ yinheli/docker-thunder-xware 注意这里命令中的data就是上面创建的文件夹，如果不同名记得修改命令中的地址 docker ps //查看当前运行的容器 docker logs xware //查看迅雷远程的日志 在日志的后几行会看到THE ACTIVE CODE IS: aabbcc这样一行代码，记录后面的代码。也就是设备CODE 点击这个链接 http://yuancheng.xunlei.com 登陆迅雷后输入刚才得到的代码即可。</content></entry><entry><title>Hexo博客个性化定制</title><url>/posts/blog/2019-04-13-hexo%E5%8D%9A%E5%AE%A2%E4%B8%AA%E6%80%A7%E5%8C%96%E5%AE%9A%E5%88%B6/</url><categories><category>blog</category></categories><tags><tag>博客</tag><tag>教程</tag></tags><content type="html"><![CDATA[前言 前段时间给博客换了个域名同时更新了博客的Next主题，最新版的7.1，之前是5.x版本。改动太多就直接clone，然后对照之前的一点点修改吧。这里简单记录一下个性化的设置。
直接在配置文件修改的地方 网站图标 favicon: 将图片定位到/theme/next/source/images 文章版权 creative_commons: 修改post属性为true 备案 beian: 菜单定制 menu: 社交 social: 友链 links: 头像 avatar: 阅读全文按钮 auto_excerpt: read_more_btn: 字符统计信息 symbols_count_time: 需要安装 插件 npm install hexo-symbols-count-time --save 同时根目录配置文件 symbols_count_time: 10. 打赏
reward_settings: enable: true animation: true comment: 自定义显示的内容 下面位置放入你的二维码
reward: wechatpay: /images/wechatpay.jpg alipay: /images/alipay.jpg Valine评论系统 # Valine # You can get your appid and appkey from https://leancloud.cn # More info available at https://valine.js.org valine: 本地搜索 local_search:
代码复制按钮 codeblock:
阅读人数 busuanzi_count:
将每篇文章的下方的标签的#改为图标 themes\next_config.yml
tag_icon: true 文章加密 cnpm install --save hexo-blog-encrypt title: 博客标题 date: 2022-06-07 23:05:38 password: 123456 这些都是我自己用到了一下配置，主题配置文件还有很多地方，大家可以去仔细看看
站点根目录配置文件和其他的地方 汉化 language: zh-CN 之前版本是zh-Hans 新版本更新了 网站标题和描述 title: description: 新建博文时文件名添加当前时间 new_post_name: :year-:month-:day-:title.md 添加网站萌宠 https://github.com/xiazeyu/live2d-widget.js https://l2dwidget.js.org/docs/class/src/index.js~L2Dwidget.html#instance-method-init 修改全局背景 /theme/next/source/images目录放入你的背景图片命令为background.jpg 然后在/theme/next/source/css/_custom/custom.sty中添加下面代码 // Custom styles. @media screen and (min-width:1200px) { body { background-image:url(/images/background.jpg); background-repeat: no-repeat; background-attachment:fixed; background-position:50% 50%; background-size:cover } #footer a { color:#eee; } } 在底部增加运行时间 在 themes\next\layout_partials\footer.swig 中新增 &lt;!-- 在网页底部添加网站运行时间 --&gt; &lt;div&gt; &lt;span id=&#34;timeDate&#34;&gt;载入天数...&lt;/span&gt;&lt;span id=&#34;times&#34;&gt;载入时分秒...&lt;/span&gt; &lt;/div&gt; &lt;script&gt; var now = new Date(); function createtime() { var grt= new Date(&#34;10/21/2018 00:00:00&#34;);//此处修改你的建站时间或者网站上线时间 now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 ){hnum = &#34;0&#34; + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = &#34;0&#34; + mnum;} seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 ){snum = &#34;0&#34; + snum;} document.getElementById(&#34;timeDate&#34;).innerHTML = &#34;Run for &#34;+dnum+&#34; Days &#34;; document.getElementById(&#34;times&#34;).innerHTML = hnum + &#34; Hours &#34; + mnum + &#34; m &#34; + snum + &#34; s&#34;; } setInterval(&#34;createtime()&#34;,250); &lt;/script&gt; 暂时就想起来这么多，以后会一点点完善的 关于搭建博客可以看我的另一篇文章 这是链接 ]]></content></entry><entry><title>FRP内网穿透访问家中的NAS和路由器后台</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-04-11-frp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E8%AE%BF%E9%97%AE%E5%AE%B6%E4%B8%AD%E7%9A%84nas%E5%92%8C%E8%B7%AF%E7%94%B1%E5%99%A8%E5%90%8E%E5%8F%B0/</url><categories><category>软路由</category></categories><tags><tag>内网穿透</tag><tag>群晖</tag></tags><content type="html">前言 自从入手了蜗牛星际以后，一直在折腾，先是安装了软路由，现在换成了PVE下虚拟LEDE软路由和黑群晖。可以远程访问的NAS才是一个完整的NAS,由于在宿舍大家一块用一条网线，虽然有公网地址，但联通公司不给改桥接，后来想想也挺麻烦的，而且宿舍的网线也只有4芯，即使路由器拨号也无法多播，就放弃DDNS了。于是开始研究内网穿透。
为什么要用FRP 1.没钱购买花生壳的付费服务，免费的局限性太大 2.学习一些新的东西
对FRP的理解 感觉frp和远程代理很像，支持的底层协议也很丰富，配置相对简单，而且不需要安装。通过命令行方式启动，有一点Linux基础的用户就可以完美驾驭。 作者 github主页 根据作者的介绍，frp的基础功能是实现远程tcp访问和ssh链接。而用的更多的确实http协议带来的远程web链接，访问家中的NAS和路由器后台。
下载以及配置 直接在github页面下载即可(注意服务的与客户端的版本尽量相同) 配置过程 下载frp： wget https://github.com/fatedier/frp/releases/download/v0.26.0/frp_0.26.0_linux_amd64.tar.gz 解压： tar -zxvf frp_0.26.0_linux_amd64.tar.gz 进入解压后的文件夹： cd frp_0.26.0_linux_amd64.tar.gz 编辑服务端配置文件： vi frps.ini 输入i进入编辑模式 i
根据文章后面的内容进行具体配置 编辑完成后按一下键盘左上角esc键退出编辑 输入:wq保存并退出 启动frp服务端并保持后台运行 （第一次测试时不需要&amp;amp;符号即可前台运行，ctrl+c即可退出） nohup ./frps -c ./frps.ini &amp;amp;
客户端和服务端类似，不过将frps更换为frpc （这里的s就是server服务端，c就是client客户端） 下载frp： wget https://github.com/fatedier/frp/releases/download/v0.26.0/frp_0.26.0_linux_amd64.tar.gz 解压： tar -zxvf frp_0.26.0_linux_amd64.tar.gz 进入解压后的文件夹： cd frp_0.26.0_linux_amd64.tar.gz 编辑客户端配置文件： vi frpc.ini// 输入i进入编辑模式 i
根据文章后面的内容进行具体配置 编辑完成后按一下键盘左上角esc键退出编辑,保存并退出 :wq 记得按esc退出编辑状态 启动frp服务端并保持后台运行 nohup ./frpc -c ./frpc.ini &amp;amp;
服务端配置文件 [common] #服务器ip bind_addr = 0.0.0.0 #frp端口 bind_port = 7000 #口令配置 token = xxx ##frp协议和端口配置 （根据自己的需要保留即可） bind_udp_port = 7001 kcp_bind_port = 7002 vhost_http_port = 80 vhost_https_port = 443 ##frp的统计信息，可以浏览器输入http://服务器ip:7500查看，账号密码为admin，可以在下面配置中修改 dashboard_addr = 0.0.0.0 dashboard_port = 7500 dashboard_user = admin dashboard_pwd = admin ##frp日志配置 log_file = ./frps.log log_level = info log_max_days = 3 客户端配置文件 [common] ####IP也可以是域名 server_addr = x.x.x.x frp服务器端口 server_port = 7000 #口令配置，要和服务端一致 token = xxx ##frp日志配置 （根据自己的需要保留或者删除） log_file = ./frpc.log log_level = info log_max_days = 3 #[]里面的内容自定义，建议用作标示 [lede] type = http local_ip = 192.168.123.1 local_port = 80 custom_domains = xxx.youdomain.com [nas] type = http local_ip = 192.168.123.102 local_port = 5000 custom_domains = yyy.youdomain.com [pve] type = https local_ip = 192.168.123.100 local_port = 8006 custom_domains = zzz.youdomain.com #这里我的客户端配置，三个域名分别对应三个不同的web页面 #custom_domains是自己的域名 ## 解决远程Transmission无法使用 修改Transmission的配置文件settings.json ，启动密码登录即可（大约在第43行开始） 个人猜测这个白名单在内网穿透时无效。（未经验证） ``` "rpc-authentication-required": true, "rpc-bind-address": "0.0.0.0", "rpc-enabled": true, "rpc-host-whitelist": "", "rpc-host-whitelist-enabled": true, "rpc-password": "{925c1d0775d6e63d3ccd87a8f97f48d38e9f013fupumAV6s", "rpc-port": 9091, "rpc-url": "/transmission/", "rpc-username": "admin", "rpc-whitelist": "", "rpc-whitelist-enabled": false, ``` ## 总结 FRP整体配置还是比较简单的，只要了解了其原理就能轻松使用。</content></entry><entry><title>蜗牛星际之安装PVE+LEDE+群辉</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-04-06-%E8%9C%97%E7%89%9B%E6%98%9F%E9%99%85%E4%B9%8B%E5%AE%89%E8%A3%85pvelede%E7%BE%A4%E8%BE%89/</url><categories><category>软路由</category></categories><tags><tag>软路由</tag><tag>虚拟机</tag><tag>LEDE</tag><tag>PVE</tag></tags><content type="html">前言 上次安装了LEDE软路由后，也挂载了一个500G的硬盘，但总感觉对于J1900+4G内存来说有点浪费，还有那么大哥机箱，如果不做NAS有点对不起他的体积，在加上本来就是个矿机就尽量多压榨一下他的性能。 这里只是简单些一下安装流程，不打算上传图片了，更加详细的教程可以看下面的链接 蜗牛矿渣装机教程 篇一：搞定PVE虚拟机 作者主页有更多的教程，一共四个系列。
一、准备 1.规划IP地址 按照自己的需求规划好IP地址，尽量用纸记下来，省的以后乱套。
建议将PVE地址规划为软路由lan口的子网地址 例如192.168.123.100
群辉地址也为lan口的子网地址 例如192.168.123.102(这里的102是PVE的虚拟机序号，默认是从100开始)
2.制作U盘启动 两个优盘，一个装PE，一个装PVE镜像
PE直接用老毛桃即可。
用win32磁盘映像工具将pve的iso镜像写入U盘
3.恢复bios默认设置 开机接键盘后按del进去bios，然后按F9恢复默认设置，然后F10保存并退出。
二、安装PVE 插入老毛桃优盘进入PE，进入后将内置16G的mSATA所有分区删除，然后建立一个新分区。NTFS格式，取消勾选ESP和EFI。
关机，拔出老毛桃U盘，插入刻录PVE镜像的优盘启动盘。
开机按F11选择UEFI开头的U盘，进入PVE安装界面
根据指示安装完成即可。(这里会提示设置PVE的IP地址、子网掩码和网关)
添加网卡桥接，默认只有一个桥接网卡，按照格式添加新的桥接网卡即可。建议备注好WAN和LAN口。因为蜗牛只有2个网卡，所以备注好WAN和LAN同时在机箱后备注好WAN和LAN。
三、安装LEDE 新建虚拟机，选择不适用任何介质，硬盘分配1G-2G即可(后面远程连接需要安装docker，所以分配够用即可)，合理配置内存与核心（1G+4cores），网卡选择E1000。
下载LEDE镜像并解压。
将img2kvm和解压后的镜像上传到PVE的root目录
root目录下指令下面命令(Linux系统当前用户目录显示为~)
chmod +x img2kvm ./img2kvm lede.img 101(虚拟机编号) lede-leader-disk(这里可以自定义的) 在虚拟机的硬件页面添加新建的磁盘文件，硬盘接口尽量选择sata
硬件添加一个新的网卡。
在选项页面调整启动顺序，将新加的文件设置为第一引导
启动虚拟机，并在控制台修改LAN口IP,然后reboot即可。
四、安装群辉 和LEDE类似，新建虚拟机，硬盘分配4G以上，配置为3G+4cores,网卡选择E1000。
同样的方法挂载引导磁盘，控制器一定要选SATA，不然无法获取IP.
调整启动顺序，将引导磁盘设置为第一启动项。
下载群辉助手，搜索，安装即可。(这一步用群辉助手搜索即可，可以挂载好硬盘再安装。)
如果搜索不到的话看一下本机IP是否在LEDE分配的网段下，因为的我网络环境是光猫拨号，直接获取到光猫分配的IP，导致无法搜索，建议在断网的环境下安装群辉。
五、群辉挂载磁盘 关闭群辉虚拟机
插入硬盘
用下面的命令查看硬盘名称
cd /dev/disk/by-id ls 复制磁盘名
用下面的命令挂载到群辉虚拟机 qm set 102(群辉ID) -sataX(X为序列号，不可与之前的重复) /dev/disk/by-id/XXXXX(XXXX为硬盘名称)
挂载好以后可以将之前的4G虚拟硬盘分离，然后删除即可。
总结 一定要提前规划好IP
群辉引导一定要选择SATA.
群辉洗白可以挂载一个ISO格式PE镜像，作为第一引导，在控制台页面修改sn和mac即可。
当LEDE作为二级路由，即WAN口协议为DHCP客户端时，要在LAN口的DHCP服务器高级设置中勾选‘强制’ //即使检测到另一台服务器，也要强制使用此网络上的 DHCP。</content></entry><entry><title>Docker神器之百度云下载(群辉 LEDE)</title><url>/posts/%E7%BE%A4%E6%99%96/2019-03-30-docker%E7%A5%9E%E5%99%A8%E4%B9%8B%E7%99%BE%E5%BA%A6%E4%BA%91%E4%B8%8B%E8%BD%BD%E7%BE%A4%E8%BE%89lede/</url><categories><category>群晖</category></categories><tags><tag>Docker</tag><tag>下载</tag><tag>LEDE</tag></tags><content type="html">前言 入手了蜗牛星际，安装了lede以后发现酷软中心的aria2和tr都不能正常工作，可能是版本bug，无意间在论坛发现了利用docker这一神奇运行百度云第三方下载，尝试一番发现确实很好用，记录一下折腾的过程。 原贴： http://koolshare.cn/thread-154383-1-1.html 我没有使用原贴中的镜像 而是选择了另一位大神oldiy的镜像，下面是他的DockerHub主页和博客。 https://hub.docker.com/u/oldiy/ https://odcn.top/ LEDE软路由下使用 第一步 LEDE酷软中心安装Docker插件 这里不多解释，直接安装即可
第二步 配置Docker插件 按照下图的设置即可 第三步 下载相关镜像 在注册表页搜索相关镜像即可，如下图为百度云下载 第四步 创建容器 在镜像页选择已经下载的镜像创建即可。 在这里对容器进行相关配置，注意端口，和容器中给定的相同最好 下面这一张图就能看明白端口和目录的设置了 简单来说就是端口号正确且不与lede其他程序冲突就可以进入后台 地址正确才能保证文件下载到你指定的位置 然后点击创建即可
进入Web页面查看安装情况 启动成功后就可以通过下面的链接进入web页面了 http://你的路由器ip:5299 //这里的5299就是配置容器时的端口，尽量和dockerhub的相同。如果不同应该是进不去相关页面的 使用自己的百度账号登录即可，然后点击右上角的设置 注意这里的目录，不要修改使用默认即可 群辉下使用 （更新内容） 第一步 群辉套件中心安装Docker插件 不多解释
第二步 下载镜像 在注册表搜索baidu下载下图中的镜像 第三步 配置镜像 按照下图配置即可，配置完成后会自动启动容器 配置下载路径 配置端口 第四步 打开Web管理页面 浏览器输入 &amp;lt;你的IP&amp;gt;:5299 进入web页面
解决百度云限速 web的设置页面修改appid为
265486 默认工作目录修改为
/apps/baidu_shurufa 百度输入法不限速，所以修改为输入法的id 而默认工作目录就是登陆页面后所展现的目录 把要下载的文件移动到/apps/baidu_shurufa 下载即可 需要操作其他文件的时换回 266719 即可
结束 2019年03月30日15:02:07 更新 2019年04月18日23:24:00</content></entry><entry><title>软路由LEDE系统之samba局域网共享</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-03-29-%E8%BD%AF%E8%B7%AF%E7%94%B1lede%E7%B3%BB%E7%BB%9F%E4%B9%8Bsamba%E5%B1%80%E5%9F%9F%E7%BD%91%E5%85%B1%E4%BA%AB/</url><categories><category>软路由</category></categories><tags><tag>软路由</tag><tag>LEDE</tag><tag>samba</tag></tags><content type="html">前言 上周末看油管的时候发现了一款极具性价比的NAS-蜗牛星际。矿渣nas，三月初就开卖了，当时好像200包邮。我入手有点晚所以价格也高一些。290包邮。不过卖家给改好了双千兆网络。虽然是矿渣，但我这台内部没有多少灰尘。只有风扇上有灰。应该没运行多久。到手后由于没4有显示器和电源线。就去楼下电脑维修店买了根电源线，顺便借老板显示器装了系统。 很久之前就想入手软路由了，但是动不动就上千的售价实在是难以接受。看到这个性价比还不错的就入手了。之前用的是k2p。没有usb接口，局域网共享就很难实现，而且就算有U盘，24小时工作也承受不了。现在终于可以好好享受一下samba带来的便携了。后期应该还会安装黑群辉实现更多的功能。 如果你的软路由主板usb借了移动硬盘或者sata口连接了机械硬盘，这一步是不需要做的。 蜗牛星际主板上带了一个16G的固态硬盘。性能极差。和3.0的U盘速度差不多。装lede还勉强可以接受。现在没有硬盘也只能用这个来代替了。 我安装的是 koolshare论坛 的lede系统，酷软中心很多插件，还是挺好用的。 注：本文借鉴了koolshare论坛的两个帖子 这里简单做了一些总结，和一些自己的经验
http://koolshare.cn/thread-154153-1-1.html http://koolshare.cn/forum.php?mod=viewthread&amp;tid=110543&amp;highlight=samba 一、为安装盘剩余的空间创建新分区 如果你的软路由主板usb借了移动硬盘或者sata口连接了机械硬盘，这一步是不需要做的。
先运行分区工具 fdisk /dev/sda 输入p查看当前分区 ### 输入n创建新的分区 这里由于我已经创建 就不在截图了 直接连续三次回车键，会默认将剩余的空间创建为一个新的分区。 ### 输入w保存分区 完成后会退出分区工具 ### 使用mkfs命令格式化新建的分区 `mkfs.ext4 /dev/sda5` 说明 etx4是文件系统。如果是固态的话建议修改为f2fs。后面的sda5是新建的分区，分区名根据自己的修改即可。 `mkfs.f2fs /dev/sda5` （固态硬盘推荐使用） ### 赋予新添加的分区权限 `chmod -R a+rwx /mnt/sda5` ### 重启，使分区表生效（好像不重启也可以，不过还是建议重启） ## 二、挂载新创建的分区 如果你的软路由主板usb借了移动硬盘或者sata口连接了机械硬盘，这一步也是不需要做的。 这里就很简单了，打开路由器管理界面简单设置即可 选择挂载点，在自定义位置填入`/mnt/sda5` (挂载器要创建这个空文件夹，注意不要输错了) ## 三、将新创建的分区添加到samba的共享目录 这里也很简单 按照下图的设置即可 ### 给samba用户添加密码 `smbpasswd -a root` （终端输入） 然后输入密码回车 最后重启一下软路由即可（想偷懒就直接重启samba服务即可） ## 总结 其实对于大多用户来说，都会挂载一个硬盘来当做简易的NAS来使用。 核心内容就是下面三步 1.添加samba用户 2.为用户设置密码 3.添加该用户可以访问的目录 这里我偷懒，加上在家里用，root用户就可以。不必要弄那些复杂的内容。 嗯，就这样 2019年03月30日00:28:30</content></entry><entry><title>Hexo静态博客搭建总结</title><url>/posts/blog/2019-03-20-hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%80%BB%E7%BB%93/</url><categories><category>blog</category></categories><tags><tag>总结</tag><tag>博客</tag><tag>hexo</tag></tags><content type="html"><![CDATA[第一次搭建博客大约是在18年6月份。当时是在腾讯云vps上安装宝塔，然后宝塔内部一键安装WordPress博客。在18年12月份发现Github+hexo这一神奇组合，果断尝试。然后又经历了期末考试和过年，博客也算是搁置了一段时间。前几天才重新捡起，然后又系统的自学了一下Git。所以打算写这个博客简单记录一下最基础的内容，可能有些小白看不懂，后期可能会慢慢完善的。
一、什么是Git、Github、Hexo？ 首先要知道这是完全不同的三个东西，但三者结合起来就会发生奇妙的反应。
什么是Git？ Git是一个的分布式版本控制系统。
什么是Github？ Github是一个提供免费服务的代码托管网站。
什么是Hexo？ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown (或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。(摘抄自hexo官网)
如果对github和git的关系感兴趣，可以去这个网站简单了解一下 Git 二、安装Git、Node.js和hexo 在以下网址下载软件 Git官网下载地址 https://www.git-scm.com/download/ node.js官网下载地址 https://nodejs.org/en/ （建议下载LTS版本）
这两款软件选好安装目录使用默认设置即可
NodsJS 安装备注说明 安装后在用户目录下新建nodejs目录然后再创建node_global和node_cache目录,并用下面命令将其设置为默认安装和缓存位置
npm config set prefix &#34;/Users/sxz799/nodejs/node_global&#34; npm config set cache &#34;/Users/sxz799/nodejs/node_cache&#34; 国内环境使用淘宝镜像命令
npm config set registry=http://registry.npm.taobao.org hexo安装 安装好git和node.js后新建一个你要放置博客的文件夹，然后鼠标右键点击 Git bash here，在弹出的窗口输入下面的命令(实际上在任意文件夹下都可以 ，hexo安装的目录由node.js的配置决定)
npm install -g hexo-cli 三、Hexo博客相关内容 初始化hexo博客 在博客目录鼠标右键点击 Git bash here 在弹出的窗口依次输入
hexo init npm install npm install hexo-deployer-git --save 这三条命令的意思分别是: 初始化博客 安装hexo需要的依赖包 安装部署到github所需要的依赖包 这时就可以写博客了（建议先了解一下md语法然后下载一个md编辑器进行创作）
hexo n 博客文章名 hexo g hexo s 这三条命令的意思分别是: 1.在source/_post目录生成对应md文件 2.hexo转化为静态网页 3.本地服务器，可以实时预览博客 建议先了解一下md语法然后下载一个md编辑器进行创作 完成这一步 在浏览器打开下面的链接
http://localhost:4000/
就可以看见系统默认的一篇博客了和你写的博客了
到这里博客就大致成型了 但是服务搭建在本地是没有什么意义的，我们需要发布到互联网。可以选择购买服务器，自行搭建git服务，也可以用github免费的代码托管服务
注册github并新建博客仓库 github官网 https://github.com/ 自行注册 然后新建一个名为 xxx.github.io 的仓库 //xxx为你的github用户名，这里不能错！！！不能自定义，必须要和github用户名相同
生成ssh密钥并将公钥添加到github(2022年08月13日00:47:05 github更新后不再支持这用模式！) 在命令提示符输入
ssh-keygen -t rsa -C &quot;注册github时的email&quot; 打开用户目录下隐藏的.ssh文件夹，打开id_rsa.pub文件，复制全部内容，粘贴到github的ssh处
修改博客配置文件 配置博客目录下的_config.yml配置文件
这时就可以通过下面的命令将博客同步到github的仓库中
hexo d
接下来就可以在链接到互联网的设备中输入下面链接访问你的博客了
http://xxxxx.github.io //xxxxx为你的用户名
四、添加DNS个性化域名并使用cdn加速 注册一个域名 这一步不详细介绍了，域名自己选购
添加域名解析 域名解析的记录类型为CNAME 记录值为xxxxx.github.io //xxxxx为你的用户名
在博客目录的source文件夹添加一个CNAME文件 没有.txt或者其他
文件内容为个人域名(注意：没有http://和www)
然后一系列的命令同步到github远程仓库
hexo clean hexo g hexo d 等域名解析更新后就可以通过域名访问博客了
五、新电脑上继续写博客 现在新电脑上安装Git 、 node.js
克隆远程代码到本地 git clone xxxxxxx 安装hexo npm install hexo-cli -g 安装hexo需要的依赖包 npm install 然后就是正常些博客的步骤了
快速发布博客快捷设置 git config --global alias.bp &#39;!hexo clean;hexo g;gulp g;hexo d&#39; 然后使用 git bp 就可以一键更新博客并发布了 取消方式
git config --global --unset alias.bp 快速推送 git config --global alias.fp &#39;!git add .;git commit -m &#34;快速push&#34;;git push&#39; 取消方法同上，不建议使用，最好老老实实写commit
关于博客的个性化可以看我的另一篇文章 链接 转载注明出处 谢谢
]]></content></entry><entry><title>VMware虚拟机体验koolshare论坛LEDE固件</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-03-17-vmware%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%BD%93%E9%AA%8Ckoolshare%E8%AE%BA%E5%9D%9Blede%E5%9B%BA%E4%BB%B6/</url><categories><category>软路由</category></categories><tags><tag>虚拟机</tag><tag>路由器</tag><tag>LEDE</tag></tags><content type="html">​ 博主自用的是路由器是斐讯K2P A2版，性能足够满足大多数家庭的需要了，但还是听说koolshare论坛的lede固件功能丰富，是软路由很常用的固件。只是现在用不到，也没有条件使用（毕竟价格接近4位数）。但看论坛截图里丰富的功能有些手痒，就打算在虚拟机里装上过过瘾。
一、固件下载 链接：http://firmware.koolshare.cn/LEDE_X64_fw867/ ​链接是x64设备用的固件，有img格式和vmdk虚拟机专用的格式，这里选择虚拟机专用格式下载。
二、安装LEDE 和安装其他虚拟机没有什么区别，有几处需要注意的地方我已经在图中标记出来了。 安装到这里就差不多了。主要区别就是选择稍后安装操作系统，然后磁盘选择第一步中下载的文件和添加了一张网卡而已。 安装后不要启动！ 安装后不要启动！ 安装后不要启动！
三、虚拟机网卡配置 和上一篇文章类似，设置VMware虚拟网卡。这里设置桥接网卡为计算机的网卡。nat地址和上一篇文章一样。 然后设置lede系统的网卡 配置好以后启动虚拟机。启动完毕后鼠标点击虚拟机内部 然后输入 vi /etc/config/network 修改lan口的地址 然后取消勾选本地连接中的ipv4和ipv6协议。 重点！重点！重点！重点！
四、配置VMware Network Adapter VMnet8 和上篇文章不同的是，这里我们的目的是通过虚拟机路由器系统进行上网，所以要配置上网关 如下图 教程结束！ //2019年03月20日19:26:46 更新
转载注明出处 谢谢</content></entry><entry><title>虚拟机内系统通过NAT方式连接外网，同时与本机进行通信</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-03-13-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E7%B3%BB%E7%BB%9F%E9%80%9A%E8%BF%87nat%E6%96%B9%E5%BC%8F%E8%BF%9E%E6%8E%A5%E5%A4%96%E7%BD%91%E5%90%8C%E6%97%B6%E4%B8%8E%E6%9C%AC%E6%9C%BA%E8%BF%9B%E8%A1%8C%E9%80%9A%E4%BF%A1/</url><categories><category>软路由</category></categories><tags><tag>学习</tag></tags><content type="html">前言 就在今天下午上课的时候突然发现自己好久没有写blog了，可能最近学习太忙，也可能最近没啥好写的。今天上课的时候有同学问到我关于虚拟机系统连接外网的问题，所以打算写这么一篇blog，也算加深一下自己的印象吧。
自求学以来，实验课用到的虚拟机软件都是VMware，相信大部分人对这个软件也不陌生，除了这个就是win10自带的Hyper-V虚拟机了.这里就简单的写一下VMware用NAT方式连接外网。
第一步 配置VMware的虚拟网络编辑器 ① 在VMware的菜单栏中点击编辑，在弹出的菜单中选择虚拟网络编辑器，在弹出的窗口中点击更改设置，可能会提示需要管理员权限，确定即可。 ② 在新弹出的界面中点击VMware8 这是VMware默认的nat模式，可以用这个默认的网络，也可以新建一个，这里没有什么区别。选中该网络后修改配置为图中的配置。下方的子网网段可自己定义。没有什么影响，只要不和上面的网络冲突即可（建议使用默认的）。然后点击图中的NAT设置，网关可以修改，建议使用默认，并记住这个网关。 ③ 设置虚拟机网卡为VMware8 NAT模式，这个就很简单了，根据图中的步骤来即可。到这里VMware的设计就完成了。 第二步 修改虚拟机系统的网络连接设置 这一步非常简单，因为大家用的系统不一样，设置界面也不尽相同，这里以centos7系统为例，简单介绍一下。这里的IP地址不是固定的只要在同一网段内即可。但是网关地址一定是上一步中nat设置中的网关地址。完成这一步虚拟机应该就可以连接外网使用百度了。 三 建立虚拟机与宿主机的连接。 此时虚拟机虽然可以连接外网，但并不能和宿主机进行通信，也就是说此时的宿主机并不能ping通虚拟机的ip。想要建立连接也很简单。只需要设置一下网络适配器中的VMware Network Adapter VMnet8 网卡的ip和子网掩码即可。 注：如果是学校的机房，或者用过脚本优化的电脑可能开机后不会启动VMware的一些必要的服务，可以手动开启。详见下图 //2019年03月20日19:25:10 更新 转载注明出处 谢谢</content></entry></search>