<?xml version="1.0" encoding="utf-8" standalone="yes"?><search><entry><title>若依ruoyi框架部门管理添加懒加载功能</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-09-20-%E8%8B%A5%E4%BE%9Druoyi%E6%A1%86%E6%9E%B6%E9%83%A8%E9%97%A8%E7%AE%A1%E7%90%86%E6%B7%BB%E5%8A%A0%E6%87%92%E5%8A%A0%E8%BD%BD%E5%8A%9F%E8%83%BD/</url><categories><category>懒加载</category><category>elementui</category></categories><tags><tag>ruoyi</tag><tag>若依</tag></tags><content type="html"><![CDATA[  最新在做一个系统,由于公司部门数量太多(1w+),ruoyi的部门管理默认加载全部数据,导致页面假死,故需要配置懒加载功能。
一、为el-table开启懒加载功能 默认配置(未开启)
&lt;el-table v-if=&#34;refreshTable&#34; v-loading=&#34;loading&#34; :data=&#34;deptList&#34; row-key=&#34;deptId&#34; :default-expand-all=&#34;isExpandAll&#34; :tree-props=&#34;{children: &#39;children&#39;, hasChildren: &#39;hasChildren&#39;}&#34; &gt; 开启后的配置
&lt;el-table v-if=&#34;refreshTable&#34; v-loading=&#34;loading&#34; :data=&#34;deptList&#34; row-key=&#34;deptId&#34; lazy :load=&#34;load&#34; :default-expand-all=&#34;isExpandAll&#34; :tree-props=&#34;{children: &#39;children&#39;, hasChildren: &#39;hasChildren&#39;}&#34; &gt; 显然，lazy是开启懒加载功能 ,load是加载数据的方法
二、添加load方法 async load(node, treeNode, resolve) { let params = {parentId: node.deptId,status:this.queryParams.status} await listDept(params).then(response =&gt; { let tData = this.handleTree(response.data, &#34;deptId&#34;); tData.forEach(t=&gt;{ t.hasChildren = true; }) node.children=tData resolve(tData) }); }, 三、添加initList方法来代替getList created() { this.initList(); }, methods: { ..... initList(){ this.loading = true; listDept(this.queryParams).then(response =&gt; { this.deptList = this.handleTree(response.data, &#34;deptId&#34;); this.deptList.forEach(d=&gt;{ d.children=null d.hasChildren = true; }) this.loading = false; }); }, ..... } 之所以会卡死就是因为初始化时渲染的节点太多，这里获取到节点并处理为树节点后将第一层的节点的children设置为null并设置配置每一个节点都有孩子节点
四、后续问题 这样处理后就会出现一些问题，但是不影响使用
1.展开/折叠 功能失效,需要删除相关功能
2.每一个节点都是默认有孩子节点,但实际有没有需要点开才知道
五、用户列表优化 在若依的用户管理页面左侧是有部门树的,部门数量多的时候,这里也会出现假死的情况,可以添加配置解决问题。这里不需要配置懒加载。 优化前：
&lt;el-tree :data=&#34;deptOptions&#34; :props=&#34;defaultProps&#34; :expand-on-click-node=&#34;false&#34; :filter-node-method=&#34;filterNode&#34; ref=&#34;tree&#34; node-key=&#34;id&#34; default-expand-all highlight-current @node-click=&#34;handleNodeClick&#34; /&gt; 优化后：
&lt;el-tree :data=&#34;deptOptions&#34; :props=&#34;defaultProps&#34; render-after-expand :expand-on-click-node=&#34;true&#34; :filter-node-method=&#34;filterNode&#34; ref=&#34;tree&#34; node-key=&#34;id&#34; :default-expand-all=&#34;false&#34; highlight-current @node-click=&#34;handleNodeClick&#34; /&gt; 1.开启点击节点展开列表 :expand-on-click-node=&quot;true&quot; 官网说明:是否在点击节点的时候展开或者收缩节点， 默认值为 true，如果为 false，则只有点箭头图标的时候才会展开或者收缩节点。
2.开启第一次展开某个树节点后才渲染其子节点 render-after-expand
3.关闭默认展开所有节点 :default-expand-all=&quot;false&quot;
  ]]></content></entry><entry><title>记录一次折腾了一下午的nginx配置文件问题</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-08-20-%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E6%8A%98%E8%85%BE%E4%BA%86%E4%B8%80%E4%B8%8B%E5%8D%88%E7%9A%84nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E9%97%AE%E9%A2%98/</url><categories><category>技巧</category></categories><tags><tag>nginx</tag><tag>docker</tag></tags><content type="html"><![CDATA[  想着写一个后端使用gin + gorm + mysql,前端使用vue3 vite + element plus 的项目模板，但是在写docker-compose调试的时候,总是报404错误，后来发现是nginx配置文件的问题。
问题描述 在调试开发的时候 vite.config.ts 文件配置如下
import { defineConfig, loadEnv } from &#39;vite&#39; import vue from &#39;@vitejs/plugin-vue&#39; export default (({ mode }) =&gt; { return defineConfig({ plugins: [vue()], server: { port: 6060, proxy: { &#39;/prod-api&#39;: { target: &#34;http://127.0.0.1:4000&#34;, changeOrigin: true, rewrite: (path) =&gt; path.replace(/^\/prod-api/, &#39;&#39;) }, } }, }) }) 请求都能正常转发到后端。但是使用docker-compose时,却总是报404错误。/ect/nginx/nginx.conf内容如下：
user nginx; worker_processes auto; error_log /var/log/nginx/error.log notice; pid /var/run/nginx.pid; events { worker_connections 1024; } http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main &#39;$remote_addr - $remote_user [$time_local] &#34;$request&#34; &#39; &#39;$status $body_bytes_sent &#34;$http_referer&#34; &#39; &#39;&#34;$http_user_agent&#34; &#34;$http_x_forwarded_for&#34;&#39;; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf; server{ listen 80; server_name location; location / { root /usr/share/nginx/html; try_files $uri $uri/ /index.html; index index.html index.htm; } location /prod-api/ { proxy_set_header Host $http_host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; rewrite ^/prod-api/(.*)$ /$1 break; proxy_pass http://177.7.0.12:4000/; } } } 发现问题 对比了ruoyi和gva的文档,都没什么问题，后来把80端口换成8080后就正常了，后来发现配置文件中有这么一行
include /etc/nginx/conf.d/*.conf; 然后看了下/etc/nginx/conf.d目录内有一个default.conf文件，内容如下：
server { listen 80; listen [::]:80; server_name localhost; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache&#39;s document root # concurs with nginx&#39;s one # #location ~ /\.ht { # deny all; #} } 这里把80端口给抢了，正好目录文件位置都在/usr/share/nginx/html,所以最开始没有考虑到nginx配置文件的问题，一直以为是前端写的有问题。
解决问题 解决方案就是把/ect/nginx/nginx.conf里代码给注释掉就行。
... #include /etc/nginx/conf.d/*.conf; ... 当然也可以不用80端口，或者删除`/etc/nginx/conf.d/default.conf`文件 或者在配置Docker镜像的时候把`default.conf`删除或者覆盖掉(推荐)   ]]></content></entry><entry><title>Golang实现Set集合</title><url>/posts/golang/2023-08-14-golang%E5%AE%9E%E7%8E%B0set%E9%9B%86%E5%90%88/</url><categories><category>goalng</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[  代码:
package main import ( &#34;fmt&#34; ) type Empty struct { } type Set struct { m map[any]Empty } func (s *Set) Add(items ...interface{}) { for _, item := range items { s.m[item] = Empty{} } } func (s *Set) Remove(item any) { delete(s.m, item) } func (s *Set) Contains(item any) bool { _, ok := s.m[item] return ok } func (s *Set) Clear() { s.m = make(map[any]Empty) } func (s *Set) Size() int { return len(s.m) } func NewSet(items ...any) *Set { s := &amp;Set{} s.m = make(map[any]Empty) s.Add(items...) return s } func main() { set := NewSet(&#34;AA&#34;, &#34;C&#34;, 546, false, false, true) for a := range set.m { fmt.Print(&#34; &#34;, a) } fmt.Println() set.Add(&#34;dd&#34;, &#34;ff&#34;, 23.2) set.Remove(&#34;C&#34;) for a := range set.m { fmt.Print(&#34; &#34;, a) } set.Clear() fmt.Println() fmt.Println(&#34;Size: &#34;, set.Size()) } //运行结果
AA C 546 false true
546 false true dd ff 23.2 AA
Size: 0
  ]]></content></entry><entry><title>Ruoyi框架部门多选配置</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-08-02-ruoyi%E6%A1%86%E6%9E%B6%E9%83%A8%E9%97%A8%E5%A4%9A%E9%80%89%E9%85%8D%E7%BD%AE/</url><categories><category>技巧</category></categories><tags><tag>前端</tag><tag>ruoyi</tag><tag>若依</tag></tags><content type="html"><![CDATA[  开发中遇到一个需求,简化一下可以理解为为一个用户配置多个部门。通常情况下要用主子表实现,但这里仅需要记录一个编码，故放在主表一个字段里即可(用逗号分隔)。如果想方便的禁用或启用某个部门,还是用主子表实现比较好。
演示图 列表 新增 修改 直接放代码吧,实现细节在代码注释中查看
后端(不重要) package com.ruoyi.person.domain; import com.ruoyi.common.annotation.Excel; import com.ruoyi.common.core.domain.BaseEntity; import java.util.List; /** * 测试用户对象 person * * @author ruoyi * @date 2023-08-02 */ public class Person extends BaseEntity { private static final long serialVersionUID = 1L; /** 主键 */ private Long id; /** 姓名 */ @Excel(name = &amp;#34;姓名&amp;#34;) private String name; /** 年龄 */ @Excel(name = &amp;#34;年龄&amp;#34;) private Long age; /** 部门 */ @Excel(name = &amp;#34;部门&amp;#34;) private String dept; //这里用String类型来记录部门信息,在数据库中存储值为 101,102,103 //... 省略了get和set方法 } 前端(主要) js 主要变动的地方在新增和修改
import request from &amp;#39;@/utils/request&amp;#39; // 查询测试用户列表 export function listPerson(query) { return request({ url: &amp;#39;/person/person/list&amp;#39;, method: &amp;#39;get&amp;#39;, params: query }) } // 查询测试用户详细 export function getPerson(id) { return request({ url: …  ]]></content></entry><entry><title>Linux登录后出现bash4.2解决办法及原因</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-05-30-linux%E7%99%BB%E5%BD%95%E5%90%8E%E5%87%BA%E7%8E%B0bash4.2%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%E5%8F%8A%E5%8E%9F%E5%9B%A0/</url><categories><category>技巧</category></categories><tags><tag>技巧</tag><tag>linux</tag></tags><content type="html"> 前言 有一天链接服务器发现变成了变成了这个样子
前段时间更新测试时,由于添加了log组件导致将/root目录软链接到了更新目录,在删除目录时将root目录内的东西都删了。再次链接服务器就出现了bash-4.2#而不是用户名,搜了一下，发现是缺失root目录下的 .bash_profile和.bashrc 。
解决方案 将默认文件复制到root目录下即可。
cp /etc/skel/.bashrc /root/ cp /etc/skel/.bash_profile /root/ 修复后的样子</content></entry><entry><title>使用Cloudflare加速github下载及图床加速</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-05-25-%E4%BD%BF%E7%94%A8cloudflare%E5%8A%A0%E9%80%9Fgithub%E4%B8%8B%E8%BD%BD%E5%8F%8A%E5%9B%BE%E5%BA%8A%E5%8A%A0%E9%80%9F/</url><categories><category>技巧</category></categories><tags><tag>github</tag><tag>技巧</tag><tag>图床</tag><tag>Cloudflare</tag></tags><content type="html"><![CDATA[  网上很多加速github的工具，但是由于使用人数多，效果时好时坏，后来发现可以使用cloudflare搭建自己专属的加速工具，故记录一下搭建流程及使用方式
前提条件 需要有cloudflare账号 需要有一个域名(国内外都行,需要用cloudflare接管。免费的不清楚) 免费版每天10w次，个人使用完全足够。 部署加速服务 一、使用cloudflare接管域名解析服务。 由于域名服务商的设置方式不同，这里就不详细介绍了，百度搜一下，教程很多的。
二、添加Cloudflare Worker服务 进到作者github项目内 https://github.com/hunshcn/gh-proxy 找到index.js文件
或者直接点击 https://github.com/hunshcn/gh-proxy/blob/master/index.js 三、配置自定义域名 由于workers.dev国内环境无法访问，需要配置自定义域名
此时打开https://gh.xxxyyy.com应该就是能看如下画面了
使用加速服务提高github下载速度 一、使用油猴脚本 油猴插件这里不再介绍了，自己创建一个脚本 内容如下
// ==UserScript== // @name github-加速下载 // @namespace https://blog.sxz799.xyz/ // @version 1.0 // @description github-加速下载 // @author sxz799 // @match https://github.com/* // @grant none // ==/UserScript== (function() { &amp;#39;use strict&amp;#39;; var proxy_url = &amp;#39;https://gh.xxxyyy.com/&amp;#39;; const download_url_fast = [proxy_url+&amp;#39;https://github.com&amp;#39;, &amp;#39;加速下载&amp;#39;, &amp;#39;Cloudflare CDN加速&amp;#39;] const svg = [ &amp;#39;&amp;lt;svg class=&amp;#34;octicon octicon-file-zip mr-2&amp;#34; …  ]]></content></entry><entry><title>Github拉取代码时提示kex_exchange_identification解决方案</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-05-12-github%E6%8B%89%E5%8F%96%E4%BB%A3%E7%A0%81%E6%97%B6%E6%8F%90%E7%A4%BAkex_exchange_identification%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/</url><categories><category>技巧</category></categories><tags><tag>github</tag></tags><content type="html"> 最近在github上拉取和推送代码时经常报kex_exchange_identification的错误,但是更换手机热点后就可以正常推代码,查了一下发现可能是梯子的问题，这里记录一下搜到的解决方案。
解决方案 在.ssh目录下创建一个config文件,内容如下
Host github.com HostName ssh.github.com User git Port 443 如果这个文件已经存在,添加或修改对应内容即可。主要目的是使用443端口。</content></entry><entry><title>GithubAction自动编译项目学习笔记</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-05-09-githubaction%E8%87%AA%E5%8A%A8%E7%BC%96%E8%AF%91%E9%A1%B9%E7%9B%AE%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>技巧</category></categories><tags><tag>github</tag><tag>自动化</tag></tags><content type="html"><![CDATA[  最近项目上线要将旧系统的数据导入新系统，旧系统的数据导出到excel文件，然后将文件整理后导入新系统。但是整理文件的时候总是会出现一些简单的错误，每次都有人工校对或者导入时提示太麻烦，于是写了一个小工具让整理数据的门店人员整理数据后自行检测一次。由于数据库使用的是sqlite，我本地的开发环境又是mac，这就导致golang交叉编译时要配置gcc,试了一下，感觉太麻烦了。也尝试过开个虚拟机进行编译，发现效果也不满意。后来发现github action可以在推送项目后自动构建项目，于是实现了项目推到github后,由Github自动编译并打包项目。
在github仓库的Action页面创建workflow 可以在这里根据你项目类型选择一个现有的模板进行创建(这里创建后会在项目根目录创建一个.github隐藏目录，目录内有一个workflows文件夹,文件夹里面就是一个yml格式的CI配置文件，所以记得在本地 git pull一下把这个目录拉到本地)
一个脚本的注释说明 name: CI # 标识在推送 main 分支时执行 on: push: branches: [main] # 任务列表 jobs: # 任务名称 build: # 策略 和后面用到的编译环境相关 strategy: matrix: node-version: [16.x] # See supported Node.js release schedule at https://nodejs.org/en/about/releases/ # 运行环境 支持 ubunutu Windows macos runs-on: ubuntu-latest # 容器 我这里使用容器是因为项目要部署到centos系统 而且用到了sqlite 编译是需要gcc环境 container: docker.io/centos:7 # 步骤 steps: # 使用checkout切换到指定分支 - uses: actions/checkout@v3 # 安装依赖 针对上面提到的gcc 非必要 - name: intall deps run: | yum install -y wget tar gcc automake autoconf libtool make # 配置go 编译环境 - name: Set up Go uses: actions/setup-go@v3 with: go-version: 1.19 # 执行编译任务 工作目录在当前目录的server目录内 编译后的app文件在 server/bin 内 后面任务会用到这个文件 - name: Build Server run: go build -ldflags=&#34;-s -w&#34; -o bin/app . working-directory: ./server # 配置前端node 编译环境 - name: Use Node.js ${{ matrix.node-version }} uses: actions/setup-node@v3 with: node-version: ${{ matrix.node-version }} # 执行编译任务 工作目录在当前目录的web目录内 编译后的app文件在 web/dist 内 后面任务会用到这个文件 - name: Build Web run: npm install &amp;&amp; npm run build working-directory: ./web # 移动编译好的文到 gsCheck 目录内 - name: Move Files run: | mkdir gsCheck mv server/bin/app gsCheck/ mv web/dist gsCheck/dist/ # 指定上传任务 将编译环境内的gsCheck目录内的文件打包为 gscheck-artifact.zip 进行上传 - name: Upload artifact uses: actions/upload-artifact@v2 with: name: gscheck-artifact path: ${{ github.workspace }}/gsCheck # 指定下载任务 将gscheck-artifact.zip下载 方便你下载编译后的文件 - name: Download a Build Artifact uses: actions/download-artifact@v2.1.1 with: name: gscheck-artifact 下载自动编译后打包的文件   ]]></content></entry><entry><title>使用Vercel部署托管在github上的前端项目</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-04-06-%E4%BD%BF%E7%94%A8vercel%E9%83%A8%E7%BD%B2%E6%89%98%E7%AE%A1%E5%9C%A8github%E4%B8%8A%E7%9A%84%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE/</url><categories><category>技巧</category></categories><tags><tag>技巧</tag><tag>Vercel</tag><tag>Vue</tag><tag>前端</tag></tags><content type="html"> 之前写了一个便携剪切板小工具，部署在家里的群晖上面，方便工作时随时写日报。前段时间发现可以用Vercel部署前端项目，还可以自定义域名，这样就不用每次都输入端口信息了。
申请Vercel账号 官网链接 建议直接使用github登录。
导入github上的前端项目 导入很简单，点几下鼠标就可以。
导入完成后页面大概这个样子，可以直接点击预览图进入
配置域名 根据提示操作即可，刚导入的项目，绿框那里应该是有一个默认的域名的。
添加域名后，会提示让你在你的域名控制台添加一条CNAME的解析记录，按照提示添加即可。
解析记录添加完成后,vercel会自动帮你申请并配置SSL证书。</content></entry><entry><title>Openwrt去除小米电视广告</title><url>/posts/%E6%8A%80%E5%B7%A7/2023-03-24-openwrt%E5%8E%BB%E9%99%A4%E5%B0%8F%E7%B1%B3%E7%94%B5%E8%A7%86%E5%B9%BF%E5%91%8A/</url><categories><category>技巧</category></categories><tags><tag>技巧</tag></tags><content type="html"><![CDATA[  小米电视去除开机广告及视频开头广告
创建mihosts文件 echo -e &#39;127.0.0.1 ad.mi.com 127.0.0.1 api.ad.xiaomi.com 127.0.0.1 t7z.cupid.ptqy.gitv.tv 127.0.0.1 sdkconfig.ad.xiaomi.com 127.0.0.1 stat.pandora.xiaomi.com 127.0.0.1 upgrade.mishop.pandora.xiaomi.com 127.0.0.1 logonext.tv.kuyun.com 127.0.0.1 config.kuyun.com 127.0.0.1 mishop.pandora.xiaomi.com 127.0.0.1 dvb.pandora.xiaomi.com 127.0.0.1 de.pandora.xiaomi.com 127.0.0.1 data.mistat.xiaomi.com 127.0.0.1 jellyfish.pandora.xiaomi.com 127.0.0.1 gallery.pandora.xiaomi.com 127.0.0.1 bss.pandora.xiaomi.com 127.0.0.1 gvod.aiseejapp.atianqi.com 127.0.0.1 sdkauth.hpplay.cn 127.0.0.1 adeng.hpplay.cn 127.0.0.1 ad.hpplay.cn 127.0.0.1 conf.hpplay.cn 127.0.0.1 fix.hpplay.cn&#39; &gt; /etc/mihosts 应用自定义的hosts文件 后台页面-&gt;网络-&gt;DHCP/DNS-&gt;HOSTS和解析文件-&gt;额外的 HOSTS 文件 内容填写/etc/mihosts
保存并应用
电视系统设置进行深度清理 重启电视查看效果   ]]></content></entry><entry><title>Map底层原理学习笔记</title><url>/posts/golang/2023-03-01-goang-map%E5%BA%95%E5%B1%82%E5%8E%9F%E7%90%86%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[  golang Map底层原理学习笔记
课程来源 map的简单使用 package main import &amp;#34;fmt&amp;#34; func f1(key string, mp map[string]int) { value, ok := mp[key] if ok { fmt.Println(value) } else { fmt.Println(key, &amp;#34;不存在&amp;#34;) } } func main() { //创建一个map用来存储姓名和年龄 当然 姓名不可重复 mp := make(map[string]int) mp[&amp;#34;xiaoming&amp;#34;] = 12 mp[&amp;#34;xiaohong&amp;#34;] = 13 f1(&amp;#34;xiaoming&amp;#34;, mp) f1(&amp;#34;xiaoming1&amp;#34;, mp) delete(mp, &amp;#34;xiaohong&amp;#34;) fmt.Println(mp[&amp;#34;xiaohong3&amp;#34;]) //0 } func delete(m map[Type]Type1, key Type)
The delete built-in function deletes the element with the specified key (m[key]) from the map. If m is nil or there is no such element, delete is a no-op.
delete是针对map的内建函数，如果map为空或者没有对应的元素，则是一个空操作
delete无返回值
map的底层原理 map最大的特点就是查找速度非常快，因为他的底层存储是基于哈希表的
Map的特点：
键不能重复 键必须可哈希（目前我们已学的数据类型中，可哈希的有：int/bool/float/string/array） 无序 map初始化 // 初始化一个可容纳10个元素的map info = make(map[string]string,10) 第一步：创建一个hmap结构体对象。
第二步：生成一个哈希因子hash0 并赋值到hmap对象中（用于后续为key创建哈希值）。
第三步：根据hint=10，并根据算法规则来创建 B，当前B应该为1。
hint B 0~8 0 9~13 …  ]]></content></entry><entry><title>Golang切片扩容学习笔记</title><url>/posts/golang/2023-02-28-golang%E5%88%87%E7%89%87%E6%89%A9%E5%AE%B9%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[  在学习golang切片时看到说golang的扩容机制是小于1024时进行double,超过1024后每次增加1/4，但是自己尝试后并非如此，于是扒了下golang的源码研究一番。
代码演示 package main import &amp;#34;fmt&amp;#34; func main() { arr := []int{0} lastCap := cap(arr) fmt.Println(&amp;#34;cap：&amp;#34;, lastCap) for i := 0; i &amp;lt; 10000; i++ { arr = append(arr, i) if lastCap != cap(arr) { fmt.Println(&amp;#34;cap：&amp;#34;, cap(arr)) lastCap = cap(arr) } } } cap： 1 cap： 2 cap： 4 cap： 8 cap： 16 cap： 32 cap： 64 cap： 128 cap： 256 cap： 512 cap： 848 cap： 1280 cap： 1792 cap： 2560 cap： 3408 cap： 5120 cap： 7168 cap： 9216 cap： 12288 一开始确实成指数上涨，每次double，但是512以后变不是1024，而变成了848。
看一下slice.go的更新日志 发现在2021年9月8日有一个更新记录
此处可以发现扩容机制发生了变化
源码 // growslice allocates new backing store for a slice. // // arguments: // //	oldPtr = pointer to the slice&amp;#39;s backing array //	newLen = new length (= oldLen + num) //	oldCap = original slice&amp;#39;s capacity. //	num = number of elements being added //	et = element type // // return values: // //	newPtr = pointer to the new backing store //	newLen = same value as the …  ]]></content></entry><entry><title>Mysql索引</title><url>/posts/mysql/2023-02-20-mysql%E7%B4%A2%E5%BC%95/</url><categories><category>mysql</category></categories><tags><tag>mysql</tag></tags><content type="html"><![CDATA[  在关系数据库中，索引是一种单独的、物理的对数据库表中一列或多列的值进行排序的一种存储结构，它是某个表中一列或若干列值的集合和相应的指向表中物理标识这些值的数据页的逻辑指针清单。索引的作用相当于图书的目录，可以根据目录中的页码快速找到所需的内容。
myslq索引 普通索引 -- 创建索引的基本语法 CREATE INDEX indexName ON table(column(length)); -- 例子 length默认我们可以忽略 CREATE INDEX idx_name ON user(name); 主键索引 我们知道每张表一般都会有自己的主键，mysql会在主键上建立一个索引，这就是主键索引。主键是具有唯一性并且不允许为NULL，所以他是一种特殊的唯一索引。一般在建立表的时候选定。
复合索引 复合索引也叫组合索引，指的是我们在建立索引的时候使用多个字段，例如同时使用身份证和手机号建立索引，同样的可以建立为普通索引或者是唯一索引。
-- 创建索引的基本语法 CREATE INDEX indexName ON table(column1(length),column2(length)); -- 例子 CREATE INDEX idx_phone_name ON user(phone,name); SELECT * FROM user_innodb where name = &amp;#39;程冯冯&amp;#39;; SELECT * FROM user_innodb where phone = &amp;#39;15100046637&amp;#39;; SELECT * FROM user_innodb where phone = &amp;#39;15100046637&amp;#39; and name = &amp;#39;程冯冯&amp;#39;; SELECT * FROM user_innodb where name = &amp;#39;程冯冯&amp;#39; and phone = &amp;#39;15100046637&amp;#39;; 只有 2 、 3、4能使用的到索引idx_phone_name,因为条件里面必须包含索引前面的字段才能够进行匹配。而3和4相比where条件的顺序不一样，为什么4可以用到索引呢？是因为mysql本身就有一层sql优化，他会根据sql来识别出来该用哪个索引，我们可以理解为3和4在mysql眼中是等 …  ]]></content></entry><entry><title>使用hugo和next主题搭建静态博客</title><url>/posts/blog/2023-02-20-%E4%BD%BF%E7%94%A8hugo%E5%92%8Cnext%E4%B8%BB%E9%A2%98%E6%90%AD%E5%BB%BA%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2/</url><categories><category>blog</category></categories><tags><tag>blog</tag><tag>hugo</tag></tags><content type="html"><![CDATA[  前两年一直在用hexo写博客，hexo构建需要node环境，且文章数量多了以后构建速度慢了许多，且部署起来比较复杂，所以改用hugo。
在Mac系统使用hugo推荐使用homebrew安装hugo。homebrew的安装不再介绍，可参考 知乎文章 安装hugo brew install hugo 生成站点 hugo new site /path/to/site 创建文章 hugo new about.md
使用next主题 链接 部署到github page 修改hugo配置文件，使生成的前端文件放到docs目录
# =============================================================== # 根据如下的配置说明完善自己的站点配置，建议另外拷贝进行调整避免冲突 # Improve your site configuration according to the following # configuration instructions. It is recommended to make # additional copies for adjustment to avoid conflicts # =============================================================== # --------------------------------------------------------------- # Hugo 引擎的基础配置 # Basic configure for Hugo engine # --------------------------------------------------------------- # 使生成的前端文件放到doc目录 publishDir : docs # 站点域名，比如： https://hugo-next.eu.org # Website domain, eg: https://hugo-next.eu.org baseURL: / # 站点标题 # Website title github创建一个仓库 username.github.io username为你的用户名
将hugo生成的站点推送到新建的仓库
配置域名解析 在docs目录中创建一个CNAME文件内容为你的域名
rm -rf docs/ # 删除旧的文件 hugo #编译出新文件 echo &#39;blog.sxz799.xyz&#39; &gt; docs/CNAME ## 如果配置的域名就加上这个 git add . git commit -m &#34;update blog&#34; git push   ]]></content></entry><entry><title>Redis基础</title><url>/posts/redis/redis%E5%9F%BA%E7%A1%80/</url><categories><category>redis</category></categories><tags><tag>redis</tag></tags><content type="html"> Redis常用数据结构 字符串（String）、哈希(Hash)、列表（list）、集合（set）、有序集合（ZSET）。
字符串（String） 字符串类型是Redis最基础的数据结构。键都是字符串类型。值最大不能超过512MB。
命令 SET set key value set abc 123
常用参数 set key value [NX|XX] [GET] [EX seconds|PX milliseconds|EXAT unix-time-seconds|PXAT unix-time-milliseconds|KEEPTTL]
NX : 键不存在才可以设置成功
XX : 键存在才可以设置成功
EX|PX|EXAT|PXAT : 设置过期时间 秒 毫秒 秒时间戳 毫秒时间戳
KEEPTTL：保留设置前指定键的生存时间 (6.0版本添加的可选参数) GET：返回指定键原本的值，若键不存在时返回nil
GET get key get abc
GETSET GETSET命令用于设置键值对的值并返回旧值，若键值对不存在则返回nil。若键存在但不为字符串类型，则返回错误。
getset key value getset abc 123
DEL命令被用于删除指定的一个或多个键值对，当其中某个键值对不存在时将被忽略。DEL命令可被用于所有数据类型，不仅限于字符串。
EXPIRE / PEXPIRE EXPIRE key seconds [NX|XX|GT|LT]
NX：只有当key没有设置过期时间，才会执行命令（已经设置过的，不能再设置） XX ：只有当key有过期时间，才会执行命令设置（没有设置过的，不能设置） GT ：只有当新的过期时间大于当前过期时间时，才会设置（只会增加过期时间） LT ：只有当新的过期时间小于当前过期时间时，才会设置（只会减少过期时间） EXPIRE/PEXPIRE命令被用于设置某个键的过期时间，其值以秒作为单位。当设置过期时间后使用SET（不使用KEEPTTL参数）、GETSET等命令，所设置的过期时间将被覆盖。EXPIRE可被用于所有数据类型，不仅限于字符串。
TTL / PTTL TTL命令用于获取指定键的剩余生存时间（time to live, TTL），其值以秒作为生存时间的单位。TTL命令可被用于所有数据类型，不仅限于字符串。
TTL …</content></entry><entry><title>Golang逃逸分析</title><url>/posts/golang/2023-02-09-golang%E9%80%83%E9%80%B8%E5%88%86%E6%9E%90/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[  案例 先看一段C语言代码
#include &lt;stdio.h&gt; int *foo(int arg_val) { int foo_val = 11; return &amp;foo_val; } int main() { int *main_val = foo(666); printf(&#34;%d\n&#34;, *main_val); } ➜ Desktop gcc cDemo.c cDemo.c:7:13: warning: address of stack memory associated with local variable &#39;foo_val&#39; returned [-Wreturn-stack-address] return &amp;foo_val; ^~~~~~~ 1 warning generated. 如上C/C++编译器明确给出了警告，foo把一个局部变量的地址返回了
在Go语言下代码如下
package main func foo(arg_val int)(*int) { var foo_val int = 11; return &amp;foo_val; } func main() { main_val := foo(666) println(*main_val) } ➜ goDemo go run main.go 11 在Go语言下却正常运行
分析 go语言编译器会自动决定把一个变量放在栈还是放在堆，编译器会做逃逸分析(escape analysis)，当发现变量的作用域没有跑出函数范围，就可以在栈上，反之则必须分配在堆。
逃逸规则 如果变量需要使用堆空间，那么他就应该进行逃逸。但是实际上Golang并不仅仅把逃逸的规则如此泛泛。Golang会有很多场景具备出现逃逸的现象。 一般我们给一个引用类对象中的引用类成员进行赋值，可能出现逃逸现象。可以理解为访问一个引用对象实际上底层就是通过一个指针来间接的访问了，但如果再访问里面的引用成员就会有第二次间接访问，这样操作这部分对象的话，极大可能会出现逃逸的现象。
Go语言中的引用类型有func（函数类型），interface（接口类型），slice（切片类型），map（字典类型），channel（管道类型），*（指针类型）等。
Golang中一个函数内局部变量，不管是不是动态new出来的，它会被分配在堆还是栈，是由编译器做逃逸分析之后做出的决定。
  ]]></content></entry><entry><title>Golang Select</title><url>/posts/golang/2023-02-09-golang-select/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"> go select用处 select是一种go可以处理多个通道之间的机制，看起来和switch语句很相似，但是select其实和IO机制中的select一样，多路复用通道，随机选取一个进行执行，如果说通道(channel)实现了多个goroutine之前的同步或者通信，那么select则实现了多个通道(channel)的同步或者通信，并且select具有阻塞的特性。
select 是 Go 中的一个控制结构，类似于用于通信的 switch 语句。每个 case 必须是一个通信操作，要么是发送要么是接收。
select 随机执行一个可运行的 case。如果没有 case 可运行，它将阻塞，直到有 case 可运行。一个默认的子句应该总是可运行的。
select { case &amp;amp;lt;-ch1: // 如果从 ch1 信道成功接收数据，则执行该分支代码 case ch2 &amp;amp;lt;- 1: // 如果成功向 ch2 信道成功发送数据，则执行该分支代码 default: // 如果上面都没有成功，则进入 default 分支处理流程 } select里的case后面并不带判断条件，而是一个信道的操作，不同于switch里的case
golang 的 select 就是监听 IO 操作，当 IO 操作发生时，触发相应的动作每个case语句里必须是一个IO操作，确切的说，应该是一个面向channel的IO操作。
注：Go 语言的 select 语句借鉴自 Unix 的 select() 函数，在 Unix 中，可以通过调用 select() 函数来监控一系列的文件句柄，一旦其中一个文件句柄发生了 IO 动作，该 select() 调用就会被返回（C 语言中就是这么做的），后来该机制也被用于实现高并发的 Socket 服务器程序。Go 语言直接在语言级别支持 select关键字，用于处理并发编程中通道之间异步 IO 通信问题。
注意：如果 ch1 或者 ch2 信道都阻塞的话，就会立即进入 default 分支，并不会阻塞。但是如果没有 default 语句，则会阻塞直到某个信道操作成功为止。
select语句只能用于信道的读写操作
select中的case条件(非阻塞)是并发执行的，select会选择先操作成功的那个case条件去执行，如果多个同时返回，则随机选择一个执行，此时 …</content></entry><entry><title>GMP模型</title><url>/posts/golang/2023-02-08-gmp%E6%A8%A1%E5%9E%8B/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"> 什么是GMP模型？ G：gorotine（协程） M：machine（内核线程） P：processor(调度器) Go语言运行时，通过核心元素G，M，P 和 自己的调度器，实现了自己的并发线程模型。调度器通过对G，M，P的调度实现了两级线程模型中操作系统内核之外的调度任务。
Golang调度器由来 Goroutine调度器器的GMP模型的设计思想 GMP模型简介 G：goroutine（协程） M：machine（内核线程） P：processor(调度器，负责G和M之间的调度，不是GMP模型的调度) 全局队列:存放等待运行的G
P的本地队列:
存放等待运行的G, 有数量限制(不超过256个), 新创建的G优先放置在本地队列，存满了会放在全局队列 P列表:程序启动时创建,默认数量为cpu线程数
M列表:当前操作系统分配到当前Go程序的内核线程数
P和M的数量:
P的数量可通过环境变量($GOMAXPROCS)或程序中代码设置runtime.GOMAXPROCS() . M的数量Go语言本身限制为10000,可通过runtime/debug包中的SetMaxThreads函数来设置, 有一个M阻塞,就会创建一个新的M,有M空闲就会回收或者睡眠。 调度器的设计策略 复用线程 避免频繁的创建销毁线程，有两种机制 work stealing机制和hand off机制
work stealing机制 : 当前P的本地队列和全局队列均无可运行的G时会尝试从其他P的队列中偷取G
hand off机制 : 当本线程正在运行的G发生阻塞时，会将G和M进行绑定，并把P转移给其他的空闲M
利用并行 GOMAXPROCS设置P的数量，最多有GOMAXPROCS个线程分布在多个cpu上同时运行
抢占 在coroutine中要等待一个协程主动让出CPU才执行下一个协程.
在Go中，一个goroutine最多占⽤用CPU 10ms，防⽌止其他goroutine被饿死.
全局G队列列 用于存放G
调度规则 如果处理器没有任务可处理，它会按以下规则来执行，直到满足某一条规则：
从本地队列获取任务 从全局队列获取任务 从网络轮询器获取任务 从其它的处理器的本地队列窃取任务 go func() 经历了什么 先创建一个goroutine 也就是G G会有限存储在创建G的P的本地本地队列,若队列已满就会存 …</content></entry><entry><title>面试题整理(Golang方向)</title><url>/posts/golang/2023-02-06-golang%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/</url><categories><category>golang</category></categories><tags><tag>golang</tag></tags><content type="html"><![CDATA[  面试题整理(Golang方向)
golang相关 list 结构 及底层实现？ // Element is an element of a linked list. type Element struct { // Next and previous pointers in the doubly-linked list of elements. // To simplify the implementation, internally a list l is implemented // as a ring, such that &amp;amp;l.root is both the next element of the last // list element (l.Back()) and the previous element of the first list // element (l.Front()). next, prev *Element // The list to which this element belongs. list *List // The value stored with this element. Value any } // List represents a doubly linked list. // The zero value for List is an empty list ready to use. type List struct { root Element // sentinel list element, only &amp;amp;root, root.prev, and root.next are used len int // current list length excluding (this) sentinel element } // Init initializes or clears list l. func (l *List) Init() *List { l.root.next = &amp;amp;l.root l.root.prev = &amp;amp;l.root l.len = 0 return l } 通过代码可以发现在go中list的底层结构是一个带有头结点的双链表，有一个前驱节点和一个后继节点。 …  ]]></content></entry><entry><title>BCM943602CS蓝牙修复记录</title><url>/posts/hackintosh/2023-02-02-bcm943602cs%E8%93%9D%E7%89%99%E4%BF%AE%E5%A4%8D%E8%AE%B0%E5%BD%95/</url><categories><category>hackintosh</category></categories><tags><tag>hackintosh</tag></tags><content type="html"> 前言 记得在两年前做过一个b85+i5-4950的黑苹果配置，当时是在闲鱼购买的bcm943602cs三天线的无线网卡，安装系统的时候就可以直接免驱，进系统后蓝牙和wifi都是直接免驱，感觉这个卡还挺好的
，正好前段时间为了玩吃鸡买了b365m+9400f的台式，现在游戏也玩的少了，就准备装个黑苹果刷刷，于是在春节后就在闲鱼下单了一个943602cs网卡，年后有点忙没时间装系统，就只在windows上测试了一下蓝牙和wifi，能驱动就确认收货了，但是在装黑苹果的时候发现，蓝牙打不开，想退货也不可能，卖的话再买一个也不合适，就自己研究了一下，在这里记录一下驱动蓝牙的过程。
bug初现 初现的症状是蓝牙无法打开，蓝牙芯片组识别为BCM_2045A0
尝试修复 最开始以为是usb定制的原因，重新定制了一下usb，发现问题依旧。 又尝试加入了 BlueToolFixup.kext 开机后可以打开蓝牙也能搜索了，但是无法连接设备，此时感觉有戏。
继续尝试 之后又在论坛搜了一个这个卡的ProductId-&amp;amp;gt;0x21ff,发现这个情况并不少见，而且论坛也给出了解决方案，但是有人反馈成功驱动，也有人反馈无效，而且帖子标题是10.12和10.13的老系统,现在都到13.1了，不知道有没有效就死马当成活马医，试一试吧。根据https://github.com/acidanthera/BrcmPatchRAM说明配置了一下蓝牙驱动。
12、13系统要用到的kext有三个 BrcmPatchRAM3.kext BrcmFirmwareData.kext BlueToolFixup.kext
10.15.X - 11 系统用这三个 BrcmPatchRAM3.kext BrcmFirmwareData.kext BrcmBluetoothInjector.kext
但是我这张bcm943602cs的ProductId并不在下载的支持列表中
[0489:e032] 20702 Combo USB [0489:e042] 20702A1 Lenovo China * [0489:e079] Lenovo China 43162 NGFF [0489:e07a] Lenovo NGFF (4352 / 20702) [04ca:2003] 20702A1 Lenovo China …</content></entry><entry><title>让Gin-Vue-Admin的表单支持图片</title><url>/posts/golang/2023-01-10-%E8%AE%A9gin-vue-admin%E7%9A%84%E8%A1%A8%E5%8D%95%E6%94%AF%E6%8C%81%E5%9B%BE%E7%89%87/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  在学习 gin-vue-admin 时发现生成代码时并不支持选择表单输入类型，都是默认的输入框或者下拉框，这样在传图片或附件是就需要手动修改前端来实现此功能。
数据结构 如下图所示
数据列表部分 代码前后对比
需要导入CustonPic模块
import CustomPic from &#39;@/components/customPic/index.vue&#39; 效果图
表单部分 数据列表还是挺简单的，麻烦的是表单部分
页面效果
代码前后对比
需要定义和导入和修改的东西比较多
// 要添加的地方： import {useUserStore} from &#34;@/pinia/modules/user&#34;; const userStore = useUserStore() const emit = defineEmits([&#39;on-success&#39;]) const path = ref(import.meta.env.VITE_BASE_API) let fileList = [] const uploadSuccess = (res) =&gt; { const { data } = res if (data.file) { emit(&#39;on-success&#39;, data.file.url) formData.value.pic=data.file.url } } const uploadError = () =&gt; { ElMessage({ type: &#39;error&#39;, message: &#39;上传失败&#39; }) } const removeFile = () =&gt; { formData.value.pic=&#39;&#39; } // 要修改的地方： const updateStudentFunc = async(row) =&gt; { const res = await findStudent({ ID: row.ID }) type.value = &#39;update&#39; if (res.code === 0) { formData.value = res.data.restudent if(formData.value.pic!=&#39;&#39;){ fileList=[{&#34;name&#34;:&#34;pic.jpg&#34;,&#34;url&#34;:&#34;/api/&#34;+formData.value.pic}] }else { fileList=[] } dialogFormVisible.value = true } } const closeDialog = () =&gt; { dialogFormVisible.value = false fileList=[] formData.value = { name: &#39;&#39;, gender: &#39;&#39;, pic: &#39;&#39;, } }   ]]></content></entry><entry><title>让Gin-Vue-Admin的字典值支持字符串</title><url>/posts/golang/2023-01-09-%E8%AE%A9gin-vue-admin%E7%9A%84%E5%AD%97%E5%85%B8%E5%80%BC%E6%94%AF%E6%8C%81%E5%AD%97%E7%AC%A6%E4%B8%B2/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  最近在学习 gin-vue-admin 开发平台，发现在配置字典时，字典值只能使用int，不能使用string，这样就会导致后期做报表开发时，查看数据库内容时容易摸不到头脑，所以准备改一下源码，使其字典值支持string！
gva版本: 2.5.5 (2022/12/14)
后端部分 修改 sys_dictionary_detail.go 中结构体的定义 // model/system/sys_dictionary_detail.go line:12 // 修改Value的数据类型为string type SysDictionaryDetail struct { global.GVA_MODEL Label string `json:&#34;label&#34; form:&#34;label&#34; gorm:&#34;column:label;comment:展示值&#34;` // 展示值 Value string `json:&#34;value&#34; form:&#34;value&#34; gorm:&#34;column:value;comment:字典值&#34;` // 字典值 Status *bool `json:&#34;status&#34; form:&#34;status&#34; gorm:&#34;column:status;comment:启用状态&#34;` // 启用状态 Sort int `json:&#34;sort&#34; form:&#34;sort&#34; gorm:&#34;column:sort;comment:排序标记&#34;` // 排序标记 SysDictionaryID int `json:&#34;sysDictionaryID&#34; form:&#34;sysDictionaryID&#34; gorm:&#34;column:sys_dictionary_id;comment:关联标记&#34;` // 关联标记 } 修改dictionary_detail.go中默认字典的配置 文件位置: source/system/dictionary_detail.go
这里就不贴代码了，根据IDE的错误提示把原来的int类型的Value数据改为string即可
修改字典server中Value的类型
//service/system/sys_dictionary_detail.go line:71 //修改前：	if info.Value != 0 { db = db.Where(&#34;value = ?&#34;, info.Value) } //修改后：	if info.Value != &#34;&#34; { db = db.Where(&#34;value = ?&#34;, info.Value) } 修改前端文件模板 这里不贴代码了，看上去很乱，贴两张图，比较清晰明了
文件位置: resource/autocode_template/web/form.vue.tpl
文件位置: resource/autocode_template/web/table.vue.tpl
前端部分 修改字典配置页，字典值改为string // src/view/superAdmin/dictionary/sysDictionaryDetail.vue line:89 //修改前： &lt;el-form-item label=&#34;字典值&#34; prop=&#34;value&#34;&gt; &lt;el-input-number v-model.number=&#34;formData.value&#34; step-strictly :step=&#34;1&#34; placeholder=&#34;请输入字典值&#34; clearable :style=&#34;{width: &#39;100%&#39;}&#34; /&gt; &lt;/el-form-item&gt; //修改后： &lt;el-form-item label=&#34;字典值&#34; prop=&#34;value&#34;&gt; &lt;el-input v-model=&#34;formData.value&#34; placeholder=&#34;请输入字典值&#34; clearable :style=&#34;{width: &#39;100%&#39;}&#34; /&gt; &lt;/el-form-item&gt; 修改代码生成器页面代码实现string类型可配置字典 // src/view/systemTools/autoCode/component/fieldDialog.vue line:68 //修改前： &lt;el-form-item label=&#34;关联字典&#34; prop=&#34;dictType&#34;&gt; &lt;el-select v-model=&#34;middleDate.dictType&#34; style=&#34;width:100%&#34; :disabled=&#34;middleDate.fieldType!==&#39;int&#39;&#34; placeholder=&#34;请选择字典&#34; clearable &gt; &lt;el-option v-for=&#34;item in dictOptions&#34; :key=&#34;item.type&#34; :label=&#34;`${item.type}(${item.name})`&#34; :value=&#34;item.type&#34; /&gt; &lt;/el-select&gt; &lt;/el-form-item&gt; //修改后： &lt;el-form-item label=&#34;关联字典&#34; prop=&#34;dictType&#34;&gt; &lt;el-select v-model=&#34;middleDate.dictType&#34; :disabled=&#34;middleDate.fieldType!==&#39;string&#39;&#34; placeholder=&#34;请选择字典&#34; clearable &gt; &lt;el-option v-for=&#34;item in dictOptions&#34; :key=&#34;item.type&#34; :label=&#34;`${item.type}(${item.name})`&#34; :value=&#34;item.type&#34; /&gt; &lt;/el-select&gt; &lt;/el-form-item&gt; 修改完成！   ]]></content></entry><entry><title>在Mac OS系统下永久试用软件</title><url>/posts/hackintosh/2023-01-05-%E5%9C%A8macos%E7%B3%BB%E7%BB%9F%E4%B8%8B%E6%B0%B8%E4%B9%85%E8%AF%95%E7%94%A8%E8%BD%AF%E4%BB%B6/</url><categories><category>技巧</category></categories><tags><tag>永久试用</tag></tags><content type="html"><![CDATA[  试用原理 部分软件每次启动后会先检查注册信息，只需要在系统启动后删除注册信息就可以永久免费试用！
支持的软件及下载地址 Beyond Compare PlistEdit Pro &hellip;
破解步骤 创建脚本 进入如下目录
cd &#34;/Users/$(whoami)/Library/Application Support/&#34; 新建一个FreeTrial文件
touch FreeTrial 内容如下(根据自己的实际使用情况修改下面的代码即可)
#!/bin/bash rm &#34;/Users/$(whoami)/Library/Application Support/Beyond Compare/registry.dat&#34; rm &#34;/Users/$(whoami)/Library/Application Support/PlistEdit Pro/.folderinfo&#34; 赋予新建的FreeTrial文件可执行权限
chmod +x FreeTrial 配置脚本开机运行 设置-通用-启动项
添加刚才创建的 FreeTrial 文件
这样有一个确定就是每次开机后都会打开一个终端窗口，如果你不想看到这个终端窗口的话可以手动执行该脚本。或者用其他更优雅的方式执行。
如果你想让页面好看一点，可以给FreeTrial配置一个icon
图标配置方式 在 这个网站 下载一个你喜欢的图标到桌面
右键点击 FreeTrial 在弹出的菜单中选择 显示简介 然后将刚才下载的图标拖到简介上方的图标即可。
  ]]></content></entry><entry><title>Golang中函数返回值注意点</title><url>/posts/golang/2022-12-09-golang%E4%B8%AD%E5%87%BD%E6%95%B0%E8%BF%94%E5%9B%9E%E5%80%BC%E6%B3%A8%E6%84%8F%E7%82%B9/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  Go语言函数返回值又两种方法，如下代码：
func GoReturn1() int { a := 0 return a } func GoReturn2() (a int) { a = 0 return } func main() { fmt.Println(&#34;返回值1：&#34;, GoReturn1()) fmt.Println(&#34;返回值2：&#34;, GoReturn2()) } 显然上面的函数返回值都是0没有什么不同，但是如果在函数体内加上一个defer func() ，那么就可能得到不同的结果 代码如下：
func GoReturn1() int { a := 0 defer func() { a++ }() return a } func GoReturn2() (a int) { a = 0 defer func() { a++ }() return a } func main() { fmt.Println(&#34;返回值1：&#34;, GoReturn1()) fmt.Println(&#34;返回值2：&#34;, GoReturn2()) } 运行结果： 返回值1： 0 返回值2： 1 为什么返回值不同呢？
由于Go的返回机制决定的，如果函数的返回值只声明了返回值的类型
func GoReturn1() int { a:=0 defer func(){ a++ } return a } 这种情况下Go会创建临时变量保存返回值,然后去执行 defer 后面的函数，这样虽然defer后面的函数修改了a的值，但不会修改临时变量中的值，所以会返回0
而函数声明返回值类型时同时带上了变量名，又是什么情况呢？
func GoReturn2() (a int) { a = 0 defer func() { a++ }() return a } 函数声明返回值类型时同时带上了变量名时，Go就不会创建临时变量保存返回值，而是直接返回声明时的变量，这样defer中修改了a的值.
  ]]></content></entry><entry><title>Golang泛型学习笔记</title><url>/posts/golang/2022-12-09-golang%E6%B3%9B%E5%9E%8B%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>go</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  什么是泛型？ 泛型程序设计（generic programming）是程序设计语言的一种风格或范式。泛型允许程序员在强类型程序设计语言中编写代码时使用一些以后才指定的类型，在实例化时作为参数指明这些类型。
Golang泛型Demo package main import ( &#34;fmt&#34; ) func main() { strs := []string{&#34;aaa&#34;, &#34;vdfe&#34;, &#34;djmerui&#34;} is := []int{1, 2, 3} printArray(strs) printAnyArray(strs) printComparableArray(strs) printArray(is) printAnyArray(is) printComparableArray(is) } // T 形式类型 string int 指定的实际类型 func printArray[T string | int](arr []T) { for _, a := range arr { fmt.Println(a) } } // 内置的泛型类型 any 任意类型 func printAnyArray[T any](arr []T) { for _, a := range arr { fmt.Println(a) } } // 内置的泛型类型 comparable 可比较的类型 func printComparableArray[T comparable](arr []T) { for _, a := range arr { fmt.Println(a) } } 泛型的作用
泛型减少重复代码并提高类型安全性
在下面情最的时候非常适合使用泛型：当你需要针对不同类型书写同样的逻辑，使用泛型来简化代码是最好的
泛型类型 只定义一个类型就能代表你想要的所有类型
Demo：
package main import &#34;fmt&#34; func main() { type MySlice[T int | float64] []T var s1 MySlice[int] = []int{1, 2, 3, 4} var s2 MySlice[float64] = []float64{1.11, 2.22, 3.33, 4.44} fmt.Print(s1, &#34; &#34;) fmt.Printf(&#34;%T&#34;, s1) fmt.Println() fmt.Print(s2, &#34; &#34;) fmt.Printf(&#34;%T&#34;, s2) fmt.Println() type MyMap[KEY int | string, VALUE any] map[KEY]VALUE var mp MyMap[string, int] = map[string]int{ &#34;go&#34;: 5, &#34;java&#34;: 6, } fmt.Print(mp, &#34; &#34;) fmt.Printf(&#34;%T&#34;, mp) } 运行结果： [1 2 3 4] main.MySlice[int] [1.11 2.22 3.33 4.44] main.MySlice[float64] map[go:5 java:6] main.MyMap[string,int] 泛型map type TMap[K string | int, V any] map[K]V func main() { p := make(TMap[string, any]) p[&#34;1&#34;] = 456 p[&#34;2&#34;] = 45.6 p[&#34;3&#34;] = &#34;45.6&#34; for s := range p { r := reflect.TypeOf(p[s]) fmt.Println(p[s], r.String()) } } //运行结果： 456 int 45.6 float64 45.6 string 泛型函数 泛型函数 package main import &#34;fmt&#34; func Add[T int | float64 | string](t1, t2 T) T { return t1 + t2 } func main() { fmt.Println(Add(&#34;S&#34;, &#34;3&#34;)) fmt.Println(Add(1, 2)) fmt.Println(Add(1.5, 2.6)) fmt.Println(Add[string](&#34;de&#34;, &#34;fr&#34;)) fmt.Println(Add[int](2, 4)) } 运行结果： S3 3 4.1 defr 6 泛型方法 package main import &#34;fmt&#34; type MySlice[T int | float64 | string] []T func (s MySlice[T]) GetMax() T { var max T for _, v := range s { if v &gt; max { max = v } } return max } func main() { var s1 MySlice[int] = []int{1, 22, 3, 4, 5, 6, 6} fmt.Println(s1.GetMax()) var s2 MySlice[string] = []string{&#34;hrty&#34;, &#34;ger&#34;, &#34;cre&#34;} fmt.Println(s2.GetMax()) } 运行结果： 22 hrty 泛型的使用 Go的泛型(或者或类型形参）目前可使用在了个地方
泛型类型 -类型定义中带类型形参的类型
泛型rceiver -泛型类型的receiver
泛型西数 -带类型形参的函数
自定义泛型 package main import &#34;fmt&#34; type int888 int8 type MyInt interface { ~int8 | int | int32 | int64 | float64 } func GetMacNum[T MyInt](t1, t2 T) T { if t1 &gt; t2 { return t1 } return t2 } func main() { var a int888 = 2 var b int888 = 3 fmt.Println(GetMacNum(a, b)) }   ]]></content></entry><entry><title>Python自动化-Selenium基操</title><url>/posts/python/2022-10-18-python%E8%87%AA%E5%8A%A8%E5%8C%96-selenium%E5%9F%BA%E6%93%8D/</url><categories><category>python</category></categories><tags><tag>python</tag><tag>自动化</tag></tags><content type="html"><![CDATA[  最近有一个新的需求要在集团的一个内部系统中根据条件获取获取Excel数据并导入另外一个系统，要用到一些自动化相关内容，所以记录一下。
什么是Selenium Selenium是一个用于Web应用程序测试的工具。Selenium测试直接运行在浏览器中，就像真正的用户在操作一样。支持的浏览器包括IE（7, 8, 9, 10, 11），Mozilla Firefox，Safari，Google Chrome，Opera，Edge等。这个工具的主要功能包括：测试与浏览器的兼容性——测试应用程序是否能够很好得工作在不同浏览器和操作系统之上。测试系统功能——创建回归测试检验软件功能和用户需求。支持自动录制动作和自动生成.Net、Java、Perl等不同语言的测试脚本。
下载安装Selenium 需要安装好python环境,不在叙述。 下载安装命令
pip3 install selenium 下载浏览器驱动 淘宝镜像地址：https://registry.npmmirror.com/binary.html?path=chromedriver/ Google官方地址：https://chromedriver.storage.googleapis.com/index.html 根据操作系统类型下载即可
使用Selenium Selenium支持的浏览器很多，这里以Chrome为例。
from selenium import webdriver from selenium.webdriver.common.by import By from selenium.webdriver.chrome.service import Service s = Service(&amp;#39;driver/chromedriver&amp;#39;) # 这里的chromedriver就是刚才下载的驱动 browser = webdriver.Chrome(service=s) url = &amp;#39;https://www.baidu.com&amp;#39; browser.get(url) time.sleep(1) searchText = browser.find_element(By.XPATH, &amp;#39;//*[@id=&amp;#34;kw&amp;#34;]&amp;#39;) …  ]]></content></entry><entry><title>antdesignvue在iPhone手机上传文件时选择文件</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-10-10-antdesignvue%E5%9C%A8iphone%E6%89%8B%E6%9C%BA%E4%B8%8A%E4%BC%A0%E6%96%87%E4%BB%B6%E6%97%B6%E9%80%89%E6%8B%A9%E6%96%87%E4%BB%B6/</url><categories><category>技巧</category></categories><tags><tag>技巧</tag><tag>Vue</tag><tag>Antd</tag><tag>前端</tag></tags><content type="html"><![CDATA[  还是这个项目 PublicFile-Server 的前端相关内容。
突然发现在iPhone上级上传文件的时候直接打开了相机，而在安卓手机上就可以选择相机或者文件。
搜索后发现只需要添加:capture=&quot;null&quot;即可。 代码如下：
&lt;div&gt; &lt;a-upload-dragger :progress=&#34;progress&#34; name=&#34;file&#34; :before-upload=&#34;beforeUpload&#34; :showUploadList=&#34;true&#34; :capture=&#34;null&#34; :multiple=&#34;false&#34; action=&#34;/file/upload&#34; @change=&#34;handleChange&#34;&gt; &lt;p class=&#34;ant-upload-drag-icon&#34;&gt; &lt;inbox-outlined&gt;&lt;/inbox-outlined&gt; &lt;/p&gt; &lt;p class=&#34;ant-upload-text&#34;&gt;点击或拖拽文件到这里进行上传&lt;/p&gt; &lt;/a-upload-dragger&gt; &lt;/div&gt; 这样的话iPhone手机就可以选择图库或者文件了！
  ]]></content></entry><entry><title>Gin+Vue前后端分离整合部署，不再需要nginx服务器</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-09-26-gin-vue%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E6%95%B4%E5%90%88%E9%83%A8%E7%BD%B2%E4%B8%8D%E5%86%8D%E9%9C%80%E8%A6%81nginx%E6%9C%8D%E5%8A%A1%E5%99%A8/</url><categories><category>技巧</category></categories><tags><tag>Gin</tag><tag>vue</tag></tags><content type="html"><![CDATA[  前言 最近在学前端，写了两个很小的项目 PublicFile-Server 、 PublicClipboard-Server-NoDB 两个项目都是前后端分离,分别用到了antdesignvue和elementUI。 两个都是单页面项目，如果用前后端分离去部署的话实在是麻烦。
Gin框架自带了静态文件服务,所以只需要简单修改代码即可实现前后端整合，当然开发的时候前后端仍然是分离的。
修改前端 前端修改起来超级简单
## vue.config.js const { defineConfig } = require(&#39;@vue/cli-service&#39;) module.exports = defineConfig({ transpileDependencies: true, publicPath: &#34;/static&#34;, //加上这一行即可 devServer: { port: 4000, proxy: { &#39;/file&#39;: { ws: false, target: &#34;http://127.0.0.1:9091&#34;, changeOrigin: true } } }, }) 修改后端 后端也是很简单的 在main.go的同级目录下新建一个static目录，然后将前端生成的dist目录下的所有文件都放进去。 然后再gin注册路由之前加上下面的代码即可
func main() { util.InitDB() model.InitAutoMigrateDB() r := gin.Default() ///添加的代码/// r.LoadHTMLGlob(&#34;static/index.html&#34;) r.Static(&#34;/static&#34;, &#34;static&#34;) r.GET(&#34;/&#34;, func(context *gin.Context) { context.HTML(200, &#34;index.html&#34;, &#34;&#34;) }) //////// router.RegRouter(r) r.Run(&#34;:&#34; + viper.GetString(&#34;server.port&#34;)) } 打包项目 后端编译后只需要将static目录和主程序一块打包即可。
  ]]></content></entry><entry><title>常用sql语句记录</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-09-22-%E5%B8%B8%E7%94%A8sql%E8%AF%AD%E5%8F%A5%E8%AE%B0%E5%BD%95/</url><categories><category>技巧</category></categories><tags><tag>mysql</tag><tag>oracle</tag></tags><content type="html"> 批量修改A表中数据在B表中的映射数据
UPDATE tableA a LEFT JOIN tableB b on a.Aid=b.Bid set a.codeA=b.codeB 在oracle中语句如下
UPDATE tableA SET tableA.codeA = ( SELECT tableB.codeB FROM tableB WHERE tableA.Aid = tableB.Bid );</content></entry><entry><title>Go语言实现RPC跨平台服务</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-09-03-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0rpc%E8%B7%A8%E5%B9%B3%E5%8F%B0%E6%9C%8D%E5%8A%A1/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"> 什么是RPC 服务 RPC，也就是远程过程调用，是分布式系统中不同节点调用的方式（进程间通信），属于 C/S 模式。RPC 由客户端发起，调用服务端的方法进行通信，然后服务端把结果返回给客户端。
RPC的核心有两个：通信协议和序列化。在 HTTP 2 之前，一般采用自定义 TCP 协议的方式进行通信，HTTP 2 出来后，也有采用该协议的，比如流行的gRPC。
序列化和反序列化是一种把传输内容编码和解码的方式，常见的编解码方式有 JSON、Protobuf 等。
在大多数 RPC的架构设计中，都有Client、Client Stub、Server、Server Stub这四个组件，Client 和 Server 之间通过 Socket 进行通信。RPC 架构如下图所示： 下面你总结下 RPC 调用的流程：
客户端（Client）调用客户端存根（Client Stub），同时把参数传给客户端存根； 客户端存根将参数打包编码，并通过系统调用发送到服务端； 客户端本地系统发送信息到服务器； 服务器系统将信息发送到服务端存根（Server Stub）； 服务端存根解析信息，也就是解码； 服务端存根调用真正的服务端程序（Sever）； 服务端（Server）处理后，通过同样的方式，把结果再返回给客户端（Client）。 RPC 调用常用于大型项目，也就是我们现在常说的微服务，而且还会包含服务注册、治理、监控等功能，是一套完整的体系。 Go 语言 RPC 简单入门 在 Go SDK 中，已经内置了 net/rpc 包来帮助开发者实现 RPC。简单来说，net/rpc 包提供了通过网络访问服务端对象方法的能力。
现在我通过一个加法运算来演示 RPC的使用，它的服务端代码如下所示：
package server type MathService struct { } type Args struct { A, B int } func (m *MathService) Add(args Args, reply *int) error { *reply = args.A + args.B return nil } 在以上代码中：
定义了MathService，用于表示一个远程服务对象；
Args 结构体用于表示参数；
Add 这个方法实现了加法的功能，加法的结果通过 replay这个 …</content></entry><entry><title>Go语言RESTfulAPI服务</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-09-03-%E8%BD%ACgo%E8%AF%AD%E8%A8%80restful-api-%E6%9C%8D%E5%8A%A1/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"> 使用G语言编写 RESTful API 和 RPC 服务。在实际开发项目中，编写的这些服务可以被其他服务使用，这样就组成了微服务的架构；也可以被前端调用，这样就可以前后端分离。
什么是 RESTful API RESTful API 是一套规范，它可以规范我们如何对服务器上的资源进行操作。在了解 RESTful API 之前，先学习一下 HTTP Method，因为 RESTful API 和它是密不可分的。
说起 HTTP Method，最常见的就是POST和GET，最早在 HTTP 0.9 版本中，只有一个GET方法，该方法是一个幂等方法，用于获取服务器上的资源，也就是我们在浏览器中直接输入网址回车请求的方法。
在 HTTP 1.0 版本中又增加了HEAD和POST方法，其中常用的是 POST 方法，一般用于给服务端提交一个资源，导致服务器的资源发生变化。
随着网络越来越复杂，发现这两个方法是不够用的，就继续新增了方法。所以在 HTTP1.1 版本的时候，一口气增加到了 9 个，新增的方法有 HEAD、OPTIONS、PUT、DELETE、TRACE、PATCH 和 CONNECT。
GET 方法可请求一个指定资源的表示形式，使用 GET 的请求应该只被用于获取数据。 HEAD 方法用于请求一个与 GET 请求的响应相同的响应，但没有响应体。 POST 方法用于将实体提交到指定的资源，通常导致服务器上的状态变化或副作用。 PUT 方法用于请求有效载荷替换目标资源的所有当前表示。 DELETE 方法用于删除指定的资源。 CONNECT 方法用于建立一个到由目标资源标识的服务器的隧道。 OPTIONS 方法用于描述目标资源的通信选项。 TRACE 方法用于沿着到目标资源的路径执行一个消息环回测试。 PATCH 方法用于对资源应用部分修改。 在 RESTful API 中，使用的主要是以下五种 HTTP 方法：
GET，表示读取服务器上的资源； POST，表示在服务器上创建资源； PUT，表示更新或者替换服务器上的资源； DELETE，表示删除服务器上的资源； PATCH，表示更新 / 修改资源的一部分。 以上 HTTP 方法在 RESTful API 规范中是一个操作，操作的就是服务器的资源，服务器的资源通过特定的 URL 表示。 …</content></entry><entry><title>oh-my-zsh安装配置记录</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-09-01-oh-my-zsh%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E8%AE%B0%E5%BD%95/</url><categories><category>技巧</category></categories><tags><tag>oh-my-zsh</tag></tags><content type="html"><![CDATA[  Oh My Zsh is a delightful, open source, community-driven framework for managing your Zsh configuration. It comes bundled with thousands of helpful functions, helpers, plugins, themes, and a few things that make you shout&hellip;
&ldquo;Oh My ZSH!&rdquo;
官网地址 安装 安装命令(二者均可)：
sh -c &#34;$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&#34; sh -c &#34;$(wget https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh -O -)&#34; 环境变量失效？ 将~/.bash_profile文件中的变量复制到~/.zshrc目录 macos下如果你之前用的是zsh 就将~/.zshrc.pre-oh-my-zsh文件中的变量复制到~/.zshrc目录即可
修改主题 // ~/.zshrc # Set name of the theme to load --- if set to &#34;random&#34;, it will # load a random theme each time oh-my-zsh is loaded, in which case, # to know which specific one was loaded, run: echo $RANDOM_THEME # See https://github.com/ohmyzsh/ohmyzsh/wiki/Themes ZSH_THEME=&#34;robbyrussell&#34; 插件 常用的两个插件
zsh-autosuggestions 自动建议补全 安装命令
git clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions zsh-syntax-highlighting 语法高亮插件 安装命令
git clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting 安装好以后启用插件,也是在~/.zshrc中配置
// ~/.zshrc # Which plugins would you like to load? # Standard plugins can be found in $ZSH/plugins/ # Custom plugins may be added to $ZSH_CUSTOM/plugins/ # Example format: plugins=(rails git textmate ruby lighthouse) # Add wisely, as too many plugins slow down shell startup. plugins=(git z zsh-autosuggestions zsh-syntax-highlighting) 刚安装好以后应该是只有一个git,后门两个是刚才下载的
z是自带插件，可以历史目录记录
配置好以后使用下面命令更新配置
source ~/.zshrc   ]]></content></entry><entry><title>Go语言模块化管理与协作开发</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-09-01-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9D%97%E5%8C%96%E7%AE%A1%E7%90%86%E4%B8%8E%E5%8D%8F%E4%BD%9C%E5%BC%80%E5%8F%91/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  任何业务，都是从简单向复杂演进的。而在业务演进的过程中，技术是从单体向多模块、多服务演进的。技术的这种演进方式的核心目的是复用代码、提高效率。
Go 语言中的包 什么是包 在业务非常简单的时候，甚至可以把代码写到一个 Go 文件中。但随着业务逐渐复杂，就会发现，如果代码都放在一个 Go 文件中，会变得难以维护，这时候就需要抽取代码，把相同业务的代码放在一个目录中。在 Go 语言中，这个目录叫作包。
在 Go 语言中，一个包是通过package 关键字定义的，最常见的就是main 包，它的定义如下所示：
package main
此外，之前演示示例经常使用到的 fmt 包，也是通过 package 关键字声明的。
一个包就是一个独立的空间，你可以在这个包里定义函数、结构体等。这时，我们认为这些函数、结构体是属于这个包的。 所有的go文件除了空行和注释，都应该在第一行声明所在的包，且同一个目录下的所有go文件都应该在一个包里(推荐包名和文件夹名保持一致)。
使用包 如果想使用一个包里的函数或者结构体，就需要先导入这个包，才能使用，比如常用的 fmt包，代码示例如下所示。
package main import &amp;#34;fmt&amp;#34; func main() { fmt.Println(&amp;#34;先导入fmt包，才能使用&amp;#34;) } 要导入一个包，需要使用 import 关键字；如果需要同时导入多个包，则可以使用小括号，示例代码如下所示。
import ( &amp;#34;fmt&amp;#34; &amp;#34;os&amp;#34; ) 从以上示例可以看到，该示例导入了 fmt 和 os 这两个包，使用了小括号，每一行写了一个要导入的包。
作用域 讲到了包之间的导入和使用，就不得不提作用域这个概念，因为只有满足作用域的函数才可以被调用。
在Java 语言中，通过 public、private 这些修饰符修饰一个类的作用域；
但是在Go 语言中，并没有这样的作用域修饰符，它是通过首字母是否大写来区分的，这同时也体现了 Go 语言的简洁。
如上述示例中 fmt 包中的Println 函数：
它的首字母就是大写的 P，所以该函数才可以在 main 包中使用；
如果 Println 函数的首字母是小写的 p，那么它只能在 fmt 包中被使用，不能跨包使用。
这里我为你总结下 Go 语言的作用域： …  ]]></content></entry><entry><title>Go语言代码检查和优化</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-30-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%BB%A3%E7%A0%81%E6%A3%80%E6%9F%A5%E5%92%8C%E4%BC%98%E5%8C%96/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  代码规范检查 什么是代码规范检查 代码规范检查，顾名思义，是从 Go 语言层面出发，依据 Go 语言的规范，对你写的代码进行的静态扫描检查，这种检查和你的业务无关。
比如你定义了个常量，从未使用过，虽然对代码运行并没有造成什么影响，但是这个常量是可以删除的，代码如下所示：
const name = &amp;#34;Golang&amp;#34; func main() { } 示例中的常量 name 其实并没有使用，所以为了节省内存你可以删除它，这种未使用常量的情况就可以通过代码规范检查检测出来。 再比如，你调用了一个函数，该函数返回了一个 error，但是你并没有对该 error 做判断，这种情况下，程序也可以正常编译运行。但是代码写得不严谨，因为返回的 error 被我们忽略了。代码如下所示：
func main() { os.Mkdir(&amp;#34;tmp&amp;#34;,0666) } 示例代码中，Mkdir 函数是有返回 error 的，但是并没有对返回的 error 做判断，这种情况下，哪怕创建目录失败，你也不知道，因为错误被忽略了。如果使用代码规范检查，这类潜在的问题也会被检测出来。
以上两个例子可以理解什么是代码规范检查、它有什么用。除了这两种情况，还有拼写问题、死代码、代码简化检测、命名中带下划线、冗余代码等，都可以使用代码规范检查检测出来。
golangci-lint 要想对代码进行检查，则需要对代码进行扫描，静态分析写的代码是否存在规范问题。
小提示：静态代码分析是不会运行代码的。
可用于 Go 语言代码分析的工具有很多，比如 golint、gofmt、misspell 等，如果一一引用配置，就会比较烦琐，所以通常我们不会单独地使用它们，而是使用 golangci-lint。
golangci-lint 是一个集成工具，它集成了很多静态代码分析工具，便于我们使用。通过配置这一工具，我们可以很灵活地启用需要的代码规范检查。
如果要使用 golangci-lint，首先需要安装。因为 golangci-lint 本身就是 Go 语言编写的，所以我们可以从源代码安装它，打开终端，输入如下命令即可安装。
go install github.com/golangci/golangci-lint/cmd/golangci-lint@latest 安装完成后，在终端输入如下命令， …  ]]></content></entry><entry><title>Go语言单元测试</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-29-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  单元测试 什么是单元测试 顾名思义，单元测试强调的是对单元进行测试。在开发中，一个单元可以是一个函数、一个模块等。一般情况下，你要测试的单元应该是一个完整的最小单元，比如 Go 语言的函数。这样的话，当每个最小单元都被验证通过，那么整个模块、甚至整个程序就都可以被验证通过。 单元测试由开发者自己编写，也就是谁改动了代码，谁就要编写相应的单元测试代码以验证本次改动的正确性。
Go 语言的单元测试 虽然每种编程语言里单元测试的概念是一样的，但它们对单元测试的设计不一样。Go 语言也有自己的单元测试规范，通过典型的例子斐波那契数列进行演示。 斐波那契数列是一个经典的黄金分隔数列：它的第 0 项是 0；第 1 项是 1；从第 2 项开始，每一项都等于前两项之和。所以它的数列是：0、1、1、2、3、5、8、13、21……
说明：为了便于总结后面的函数方程式，这里特意写的从第 0 项开始，其实现实中没有第 0 项。
根据以上规律，可以总结出它的函数方程式。
F(0)=0 F(1)=1 F(n)=F(n - 1)+F(n - 2) 有了函数方程式，再编写一个 Go 语言函数来计算斐波那契数列就比较简单了，代码如下：
func Fibonacci(n int) int { if n &amp;lt; 0 { return 0 } if n == 0 { return 0 } if n == 1 { return 1 } return Fibonacci(n-1) + Fibonacci(n-2) } Fibonacci 函数已经编写好了，可以供其他开发者使用，不过在使用之前，需要先对它进行单元测试。需要新建一个 go 文件用于存放单元测试代码。
//main_test.go func TestFibonacci(t *testing.T) { type args struct { n int } tests := []struct { name string args args want int }{ {&amp;#34;1&amp;#34;, args{0}, 0}, {&amp;#34;1&amp;#34;, args{1}, 1}, {&amp;#34;1&amp;#34;, args{2}, 1}, {&amp;#34;1&amp;#34;, args{3}, 2}, {&amp;#34;1&amp;#34;, args{4}, 3}, } for _, tt …  ]]></content></entry><entry><title>Go语言中的Slice</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-29-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%B8%AD%E7%9A%84slice/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  数组 几乎所有的编程语言里都存在数组，Go 也不例外。那么为什么 Go 语言除了数组之外又设计了 slice 呢？要想解答这个问题，先来了解数组的局限性。
在下面的示例中，a1、a2 是两个定义好的数组，但是它们的类型不一样。变量 a1 的类型是 [1]string，变量 a2 的类型是 [2]string，也就是说数组的大小属于数组类型的一部分，只有数组内部元素类型和大小一致时，这两个数组才是同一类型。
a1:=[1]string{&amp;#34;golang&amp;#34;} a2:=[2]string{&amp;#34;golang&amp;#34;} 可以总结为，一个数组由两部分构成：数组的大小和数组内的元素类型。
//数组结构伪代码表示 array{ len item type } 比如变量 a1 的大小是 1，内部元素的类型是 string，也就是说 a1 最多只能存储 1 个类型为 string 的元素。而 a2 的大小是 2，内部元素的类型也是 string，所以 a2 最多可以存储 2 个类型为 string 的元素。一旦一个数组被声明，它的大小和内部元素的类型就不能改变，你不能随意地向数组添加任意多个元素。这是数组的第一个限制。
既然数组的大小是固定的，如果需要使用数组存储大量的数据，就需要提前指定一个合适的大小，比如 10 万，代码如下所示：
a10:=[100000]string{&amp;#34;golang&amp;#34;} 这样虽然可以解决问题，但又带来了另外的问题，那就是内存占用。因为在 Go 语言中，函数间的传参是值传递的，数组作为参数在各个函数之间被传递的时候，同样的内容就会被一遍遍地复制，这就会造成大量的内存浪费，这是数组的第二个限制。
虽然数组有限制，但是它是 Go 非常重要的底层数据结构，比如 slice 切片的底层数据就存储在数组中。
slice 切片 数组虽然也不错，但是在操作上有不少限制，为了解决这些限制，Go 语言创造了 slice，也就是切片。切片是对数组的抽象和封装，它的底层是一个数组存储所有的元素，但是它可以动态地添加元素，容量不足时还可以自动扩容，你完全可以把切片理解为动态数组。在 Go 语言中，除了明确需要指定长度大小的类型需要数组来完成，大多数情况下都是使用切片的。
动态扩容 通过内置的 append 方法，你可以向一个切片中追加任意多个元素，所 …  ]]></content></entry><entry><title>Go语言又爱又恨的unsafe</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-28-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%8F%88%E7%88%B1%E5%8F%88%E6%81%A8%E7%9A%84unsafe/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"> 顾名思义，unsafe 是不安全的。Go 将其定义为这个包名，也是为了让我们尽可能地不使用它。不过虽然不安全，它也有优势，那就是可以绕过 Go 的内存安全机制，直接对内存进行读写。所以有时候出于性能需要，还是会冒险使用它来对内存进行操作。
指针类型转换 Go 的设计者为了编写方便、提高效率且降低复杂度，将其设计成一门强类型的静态语言。强类型意味着一旦定义了，类型就不能改变；静态意味着类型检查在运行前就做了。同时出于安全考虑，Go 语言是不允许两个指针类型进行转换的。
我们一般使用 *T 作为一个指针类型，表示一个指向类型 T 变量的指针。为了安全的考虑，两个不同的指针类型不能相互转换，比如 *int 不能转为 *float64。
我们来看下面的代码：
func main() { i:= 10 ip:=&amp;amp;amp;i var fp *float64 = (*float64)(ip) fmt.Println(fp) } 运行结果 cannot convert ip (type * int) to type * float64 这个代码在编译的时候，会提示 cannot convert ip (type * int) to type * float64，也就是不能进行强制转型。那如果还是需要转换呢？这就需要使用 unsafe 包里的 Pointer 了。下面先学习 unsafe.Pointer 是什么，再学习如何转换。
unsafe.Pointer unsafe.Pointer 是一种特殊意义的指针，可以表示任意类型的地址，类似 C 语言里的 void* 指针，是全能型的。
正常情况下，*int 无法转换为 *float64，但是通过 unsafe.Pointer 做中转就可以了。在下面的示例中，我通过 unsafe.Pointer 把 *int 转换为 *float64，并且对新的 *float64 进行 3 倍的乘法操作，你会发现原来变量 i 的值也被改变了，变为 30。
func main() { i:= 10 ip:=&amp;amp;amp;i var fp *float64 = (*float64)(unsafe.Pointer(ip)) *fp = *fp * 3 fmt.Println(i) } 运行结果 30 这个例子没有任何实际意义， …</content></entry><entry><title>Go语言字符串和结构体之间转换</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-27-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%92%8C%E7%BB%93%E6%9E%84%E4%BD%93%E4%B9%8B%E9%97%B4%E8%BD%AC%E6%8D%A2/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"> 在web应用调用 API 的时候，需要把 API 返回的 JSON 字符串转换为 struct 结构体，便于操作。那么一个 JSON 字符串是如何转换为 struct 结构体的呢？这就需要用到反射的知识，今天学习基于字符串和结构体之间的转换，一步步地揭开 Go 语言运行时反射的面纱。
反射是什么？ 和 Java 语言一样，Go 语言也有运行时反射，这为我们提供了一种可以在运行时操作任意类型对象的能力。比如查看一个接口变量的具体类型、看看一个结构体有多少字段、修改某个字段的值等。
Go 语言是静态编译类语言，比如在定义一个变量的时候，已经知道了它是什么类型，那么为什么还需要反射呢？这是因为有些事情只有在运行时才知道。比如你定义了一个函数，它有一个interface{}类型的参数，这也就意味着调用者可以传递任何类型的参数给这个函数。在这种情况下，如果你想知道调用传递的是什么类型的参数，就需要用到反射。如果你想知道一个结构体有哪些字段和方法，也需要反射。 以常用的函数 fmt.Println 为例，如下所示：
//src/fmt/print.go func Println(a ...interface{}) (n int, err error) { return Fprintln(os.Stdout, a...) } fmt.Println 的源代码有一个可变参数，类型为 interface{}，这意味着你可以传递零个或者多个任意类型参数给它，都能被正确打印。
reflect.Value 和 reflect.Type 在 Go 语言的反射定义中，任何接口都由两部分组成：接口的具体类型，以及具体类型对应的值。比如 var i int = 3，因为 interface{} 可以表示任何类型，所以变量 i 可以转为 interface{}。你可以把变量 i 当成一个接口，那么这个变量在 Go 反射中的表示就是 &amp;amp;lt;Value,Type&amp;amp;gt;。其中 Value 为变量的值，即 3，而 Type 为变量的类型，即 int。
小提示：interface{} 是空接口，可以表示任何类型，也就是说你可以把任何类型转换为空接口，它通常用于反射、类型断言，以减少重复代码，简化编程。
在 Go 反射中，标准库为我们提供了两种类型 reflect.Value 和 reflect.Type …</content></entry><entry><title>Go语言中make和new的区别</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-26-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%B8%ADmake%E5%92%8Cnew%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  程序的运行都需要内存，比如像变量的创建、函数的调用、数据的计算等。所以在需要内存的时候就要申请内存，进行内存分配。在 C/C++ 这类语言中，内存是由开发者自己管理的，需要主动申请和释放，而在 Go 语言中则是由该语言自己管理的，开发者不用做太多干涉，只需要声明变量，Go 语言就会根据变量的类型自动分配相应的内存。
Go 语言程序所管理的虚拟内存空间会被分为两部分：堆内存和栈内存。栈内存主要由 Go 语言来管理，开发者无法干涉太多，堆内存才是我们开发者发挥能力的舞台，因为程序的数据大部分分配在堆内存上，一个程序的大部分内存占用也是在堆内存上。
小提示：我们常说的 Go 语言的内存垃圾回收是针对堆内存的垃圾回收。
变量的声明、初始化就涉及内存的分配，比如声明变量会用到 var 关键字，如果要对变量初始化，就会用到 = 赋值运算符。除此之外还可以使用内置函数 new 和 make，这两个函数在前面的代码中已经见过，它们的功能非常相似，但可能还是比较迷惑，今天就基于内存分配，进而引出内置函数 new 和 make，学习他们的不同，以及使用场景。
变量 变量的声明 var s string //使用var关键字声明一个变量
该示例只是声明了一个变量 s，类型为 string，并没有对它进行初始化，所以它的值为 string 的零值，也就是 &amp;ldquo;&amp;quot;（空字符串）。
之前学到 string 其实是个值类型，现在我们来声明一个指针类型的变量试试，如下所示：
var sp *string
发现也是可以的，但是它同样没有被初始化，所以它的值是 *string 类型的零值，也就是 nil。
变量的赋值 变量可以通过 = 运算符赋值，也就是修改变量的值。如果在声明一个变量的时候就给这个变量赋值，这种操作就称为变量的初始化。如果要对一个变量初始化，可以有三种办法。
声明时直接初始化，比如 var s string = &amp;ldquo;我的Blog&amp;rdquo;。 声明后再进行初始化，比如 s=&amp;ldquo;我的Blog&amp;rdquo;（假设已经声明变量 s）。 使用 := 简单声明，比如 s:=&amp;ldquo;我的Blog&amp;rdquo;。 小提示：变量的初始化也是一种赋值，只不过它发生在变量声明的时候，时机最靠前。也就是说，当你获得这个变量时，它就已经被赋值了。
下面通过代码演 …  ]]></content></entry><entry><title>Go语言值,引用,指针之间的区别</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-25-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%80%BC%E5%BC%95%E7%94%A8%E6%8C%87%E9%92%88%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  前言 先看一段代码
type address struct { province string city string } func (addr address) String() string { return fmt.Sprintf(&amp;#34;the addr is %s%s&amp;#34;, addr.province, addr.city) } func main() { add := address{province: &amp;#34;山东省&amp;#34;, city: &amp;#34;济南市&amp;#34;} printString(add) printString(&amp;amp;add) } func printString(s fmt.Stringer) { fmt.Println(s.String()) } 运行结果： the addr is 山东省济南市 the addr is 山东省济南市 这段代码中先声明了一个结构体address，结构体有两个string类型的元素组成，分别是省份和城市
然后为addres这个结构体实现了String方法 返回值类型为string 并且进行了格式化
在main函数中先创建一个addres对象并初始化了值 然后分别使用变量和他的指针作为参数调用了printString函数 这个函数的形参是fmt.Stringer 看一下这个fmt.Stringer的解释
Stringer 由任何具有 String 方法的值实现，该方法定义了该值的“native”格式。 String 方法用于将作为操作数传递的值打印到任何接受字符串的格式或未格式化的printer（例如 Print）
因为address实现了String方法，所以可以将addr传入printString函数
printString函数就是将传入变量调用String方法的结果打印出来 也就是上面接口实现时的返回值 由此可见在代码
func (addr address) String() string { return fmt.Sprintf(&amp;#34;the addr is %s%s&amp;#34;, addr.province, addr.city) } 中，不仅address实现了String方法 *address 也实现了String方法
如果我们将这个实现方法改成下面的样子结果会怎样呢？ …  ]]></content></entry><entry><title>Go语言指针学习</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-24-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E6%8C%87%E9%92%88%E5%AD%A6%E4%B9%A0/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  什么是指针 程序运行时的数据是存放在内存中的，而内存会被抽象为一系列具有连续编号的存储空间，那么每一个存储在内存中的数据都会有一个编号，这个编号就是内存地址。有了这个内存地址就可以找到这个内存中存储的数据，而内存地址可以被赋值给一个指针。
小提示：内存地址通常为 16 进制的数字表示，比如 0x45b876。
可以总结为：在编程语言中，指针是一种数据类型，用来存储一个内存地址，该地址指向存储在该内存中的对象。这个对象可以是字符串、整数、函数或者你自定义的结构体。
小技巧：你也可以简单地把指针理解为内存地址。
举个通俗的例子，每本书中都有目录，目录上会有相应章节的页码，你可以把页码理解为一系列的内存地址，通过页码你可以快速地定位到具体的章节（也就是说，通过内存地址可以快速地找到存储的数据）。
Go语言中指针的声明和定义 func main() { name := &amp;#34;Golang&amp;#34; nameP := &amp;amp;name //取地址 fmt.Println(&amp;#34;name变量的值为:&amp;#34;, name) fmt.Println(&amp;#34;nameP变量的值为:&amp;#34;, nameP) fmt.Printf(&amp;#34;nameP变量的类型为:%T&amp;#34;, nameP) } //运行结果 name变量的值为: Golang nameP变量的值为: 0xc000010200 nameP变量的类型为:*string 这一串 0xc000010200 就是内存地址(这个每次运行得到的结果都是不一样的)，这个内存地址可以赋值给指针变量 nameP。
指针类型非常廉价，只占用 4 个或者 8 个字节的内存大小。
以上示例中 nameP 指针的类型是 *string，用于指向 string 类型的数据。在 Go 语言中使用类型名称前加 * 的方式，即可表示一个对应的指针类型。比如 int 类型的指针类型是 *int，float64 类型的指针类型是 *float64，自定义结构体 A 的指针类型是 *A。总之，指针类型就是在对应的类型前加 * 号。
从图中可以看到普通变量 name 的值“Golang”被放到内存地址为 0xc000010200 的内存块中。指针类型变量也是变量，它也需要一块内存用来存储值，这块内存对应的地址就是 0xc00000e028，存 …  ]]></content></entry><entry><title>Go语言常见的高效并发模式</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-18-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E5%B8%B8%E8%A7%81%E7%9A%84%E9%AB%98%E6%95%88%E5%B9%B6%E5%8F%91%E6%A8%A1%E5%BC%8F/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  如何用 goroutine、channel、sync包 这些基础元素组成并发模式，更好地编写并发程序。
for select 循环模式 for { //for无限循环，或者for range循环 select { //通过一个channel控制 } } for select 循环模式一 无限循环直到停止指令 for { select { case &amp;lt;-done: return default: //执行具体的任务 } } for select 循环模式二 迭代循环 一般用于把可以迭代的内容发送到 channel 上 for _,s:=range []int{}{ select { case &amp;lt;-done: return case resultCh &amp;lt;- s: } } select timeout 模式 假如需要访问服务器获取数据，因为网络的不同响应时间不一样，为保证程序的质量，不可能一直等待网络返回，所以需要设置一个超时时间，这时候就可以使用 select timeout 模式
func main() { result := make(chan string) go func() { //模拟网络访问 time.Sleep(8 * time.Second) result &amp;lt;- &amp;#34;服务端结果&amp;#34; }() select { case v := &amp;lt;-result: fmt.Println(v) case &amp;lt;-time.After(5 * time.Second): fmt.Println(&amp;#34;网络访问超时了&amp;#34;) } } select timeout 模式的核心在于通过 time.After 函数设置一个超时时间，防止因为异常造成 select 语句的无限等待。
Pipeline 模式 Pipeline 模式也称为流水线模式，模拟的就是现实世界中的流水线生产。以手机组装为例，整条生产流水线可能有成百上千道工序，每道工序只负责自己的事情，最终经过一道道工序组装，就完成了一部手机的生产。
从技术上看，每一道工序的输出，就是下一道工序的输入，在工序之间传递的东西就是数据，这种模式称为流水线模式，而传递的数据称为数据流。 通过以上流水线模式示意图，可以看到从最开始的生产，经过工序 1、2、3、4 到最终成品，这就是一条 …  ]]></content></entry><entry><title>Go语言Context学习笔记</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-16-%E8%BD%ACgo%E8%AF%AD%E8%A8%80context%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  前言 之前学习了怎么在所有的协程运行结束后让程序停止。这次学一下怎么让运行中的协程停止。比如我们开了1个协程去监控一个程序，如果我们手动取消监控就要让协程主动停止任务，该怎么实现呢？用 select+channel 做检测！
func main() { var wg sync.WaitGroup wg.Add(1) stopCh := make(chan bool) //用来停止监控狗 go func() { defer wg.Done() watchDog(stopCh,&amp;#34;【监控狗1】&amp;#34;) }() time.Sleep(5 * time.Second) //先让监控狗监控5秒 stopCh &amp;lt;- true //发停止指令 wg.Wait() } func watchDog(stopCh chan bool,name string){ //开启for select循环，一直后台监控 for{ select { case &amp;lt;-stopCh: fmt.Println(name,&amp;#34;停止指令已收到，马上停止&amp;#34;) return default: fmt.Println(name,&amp;#34;正在监控……&amp;#34;) } time.Sleep(1*time.Second) } } 初识Context 在实际应用中为了更好的利用资源肯定不会只开一个协程去处理任务，如果开了多个协程去监控，那怎么同时取消多个协程呢？使用多个channel吗？如果是几百上千个协程呢？使用channel的局限性就提现出来了。这时候就要用到Context包了。context不仅可以同时取消多个协程，还可以定时取消！先看下使用Context修改后的代码
func main() { var wg sync.WaitGroup wg.Add(1) ctx,stop:=context.WithCancel(context.Background()) go func() { defer wg.Done() watchDog(ctx,&amp;#34;【监控狗1】&amp;#34;) }() time.Sleep(5 * time.Second) //先让监控狗监控5秒 stop() //发停止指令 wg.Wait() } func watchDog(ctx …  ]]></content></entry><entry><title>Go语言中使用sync包控制并发</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-15-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%B8%AD%E4%BD%BF%E7%94%A8sync%E5%8C%85%E6%8E%A7%E5%88%B6%E5%B9%B6%E5%8F%91/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  sync.Mutex 和 sync.RWMutex 如果同一块内存被多个 goroutine 同时访问，就会产生不知道谁先访问也无法预料最后结果的情况。这就是资源竞争，这块内存可以称为共享的资源。例如下面的代码
var sum = 0 func main() { for i := 1; i &amp;lt; 5; i++ { go add(i) } time.Sleep(2 * time.Second) fmt.Println(&amp;#34;和为:&amp;#34;, sum) } func add(i int) { fmt.Println(&amp;#34;add前sum=&amp;#34;, sum) sum += i fmt.Println(&amp;#34;add &amp;#34;, i, &amp;#34;后sum=&amp;#34;, sum) } 运行结果: add前sum= 0 add 2 后sum= 2 add前sum= 0 add前sum= 0 add 4 后sum= 7 add 1 后sum= 3 add前sum= 2 add 3 后sum= 10 和为: 10 通过上面的代码我们发现我们创建的4个协程再执行add中的语句时是有可能同时执行的,这就是资源竞争,并没有得到想要结果。那我们有没有什么办法能在同一时刻只有一个协程去读取sum呢？这就要用到sync包了。看下面的代码
var sum = 0 var mutex sync.Mutex func main() { for i := 1; i &amp;lt; 5; i++ { go add(1) } time.Sleep(2 * time.Second) fmt.Println(&amp;#34;和为:&amp;#34;, sum) } func add(i int) { mutex.Lock() defer mutex.Unlock() fmt.Println(&amp;#34;add前sum=&amp;#34;, sum) sum += i fmt.Println(&amp;#34;add &amp;#34;, i, &amp;#34;后sum=&amp;#34;, sum) } 运行结果： add前sum= 0 add 2 后sum= 2 add前sum= 2 add 1 后sum= 3 add前sum= 3 add 4 后sum= 7 add前sum= 7 add 3 后sum= 10 和为: 10 通过上面的代码我们 …  ]]></content></entry><entry><title>Go语言使用channel进行goroutine通信</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-15-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%BD%BF%E7%94%A8channel%E8%BF%9B%E8%A1%8Cgoroutine%E9%80%9A%E4%BF%A1/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  声明channel channel是go语言中的一种数据类型，也叫通道 声明方式
ch:=make(chan string, n) ch : channel的变量名 chan : 声明channel的关键字 string : channel中存储额数据类型 n: 缓冲长度(不填时代表无缓冲) 如果给一个 nil 的 channel 发送数据，会造成永远阻塞。
如果从一个 nil 的 channel 中接收数据，也会造成永久阻塞。 给一个已经关闭的 channel 发送数据，会引起 panic
从一个已经关闭的 channel 接收数据，如果缓冲区中为空，则返回一个零 值。 无缓冲的 channel 是同步的，而有缓冲的 channel 是非同步的。
channel的操作 1.发送数据
ch &amp;lt;- &amp;#34;你好&amp;#34; 2.接受数据
str := &amp;lt;-ch fmt.Println(str) // 你好 3.测试
func main() { ch := make(chan string, 3) // 3 是指channel的缓冲长度为3 i := 0 go func() { for ; i &amp;lt; 10; i++ { ch &amp;lt;- strconv.Itoa(i) log.Println(&amp;#34;向ch中-&amp;gt;发送了 &amp;#34;, i, &amp;#34;此时ch的长度为：&amp;#34;, len(ch)) } }() go func() { for { time.Sleep(time.Second * 2) log.Println(&amp;#34;在ch中&amp;lt;-取出了 &amp;#34;, &amp;lt;-ch, &amp;#34;此时ch的长度为:&amp;#34;, len(ch)) } }() for { time.Sleep(time.Second * 3) if len(ch) == 0 { break } } } 输出结果： 2022/08/15 11:25:28 向ch中-&amp;gt;发送了 0 此时ch的长度为： 1 2022/08/15 11:25:28 向ch中-&amp;gt;发送了 1 此时ch的长度为： 2 2022/08/15 11:25:28 向ch中-&amp;gt;发送了 2 此时ch的长度为： 3 2022/08/15 11:25:30 在ch中&amp;lt;-取出了 0 此 …  ]]></content></entry><entry><title>Go语言错误处理笔记</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-14-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E7%AC%94%E8%AE%B0/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  type error interface { Error() string } 一、常见的使用方法 func add(a, b int) (int, error) { if a &lt; 0 || b &lt; 0 { return 0, errors.New(&#34;传入参数不能为负数&#34;) } return a + b, nil } func main() { sum, err := add(1, -2) if err != nil { fmt.Println(err) } else { fmt.Println(sum) } } 二、Error Wrapping func main() { e := errors.New(&#34;原始error&#34;) e1 := fmt.Errorf(&#34;Wrap一个error:%w&#34;, e) fmt.Println(e1) // Wrap一个error:原始error } 使用这种方式可以对原有的error进行修饰 errors.Unwrap(e error) 可以获取被嵌套的error
func main() { e := errors.New(&#34;原始error&#34;) e1 := fmt.Errorf(&#34;Wrap一个error:%w&#34;, e) e2 := errors.Unwrap(e1) fmt.Println(e2) //原始error } errors.IS(e1,e2 error) 可以判断被嵌套的error是不是原有的error
func main() { e := errors.New(&#34;原始error&#34;) e1 := fmt.Errorf(&#34;Wrap一个error:%w&#34;, e) fmt.Println(errors.Is(e, e1)) //false e2 := fmt.Errorf(&#34;又Wrap一个error:%w&#34;, e1) fmt.Println(errors.Is(e2, e1)) //true fmt.Println(errors.Is(e2, e)) //true }   ]]></content></entry><entry><title>Go语言接口学习笔记</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-14-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E6%8E%A5%E5%8F%A3%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  一、接口的定义 接口是和调用方的一种约定 是一个高度抽象的类型 不同和具体的实现细节绑定在一起
示例代码： type Person interface { //定义一个Person接口 Speak(msg string) Walk() } type Student struct { name string } type Teacher struct { name string } /** Student实现Person接口的两个方法 */ func (s Student) Speak(msg string) { fmt.Println(s.name, &#34; say &#34;, msg) } func (s Student) Walk() { fmt.Println(s.name, &#34; 会走路 &#34;) } func (t Teacher) Speak(msg string) { fmt.Println(t.name, &#34; say &#34;, msg) } func (t Teacher) Walk() { fmt.Println(t.name, &#34; 会走路 &#34;) } func main() { var p1 Person = Student{name: &#34;小明&#34;} var p2 Person = Teacher{name: &#34;王老师&#34;} p1.Speak(&#34;老师好&#34;) p2.Speak(&#34;同学们好&#34;) } 二、解释说明 一个类型实现了一个接口的所有方法就说明这个类型实现了这个接口
接口就是一个需要实现的方法列表
当我们使用指针实现接口时，只有指针类型的变量才会实现该接口；当我们使用结构体实现接口时，指针类型和结构体类型都会实现该接口。
三、空接口 空interface(interface{})不包含任何的method，正因为如此，所有的类型都实现了空interface
作为数据容器时，空interface可以存储任意类型的数值。
interface{} 类型不是任意类型
空接口作为函数参数 func show(a interface{}) { fmt.Printf(&#34;type:%T value:%v\n&#34;, a, a) } func main() { show(555) show(float64(5.1234567890123456789)) show(float32(5.123456789)) show(&#34;hello&#34;) } //运行结果 type:int value:555 type:float64 value:5.123456789012345 type:float32 value:5.123457 type:string value:hello float32 和 float64 Go语言中提供了两种精度的浮点数 float32 和 float64。
float32，也即我们常说的单精度，存储占用4个字节，也即4*8=32位，其中1位用来符号，8位用来指数，剩下的23位表示尾数
float64，也即我们熟悉的双精度，存储占用8个字节，也即8*8=64位，其中1位用来符号，11位用来指数，剩下的52位表示尾数
那么精度是什么意思？有效位有多少位？
精度主要取决于尾数部分的位数。
对于 float32（单精度）来说，表示尾数的为23位，除去全部为0的情况以外，最小为2-23，约等于1.19*10-7，所以float小数部分只能精确到后面6位，加上小数点前的一位，即有效数字为7位。
同理 float64（单精度）的尾数部分为 52位，最小为2-52，约为2.22*10-16，所以精确到小数点后15位，加上小数点前的一位，有效位数为16位。
空接口作为map值 var studentInfo = make(map[string]interface{}) studentInfo[&#34;name&#34;] = &#34;Wilen&#34; studentInfo[&#34;age&#34;] = 18 studentInfo[&#34;married&#34;] = false fmt.Println(studentInfo) //map[age:18 married:false name:Wilen] //例如gin框架的gin.H{} 四、注意事项 只有当有两个或两个以上的具体类型必须以相同的方式进行处理时才需要定义接口。不要为了接口而写接口，那样只会增加不必要的抽象，导致不必要的运行时损耗。
  ]]></content></entry><entry><title>Go语言中函数和方法的区别</title><url>/posts/golang%E5%9F%BA%E7%A1%80/2022-08-14-%E8%BD%ACgo%E8%AF%AD%E8%A8%80%E4%B8%AD%E5%87%BD%E6%95%B0%E5%92%8C%E6%96%B9%E6%B3%95%E7%9A%84%E5%8C%BA%E5%88%AB/</url><categories><category>go基础</category></categories><tags><tag>go</tag></tags><content type="html"><![CDATA[  一、函数 1.举个🌰 func sum(a,b int) int{ return a+b } func ： 关键字func
sum ：函数名
(a,b int) int：可以传入两个int类型的形参，返回值为int类型
2.多返回值 func sumAndsub(a,b int) （int,int){ return a+b,a-b } func main(){ sum,sub:=sumAndsub(5,3) fmt.Println(sum,sub) // 8 2 } 3.可变参数 // 可变参数列表需在参数列表中的最后一位，且为切片类型 func operation(op string, params ...int) int { result := 0 switch { case op == &#34;+&#34;: for _, v := range params { result += v } case op == &#34;*&#34;: result = 1 for _, v := range params { result *= v } } return result } func main() { result1 := operation(&#34;+&#34;, 1, 2, 3, 4) result2 := operation(&#34;*&#34;, 1, 2, 3, 4) fmt.Println(result1) // 10 fmt.Println(result2) // 24 } //运行结果 params的类型为[]int params的类型为[]int 10 24 4.匿名函数 func creatFunc1() func() int { i := 0 return func() int { i++ return i } } func creatFunc2() func() int { i := 0 return func() int { defer func() { i++ }() return i } } func main() { addFunc1 := creatFunc1() fmt.Println(addFunc1()) fmt.Println(addFunc1()) fmt.Println(addFunc1()) fmt.Println(&#34;===============&#34;) addFunc2 := creatFunc2() fmt.Println(addFunc2()) fmt.Println(addFunc2()) fmt.Println(addFunc2()) } 运行结果： 1 2 3 =============== 0 1 2 二、方法 type rectangle struct { long int width int } func (r rectangle) getArea() int { return r.long * r.width } func (r rectangle) getGirth() int { return (r.long + r.width) * 2 } func main() { r := rectangle{ long: 3, width: 4, } fmt.Println(r.getArea()) fmt.Println(r.getGirth()) fmt.Println(&#34;=============&#34;) ga := rectangle.getArea fmt.Println(ga(r)) gg := rectangle.getGirth fmt.Println(gg(r)) } 运行结果： 12 14 ============= 12 14 三、总结 二者概念基本相同,区别是二者所属的对象不同
函数属于包,方法属于类型
  ]]></content></entry><entry><title>记录一个集合相关算法的实现代码</title><url>/posts/%E6%8A%80%E5%B7%A7/2022-08-13-%E8%AE%B0%E5%BD%95%E4%B8%80%E4%B8%AA%E9%9B%86%E5%90%88%E7%9B%B8%E5%85%B3%E7%AE%97%E6%B3%95%E7%9A%84%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%A0%81/</url><categories><category>技巧</category></categories><tags><tag>code</tag></tags><content type="html"><![CDATA[  算法说明 讨论个算法 场景一 集合一：1、3 集合二：3、4、5 如何得到 集合 1、4、5 场景二 集合一：1、2、3 集合二：2、3、3、4、5 如何得到 集合 1、3、4、5 文字描述 同事A算法 合并两个集合后将出现偶数次的元素剔除 同事B算法 遍历两个集合，把每个元素出现的次数通过map&lt;元素，次数&gt;记录下来，最后遍历map，把次数为偶数的删除，剩下的拿出来所有的key就是需要的集合 合并两个集合并排序，然后一次遍历去掉重复的元素
代码实现 package main import ( &#34;fmt&#34; &#34;sort&#34; ) func func1(a, b []int) (stack []int) { c := append(a, b...) sort.Ints(c) for _, v := range c { if len(stack) == 0 { stack = append(stack, v) continue } if v != stack[len(stack)-1] { stack = append(stack, v) } else { stack = stack[:len(stack)-1] } } return } func func2(a, b []int) (c []int) { mp := make(map[int]int) for _, n := range append(a, b...) { if _, ok := mp[n]; ok { mp[n]++ } else { mp[n] = 1 } } for k, v := range mp { if v%2 != 0 { c = append(c, k) } } return } func func3(a, b []int) (c []int) { t := append(a, b...) sort.Ints(t) for i := 0; i &lt; len(t); i++ { if i != len(t)-1 &amp;&amp; t[i] == t[i+1] { i++ } else { c = append(c, t[i]) } } return } func main() { var a = []int{1, 1, 2, 3, 5, 6, 9, 78, 5} var b = []int{3, 2, 5, 85, 7, 7, 7, 8, 6, 6, 4} fmt.Println(&#34;func1: &#34;, func1(a, b)) c := func2(a, b) fmt.Println(&#34;func2: &#34;, c) sort.Ints(c) fmt.Println(&#34;func2[sort]:&#34;, c) fmt.Println(&#34;func3: &#34;, func3(a, b)) } 运行结果// func1: [4 5 6 7 8 9 78 85] func2: [6 78 85 5 9 7 8 4] func2[sort]: [4 5 6 7 8 9 78 85] func3: [4 5 6 7 8 9 78 85]   ]]></content></entry><entry><title>About Me</title><url>/about.html</url><categories/><tags/><content type="html"> 基本信息 姓名: 宋先志 出生年月: 1996-10 学历: 本科 面试职位: Golang开发 工作年限: 2年 意向城市: 济南 掌握技能 编程语言: Golang、Java Web开发: Vue 、Gin 、Mybatis 数据库管理: MySQL 、Oracle 、Redis 版本控制: Git 、CI/CD [Github Action] 工作经历 银座集团，济南，开发工程师，2020.3-Now
负责公司内部系统的开发和维护。 参与项目需求分析和系统设计，与团队合作推进项目进展。 优化现有代码，提升系统性能，解决关键技术难题。 项目经历 项目名称: [资产管理系统]
项目背景: 集团内部资产数字化管理 项目难点: OA审批流对接 我的价值: OA审批流对接核心代码开发 关于我 我是一名充满热情和创造力的程序员，拥有扎实的编程基础和丰富的软件开发经验。我善于分析问题、解决难题，并且具备出色的团队合作与沟通能力。在项目中，我始终追求技术的卓越与创新，努力在每个阶段都发挥出最大的价值。</content></entry><entry><title>【转】理解MVCC机制</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-11-%E7%90%86%E8%A7%A3mvcc%E6%9C%BA%E5%88%B6/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> 理解MVCC机制的前奏：undo log版本链是个什么东西？ 简单来说呢，我们每条数据其实都有两个隐藏字段，一个是trx_id，一个是roll_pointer，这个trx_id就是最近一次更新这条数据的事务id，roll_pointer就是指向你了你更新这个事务之前生成的undo log
我们给大家举个例子，现在假设有一个事务A（id=50），插入了一条数据，那么此时这条数据的隐藏字段以及指向的undo log如下图所示，插入的这条数据的值是值A，因为事务A的id是50，所以这条数据的txr_id就是50，roll_pointer指向一个空的undo log，因为之前这条数据是没有的。
接着假设有一个事务B跑来修改了一下这条数据，把值改成了值B ，事务B的id是58，那么此时更新之前会生成一个undo log记录之前的值，然后会让roll_pointer指向这个实际的undo log回滚日志，如下图所示。
大家看上图是不是觉得很有意思？事务B修改了值为值B，此时表里的那行数据的值就是值B了，那行数据的txr_id就是事务B的id，也就是58，roll_pointer指向了undo log，这个undo log就记录你更新之前的那条数据的值。
所以大家看到roll_pointer指向的那个undo log，里面的值是值A，txr_id是50，因为undo log里记录的这个值是事务A插入的，所以这个undo log的txr_id就是50，我还特意把表里的那行数据和undo log的颜色弄成不一样的，以示区分。
接着假设事务C又来修改了一下这个值为值C，他的事务id是69，此时会把数据行里的txr_id改成69，然后生成一条undo log，记录之前事务B修改的那个值
我们在上图可以清晰看到，数据行里的值变成了值C，txr_id是事务C的id，也就是69，然后roll_pointer指向了本次修改之前生成的undo log，也就是记录了事务B修改的那个值，包括事务B的id，同时事务B修改的那个undo log还串联了最早事务A插入的那个undo log，如图所示，过程很清晰明了。
所以这就是今天要给大家讲的一点，大家先不管多个事务并发执行是如何执行的，起码先搞清楚一点，就是多个事务串行执行的时候，每个人修改了一行数据，都会更新隐藏字段txr_id …</content></entry><entry><title>【转】SQL标准中对事务的4个隔离级别</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-11-sql%E6%A0%87%E5%87%86%E4%B8%AD%E5%AF%B9%E4%BA%8B%E5%8A%A1%E7%9A%844%E4%B8%AA%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> SQL标准中对事务的4个隔离级别 这4种级别包括了：
**read uncommitted（读未提交）**不允许发生脏写,也就是说，不可能两个事务在没提交的情况下去更新同一行数据的值，但是在这种隔离级别下，可能发生脏读，不可重复读，幻读。
**read committed（读已提交）这个级别下，不会发生脏写和脏读,也就是说，人家事务没提交的情况下修改的值，你是绝对读不到的！但是呢，可能会发生不可重复读和幻读问题，因为一旦人家事务修改了值然后提交了，你事务是会读到的，所以可能你多次读到的值是不同的！有点骚气的简写名词，就是RC，一般如果你在公司里做开发，有个其他团队的兄弟讨论技术方案的时候，跟你来了句，把事务隔离级别设置成RC！这个时候你不要目瞪口呆，知道是读已提交级别就行了。
***repeatable read（可重复读）***这个级别下，不会发生脏写、脏读和不可重复读的问题，因为你一个事务多次查询一个数据的值，哪怕别的事务修改了这个值还提交了，没用，你不会读到人家提交事务修改过的值，你事务一旦开始，多次查询一个值，会一直读到同一个值！RR级别保证你不会读到人家已经提交的事务修改过的值！但是他还是会发生幻读的
**serializable（串行化）**这种级别，根本就不允许你多个事务并发执行，只能串行起来执行，先执行事务A提交，然后执行事务B提交，接着执行事务C提交，所以此时你根本不可能有幻读的问题，因为事务压根儿都不并发执行！
但是这种级别一般除非脑子坏了，否则更不可能设置了，因为多个事务串行，那数据库很可能一秒并发就只有几十了，性能会极差的。
MySQL是如何支持4种事务隔离级别的？Spring事务注解是如何设置的？ MySQL默认设置的事务隔离级别，都是RR级别的，而且MySQL的RR级别是可以避免幻读发生的。
这点是MySQL的RR级别的语义跟SQL标准的RR级别不同的，毕竟SQL标准里规定RR级别是可以发生幻读的，但是MySQL的RR级别避免了！
也就是说，MySQL里执行的事务，默认情况下不会发生脏写、脏读、不可重复读和幻读的问题，事务的执行都是并行的，大家互相不会影响，我不会读到你没提交事务修改的值，即使你修改了值还提交了，我也不会读到的，即使你插入了一行值还提交了，我也不会读到的，总之，事务之间互相都完全不影响！
当然，要做到这么神奇和牛叉的效 …</content></entry><entry><title>【转】什么是脏写、脏读、不可重复读和幻读？</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-10-%E4%BB%80%E4%B9%88%E6%98%AF%E8%84%8F%E5%86%99%E8%84%8F%E8%AF%BB%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB%E5%92%8C%E5%B9%BB%E8%AF%BB/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> 多个事务并发执行时候的另外两种问题：一个是不可重复读，一个是幻读 多个事务并发执行时候，对MySQL的缓存页里的同一行数据同时进行更新或者查询的时候，可能发生的脏写和脏读的问题
先来说说这个不可重复读的问题，这个问题是这样的：假设我们有一个事务A开启了，在这个事务A里会多次对一条数据进行查询
然后呢，另外有两个事务，一个是事务B，一个是事务C，他们俩都是对一条数据进行更新的。
然后我们假设一个前提，就是比如说事务B更新数据之后，如果还没提交，那么事务A是读不到的，必须要事务B提交之后，他修改的值才能被事务A给读取到，其实这种情况下，就是我们首先避免了脏读的发生。
因为脏读的意思就是事务A可以读到事务B修改过还没提交的数据，此时事务B一旦回滚，事务A再次读就读不到了，那么此时就会发生脏读问题。
我们现在假设的前提是事务A只能在事务B提交之后读取到他修改的数据，所以此时必然是不会发生脏读的
好了，但是你以为没有脏读就万事大吉了吗？绝对不是，此时会有另外一个问题，叫做不可重复读
假设缓存页里一条数据原来的值是A值，此时事务A开启之后，第一次查询这条数据，读取到的就是A值。
接着事务B更新了那行数据的值为B值，同时事务B立马提交了，然后事务A此时可是还没提交！
大家注意，此时事务A是没提交的，他在事务执行期间第二次查询数据，此时查到的是事务B修改过的值，B值，因为事务B已经提交了，所以事务A可以读到的了，
紧接着事务C再次更新数据为C值，并且提交事务了，此时事务A在没提交的情况下，第三次查询数据，查到的值为C值，
好，那么上面的场景有什么问题呢？
其实要说没问题也可以是没问题，毕竟事务B和事务C都提交之后，事务A多次查询查到他们修改的值，是ok的。
但是你要说有问题，也可以是有问题的，就是事务A可能第一次查询到的是A值，那么他可能希望的是在事务执行期间，如果多次查询数据，都是同样的一个A值，他希望这个A值是他重复读取的时候一直可以读到的！他希望这行数据的值是可重复读的！
但是此时，明显A值不是可重复读的，因为事务B和事务C一旦更新了值并且提交了，事务A会读到别的值，所以此时这行数据的值是不可重复读的！此时对于你来说，这个不可重复读的场景，就是一种问题了！
上面描述的，其实就是不可重复读的问题，其实这个问题你说是问题也不一定就是什么大问题，但是说他有问题，确实是有问题的。
因 …</content></entry><entry><title>【转】重新回顾redo日志对于事务提交后，数据绝对不会丢失的意义 1</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-%E9%87%8D%E6%96%B0%E5%9B%9E%E9%A1%BEredo%E6%97%A5%E5%BF%97%E5%AF%B9%E4%BA%8E%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4%E5%90%8E%E6%95%B0%E6%8D%AE%E7%BB%9D%E5%AF%B9%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1%E7%9A%84%E6%84%8F%E4%B9%89-1/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> 在更新完Buffer Pool中的缓存页之后，必须要写一条redo log，这样才能记录下来我们对数据库做的修改。 redo log可以保证我们事务提交之后，如果事务中的增删改SQL语句更新的缓存页还没刷到磁盘上去，此时MySQL宕机了，那么MySQL重启过后，就可以把redo log重做一遍，恢复出来事务当时更新的缓存页，然后再把缓存页刷到磁盘就可以了
redo log本质是保证事务提交之后，修改的数据绝对不会丢失。
所以接下来一段时间我们会深入研究redo log的底层实现原理，今天就承上启下，简单回顾一下redo log这个机制存在的意义。
首先我们都知道，执行增删改SQL语句的时候，都是针对一个表中的某些数据去执行的，此时的话，首先必须找到这个表对应的表空间，然后找到表空间对应的磁盘文件，接着从磁盘文件里把你要更新的那批数据所在的数据页从磁盘读取出来，放到Buffer Pool的缓存页里去 接着实际上你的增删改SQL语句就会针对Buffer Pool中的缓存页去执行你的更新逻辑，比如插入一行数据，或者更新一行数据，或者是删除一行数据。 那么学习过之前的Buffer Pool底层原理之后都知道，其实你更新缓存页的时候，会更新free链表、flush链表、lru链表，然后有专门的后台IO线程，不定时的根据flush链表、lru链表，会把你更新过的缓存页刷新回磁盘文件的数据页里去 所以大家都知道这个机制里最大的漏洞就在于，万一你一个事务里有增删改SQL更新了缓存页，然后事务提交了，结果万一你还没来得及让IO线程把缓存页刷新到磁盘文件里，此时MySQL宕机了，然后内存数据丢失，你事务更新的数据就丢失了！ 但是也不可能每次你事务一提交，就把你事务更新的缓存页都刷新回磁盘文件里去，因为大家之前也都知道，缓存页刷新到磁盘文件里，是随机磁盘读写，性能是相当的差！这会导致你数据库性能和并发能力都很弱的！
所以此时才会引入一个redo log机制，这个机制就是说，你提交事务的时候，绝对是保证把你对缓存页做的修改以日志的形式，写入到redo log日志文件里去的
这种日志大致的格式如下：对表空间XX中的数据页XX中的偏移量为XXXX的地方更新了数据XXX
只要你事务提交的时候保证你做的修改以日志形式写入redo log日志，那么哪怕你此时突然宕机了，也没关系！
因为你MySQL重 …</content></entry><entry><title>【转】重新回顾redo日志对于事务提交后，数据绝对不会丢失的意义 2</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-%E9%87%8D%E6%96%B0%E5%9B%9E%E9%A1%BEredo%E6%97%A5%E5%BF%97%E5%AF%B9%E4%BA%8E%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4%E5%90%8E%E6%95%B0%E6%8D%AE%E7%BB%9D%E5%AF%B9%E4%B8%8D%E4%BC%9A%E4%B8%A2%E5%A4%B1%E7%9A%84%E6%84%8F%E4%B9%89-2/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> 如果事务执行到一半要回滚怎么办？再探undo log回滚日志原理！ redo log都是先进入redo log buffer中的一个block，然后事务提交的时候就会刷入磁盘文件里去。
这样万一要是你提交事务了，结果事务修改的缓存页还没来得及刷入磁盘上的数据文件，此时你MySQL关闭了或者是宕机了，那么buffer pool里被事务修改过的数据就全部都丢失了！
但是只要有redo log，你重启MySQL之后完全是可以把那些修改了缓存页，但是缓存页还没来得及刷入磁盘的事务，他们所对应的redo log都加载出来，在buffer pool的缓存页里重做一遍，就可以保证事务提交之后，修改的数据绝对不会丢！
相信之前讲解了redo log日志之后，大家对这块都理解的更加深刻了，那么今天我们就带着大家来探索另外一种日志，就是undo log日志，也就是回滚日志，这种日志要应对的场景，就是事务回滚的场景！
那么首先大家先思考一个问题，假设现在我们一个事务里要执行一些增删改的操作，那么必然是先把对应的数据页从磁盘加载出来放buffer pool的缓存页里，然后在缓存页里执行一通增删改，同时记录redo log日志
但是现在问题来了，万一要是一个事务里的一通增删改操作执行到了一半，结果就回滚事务了呢？
比如一个事务里有4个增删改操作，结果目前为止已经执行了2个增删改SQL了，已经更新了一些buffer pool里的数据了，但是还有2个增删改SQL的逻辑还没执行，此时事务要回滚了怎么办？
这个时候就很尴尬了，如果你要回滚事务的话，那么必须要把已经在buffer pool的缓存页里执行的增删改操作给回滚了
但是怎么回滚呢？毕竟无论是插入，还是更新，还是删除，该做的都已经做了啊！
所以在执行事务的时候，才必须引入另外一种日志，就是undo log回滚日志
这个回滚日志，他记录的东西其实非常简单，比如你要是在缓存页里执行了一个insert语句，那么此时你在undo log日志里，对这个操作记录的回滚日志就必须是有一个主键和一个对应的delete操作，要能让你把这次insert操作给回退了。
那么比如说你要是执行的是delete语句，那么起码你要把你删除的那条数据记录下来，如果要回滚，就应该执行一个insert操作把那条数据插入回去。
如果你要是执行的是update语句，那么起码你要把你更 …</content></entry><entry><title>【转】如何解决经典的Too many connections故障？背后原理是什么</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-%E5%A6%82%E4%BD%95%E8%A7%A3%E5%86%B3%E7%BB%8F%E5%85%B8%E7%9A%84too-many-connections%E6%95%85%E9%9A%9C%E8%83%8C%E5%90%8E%E5%8E%9F%E7%90%86%E6%98%AF%E4%BB%80%E4%B9%88/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> 其实核心就是一行命令：
ulimit -HSn 65535
然后就可以用如下命令检查最大文件句柄数是否被修改了
cat /etc/security/limits.conf 如果都修改好之后，可以在MySQL的my.cnf里确保max_connections参数也调整好了，然后可以重启服务器，然后重启MySQL，这样的话，linux的最大文件句柄就会生效了，MySQL的最大连接数也会生效了。
设置之后，我们要确保变更落地到/etc/security/limits.conf文件里，永久性的设置进程的资源限制
所以执行ulimit -HSn 65535命令后，要用如下命令检查一下是否落地到配置文件里去了。
cat /etc/security/limits.conf</content></entry><entry><title>【转】一个真实的生产优化案例</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-%E4%B8%80%E4%B8%AA%E7%9C%9F%E5%AE%9E%E7%9A%84%E7%94%9F%E4%BA%A7%E4%BC%98%E5%8C%96%E6%A1%88%E4%BE%8B/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> MySQL数据库的日志顺序读写以及数据文件随机读写的原理 先给大家剖析一下MySQL在实际工作时候的两种数据读写机制，一种是对redo log、binlog这种日志进行的磁盘顺序读写，一种是对表空间的磁盘文件里的数据页进行的磁盘随机读写。 简单来说，MySQL在工作的时候，尤其是执行增删改操作的时候，肯定会先从表空间的磁盘文件里读取数据页出来，这个过程其实就是典型的磁盘随机读操作
我们先看下面的图，图里有一个磁盘文件的示意，里面有很多数据页，然后你可能需要在一个随机的位置读取一个数据页到缓存，这就是磁盘随机读
因为你要读取的这个数据页可能在磁盘的任意一个位置，所以你在读取磁盘里的数据页的时候只能是用随机读的这种方式。
磁盘随机读的性能是比较差的，所以不可能每次更新数据都进行磁盘随机读，必须是读取一个数据页之后放到Buffer Pool的缓存里去，下次要更新的时候直接更新Buffer Pool里的缓存页。
对于磁盘随机读来说，主要关注的性能指标是IOPS和响应延迟
IOPS就是底层的存储系统每秒可以执行多少次磁盘读写操作，比如你底层磁盘支持每秒执行1000个磁盘随机读写操作和每秒执行200个磁盘随机读写操作，对你的数据库的性能影响其实是非常大的。
这个指标实际上对数据库的crud操作的QPS影响是非常大的，因为他在某种程度上几乎决定了你每秒能执行多少个SQL语句，底层存储的IOPS越高，数据库的并发能力就越高。
另外一个就是磁盘随机读写操作的响应延迟，也是对数据库的性能有很大的影响。因为假设底层磁盘支持每秒执行200个随机读写操作，但是每个操作是耗费10ms完成呢，还是耗费1ms完成呢，这个其实也是有很大的影响的，决定了对数据库执行的单个crud SQL语句的性能。
比如一个SQL语句发送过去，他磁盘要执行随机读操作加载多个数据页，此时每个磁盘随机读响应时间是50ms，那么此时可能你的SQL语句要执行几百ms，但是如果每个磁盘随机读仅仅耗费10ms，可能SQL就执行100ms就行了。
所以其实一般对于核心业务的数据库的生产环境机器规划，我们都是推荐用SSD固态硬盘的，而不是机械硬盘，因为SSD固态硬盘的随机读写并发能力和响应延迟要比机械硬盘好的多，可以大幅度提升数据库的QPS和性能。
接着我们来看磁盘顺序读写，之前我们都知道，当你在Buffer Pool的缓存页里更新 …</content></entry><entry><title>【转】MySQL物理数据模型2</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-mysql%E7%89%A9%E7%90%86%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B2/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> 磁盘上的一行数据到底如何读取出来的？ 我们结合上面的磁盘上的数据存储格式来思考一下，一行数据到底是如何读取出来的呢？
再看上面的磁盘数据存储格式：
0x09 0x04 00000101 头信息 column1=value1 column2=value2 &amp;amp;hellip; columnN=valueN
首先他必然要把变长字段长度列表和NULL值列表读取出来，通过综合分析一下，就知道有几个变长字段，哪几个变长字段是NULL，因为NULL值列表里谁是NULL谁不是NULL都一清二楚。
此时就可以从变长字段长度列表中解析出来不为NULL的变长字段的值长度，然后也知道哪几个字段是NULL的，此时根据这些信息，就可以从实际的列值存储区域里，把你每个字段的值读取出来了。
如果是变长字段的值，就按照他的值长度来读取，如果是NULL，就知道他是个NULL，没有值存储，如果是定长字段，就按照定长长度来读取，这样就可以完美的把你一行数据的值都读取出来了！
磁盘文件中， 40个bit位的数据头以及真实数据是如何存储的？ 之前我们已经给大家讲到了在磁盘上存储数据的时候，每一行数据都会有变长字段长度列表，逆序存放这行数据里的变长字段的长度，然后会有NULL值列表，对于允许为NULL的字段都会有一个bit位标识那个字段是否为NULL，也是逆序排列的。
今天我们接着给大家讲每一行数据存储的时候，还得有40个bit位的数据头，这个数据头是用来描述这行数据的。
这40个bit位里，第一个bit位和第二个bit位，都是预留位，是没任何含义的。
然后接下来有一个bit位是delete_mask，他标识的是这行数据是否被删除了，其实看到这个bit位，很多人可能已经反映过来了，这么说在MySQL里删除一行数据的时候，未必是立马把他从磁盘上清理掉，而是给他在数据头里搞1个bit标记他已经被删了？
没错，其实大家现在看这些数据头，只要先留有一个印象就可以了，知道每一行数据都有一些数据头，不同的数据头都是用来描述这行数据的一些状态和附加信息的。
然后下一个bit位是min_rec_mask，这个bit位大家现在先不用去关注，他的含义以后我们讲到对应的内容的时候再说，他其实就是说在B+树里每一层的非叶子节点里的最小值都有这个标记。
接下来有4个bit位是n_owned，这个暂时我们也先不用去管他，他其实就是记录了一个 …</content></entry><entry><title>【转】MySQL物理数据模型</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-05-09-mysql%E7%89%A9%E7%90%86%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B1/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> 为什么不能直接更新磁盘上的数据？ 因为来一个请求就直接对磁盘文件进行随机读写，然后更新磁盘文件里的数据，虽然技术上是可以做到的，但是那必然导致执行请求的性能极差。 因为磁盘随机读写的性能是最差的，所以直接更新磁盘文件，必然导致我们的数据库完全无法抗下任何一点点稍微高并发一点的场景。
所以MySQL才设计了如此复杂的一套机制，通过内存里更新数据，然后写redo log以及事务提交，后台线程不定时刷新内存里的数据到磁盘文件里。 通过这种方式保证，你每个更新请求，尽量就是更新内存，然后顺序写日志文件。 更新内存的性能是极高的，然后顺序写磁盘上的日志文件的性能也是比较高的，因为顺序写磁盘文件，他的性能要远高于随机读写磁盘文件。 也正是通过这套机制，才能让我们的MySQL数据库在较高配置的机器上，每秒可以抗下几千的读写请求。
MySQL为什么要引入数据页这个概念？ 当我们要执行update之类的SQL语句的时候，并不是直接去更新磁盘文件，而是要把磁盘上的一些数据加载到内存里来，然后对内存里的数据进行更新，同时写redo log到磁盘上去。 但是这里就有一个问题了，难道我们每次都是把磁盘里的一条数据加载到内存里去进行更新，然后下次要更新别的数据的时候，再从磁盘里加载另外一条数据到内存里去？ 这样每次都是一条数据一条数据的加载到内存里去更新，很明显是效率不高的 所以innodb存储引擎在这里引入了一个数据页的概念，也就是把数据组织成一页一页的概念，每一页有16kb，然后每次加载磁盘的数据到内存里的时候，是至少加载一页数据进去，甚至是多页数据进去 假设我们有一次要更新一条id=1的数据： update xxx set xxx=xxx where id=1 那么此时他会把id=1这条数据所在的一页数据都加载到内存里去，这一页数据里，可能还包含了id=2，id=3等其他数据。 然后我们更新完id=1的数据之后，接着更新id=2的数据，那么此时是不是就不用再次读取磁盘里的数据了？ 因为id=2本身就跟id=1在一页里，之前这一页数据就加载到内存里去了，你直接更新内存里的数据页中的id=2这条数据就可以了。 我们看下图，这就是数据页的意义，磁盘和内存之间的数据交换通过数据页来执行，包括内存里更新后的脏数据，刷回磁盘的时候，也是至少一个数据页刷回去。 当IO线程把内存里的脏数据刷到磁盘上去的 …</content></entry><entry><title>【转】LRU算法优化和性能优化</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-04-18-lru%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96%E5%92%8C%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> MYSQL的预读机制 MySQL设计了一个预读机制，要把相邻的一些数据页一次性读入到Buffer Pool缓存里去
假设你读取了数据页01到缓存页里去，那么好，接下来有可能会接着顺序读取数据页01相邻的数据页02到缓存页里去，这个时候，是不是可能在读取数据页02的时候要再次发起一次磁盘IO？
所以为了优化性能，MySQL才设计了预读机制，也就是说如果在一个区内，你顺序读取了好多数据页了，比如数据页01~数据页56都被你依次顺序读取了，MySQL会判断，你可能接着会继续顺序读取后面的数据页。
那么此时他就干脆提前把后续的一大堆数据页（比如数据页57~数据页72）都读取到Buffer Pool里去，那么后续你再读取数据页60的时候，是不是就可以直接从Buffer Pool里拿到数据了？
当然理想是上述那样，很丰满，但是现实可能很骨感。你预读的一大堆数据页要是占据了LRU链表的前面部分，可能这些预读的数据页压根儿后续没人会使用，那你这个预读机制就是在捣乱了。
基于冷热数据分离的思想设计LRU链表 所以为了解决上一讲我们说的简单的LRU链表的问题，真正MySQL在设计LRU链表的时候，采取的实际上是冷热数据分离的思想。
所以真正的LRU链表，会被拆分为两个部分，一部分是热数据，一部分是冷数据，这个冷热数据的比例是由innodb_old_blocks_pct参数控制的，他默认是37，也就是说冷数据占比37%。
而且数据页第一次被加载到缓存的时候，缓存页会被放在冷数据区域的链表头部
冷数据区域的缓存页什么时候会被放入到热数据区域？ 冷数据区域的缓存页肯定是会被使用的，那么冷数据区域的缓存页什么时候会放到热数据区域呢？
MySQL设定了一个规则，他设计了一个innodb_old_blocks_time参数，默认值1000，也就是1000毫秒。
也就是说，必须是一个数据页被加载到缓存页之后，在1s之后，你访问这个缓存页，他才会被挪动到热数据区域的链表头部去。
因为假设你加载了一个数据页到缓存去，然后过了1s之后你还访问了这个缓存页，说明你后续很可能会经常要访问它，这个时间限制就是1s，因此只有1s后你访问了这个缓存页，他才会给你把缓存页放到热数据区域的链表头部去。
在这样的一个LRU链表方案下，预读机制以及全表扫描加载进来的一大堆缓存页是放在LRU链表的冷数据区域的前面
预读机制和 …</content></entry><entry><title>【转】Buffer Pool的内存数据结构</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-04-18-buffer-pool%E7%9A%84%E5%86%85%E5%AD%98%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html"> Buffer Pool Buffer Pool本质其实就是数据库的一个内存组件，可以理解为他就是一片内存数据结构. Buffer Pool默认情况下是128MB
比如我们的数据库如果是16核32G的机器，那么你就可以给Buffer Pool分配个2GB的内存
[server] innodb_buffer_pool_size = 2147483648 数据页 数据页：MySQL中抽象出来的数据单位 接着我们要了解下一个概念，对于每个缓存页，他实际上都会有一个描述信息，这个描述信息大体可以认为是用来描述这个缓存页的
比如包含如下的一些东西：这个数据页所属的表空间、数据页的编号、这个缓存页在Buffer Pool中的地址以及别的一些杂七杂八的东西。
每个缓存页都会对应一个描述信息，这个描述信息本身也是一块数据，在Buffer Pool中，每个缓存页的描述数据放在最前面，然后各个缓存页放在后面
所以此时我们看下面的图，Buffer Pool实际看起来大概长这个样子。
而且这里我们要注意一点，Buffer Pool中的描述数据大概相当于缓存页大小的5%左右，也就是每个描述数据大概是800个字节左右的大小，然后假设你设置的buffer pool大小是128MB，实际上Buffer Pool真正的最终大小会超出一些，可能有个130多MB的样子，因为他里面还要存放每个缓存页的描述数据。
Buffer Pool的初始化 数据库只要一启动，就会按照你设置的Buffer Pool大小，稍微再加大一点，去找操作系统申请一块内存区域，作为Buffer Pool的内存区域。
然后当内存区域申请完毕之后，数据库就会按照默认的缓存页的16KB的大小以及对应的800个字节左右的描述数据的大小，在Buffer Pool中划分出来一个一个的缓存页和一个一个的他们对应的描述数据。
然后当数据库把Buffer Pool划分完毕之后，看起来就是之前我们看到的那张图。
只不过这个时候，Buffer Pool中的一个一个的缓存页都是空的，里面什么都没有，要等数据库运行起来之后，当我们要对数据执行增删改查的操作的时候，才会把数据对应的页从磁盘文件里读取出来，放入Buffer Pool中的缓存页中。
怎么知道哪些缓存页是空闲的呢？ 数据库会为Buffer Pool设计一个free链表，他是一个双向链表数据结构，这 …</content></entry><entry><title>【转】InnoDB引擎更新数据过程</title><url>/posts/mysql%E7%AC%94%E8%AE%B0/2022-04-13-innodb%E5%BC%95%E6%93%8E%E6%9B%B4%E6%96%B0%E6%95%B0%E6%8D%AE%E8%BF%87%E7%A8%8B/</url><categories><category>mysql笔记</category></categories><tags><tag>mysql</tag></tags><content type="html">
SQL语句执行阶段 1.缓冲池（Buffer Pool）中查找记录，若找不到就去磁盘中查找然后加载到缓冲池
2.写undo日志文件 便于回滚
3.更新Buffer Pool中的数据（更新后Buffer Pool中的数据为脏数据）
4.Redo Log Buffer中写入修改日志
innodb_flush_log_at_trx_commit的值对应的情况: 0：提交事务的时候，不会把redo log buffer里的数据刷入磁盘文件 1：提交事务的时候，就必须把redo log从内存刷入到磁盘文件里去 2：提交事务的时候，把redo日志写入磁盘文件对应的os cache缓存里去，而不是直接进入磁盘文件，可能1秒后才会把os cache里的数据写入到磁盘文件里去 事务提交阶段 &amp;amp;gt; MySQL binlog是什么？和Redo Log 的区别？ &amp;amp;gt; redo log，他是一种偏向物理性质的重做日志，因为他里面记录的是类似这样的东西，“对哪个数据页中的什么记录，做了个什么修改”。 binlog叫做归档日志，他里面记录的是偏向于逻辑性的日志，类似于“对users表中的id=10的一行数据做了更新操作，更新以后的值是什么” 5.准备提交事务，将redo log buffer里的数据刷入磁盘文件 6.准备提交事务，将binlog日志写入磁盘文件中去
sync_binlog参数可以控制binlog的刷盘策略 0：把binlog日志写入磁盘文件对应的os cache缓存里去，而不是直接进入磁盘文件 1：把binlog日志进入磁盘文件 7:完成最终的事务提交
此时会把本次更新对应的binlog文件名称和这次更新的binlog日志在文件里的位置，都写入到redo log日志文件里去，同时在redo log日志文件里写入一个commit标记。
最后一步在redo日志中写入commit标记的意义是什么？ 是用来保持redo log日志与binlog日志一致的。 我们来举个例子，假设我们在提交事务的时候，一共有上图中的5、6、7三个步骤，必须是三个步骤都执行完毕，才算是提交了事务。那么在我们刚完成步骤5的时候，也就是redo log刚刷入磁盘文件的时候，mysql宕机了，此时怎么办？ 这个时候因为没有最终的事务commit标记在redo日志里，所以此次事务可以判定为不成功。不会 …</content></entry><entry><title>使用ProGuard混淆你的JAVA代码</title><url>/posts/java/2020-06-14-%E5%9C%A8maven%E9%A1%B9%E7%9B%AE%E4%B8%AD%E4%BD%BF%E7%94%A8proguard%E6%B7%B7%E6%B7%86%E4%BD%A0%E7%9A%84java%E4%BB%A3%E7%A0%81/</url><categories><category>Java</category></categories><tags><tag>Java</tag></tags><content type="html"><![CDATA[  在Maven项目中使用Proguard十分简单 只要在pom文件的标签内添加如下代码即可
&lt;!-- ProGuard混淆插件--&gt; &lt;plugin&gt; &lt;groupId&gt;com.github.wvengen&lt;/groupId&gt; &lt;artifactId&gt;proguard-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;!-- 混淆时刻，这里是打包的时候混淆--&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;!-- 使用插件的什么功能，当然是混淆--&gt; &lt;goal&gt;proguard&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;!-- 是否将生成的PG文件安装部署--&gt; &lt;attach&gt;true&lt;/attach&gt; &lt;!-- 是否混淆--&gt; &lt;obfuscate&gt;true&lt;/obfuscate&gt; &lt;!-- 指定生成文件分类 --&gt; &lt;attachArtifactClassifier&gt;pg&lt;/attachArtifactClassifier&gt; &lt;options&gt; &lt;!-- JDK目标版本1.8--&gt; &lt;option&gt;-target 1.8&lt;/option&gt; &lt;!-- 不做收缩（删除注释、未被引用代码）--&gt; &lt;option&gt;-dontshrink&lt;/option&gt; &lt;!-- 不做优化（变更代码实现逻辑）--&gt; &lt;option&gt;-dontoptimize&lt;/option&gt; &lt;!-- 不路过非公用类文件及成员--&gt; &lt;option&gt;-dontskipnonpubliclibraryclasses&lt;/option&gt; &lt;option&gt;-dontskipnonpubliclibraryclassmembers&lt;/option&gt; &lt;!--不用大小写混合类名机制--&gt; &lt;option&gt;-dontusemixedcaseclassnames&lt;/option&gt; &lt;!-- 优化时允许访问并修改有修饰符的类和类的成员 --&gt; &lt;option&gt;-allowaccessmodification&lt;/option&gt; &lt;!-- 确定统一的混淆类的成员名称来增加混淆--&gt; &lt;option&gt;-useuniqueclassmembernames&lt;/option&gt; &lt;!-- 不混淆所有包名--&gt; &lt;option&gt;-keeppackagenames&lt;/option&gt; &lt;!-- 需要保持的属性：异常，注解等--&gt; &lt;option&gt;-keepattributes Exceptions,InnerClasses,Signature,Deprecated,SourceFile,*Annotation*,Synthetic,EnclosingMethod&lt;/option&gt; &lt;!-- 不混淆所有的set/get方法 --&gt; &lt;option&gt;-keepclassmembers public class * {void set*(***);*** get*();}&lt;/option&gt; &lt;!-- 不混淆所有的services.dao.ChargeDAO类内的所有方法方法 --&gt; &lt;option&gt;-keep class services.dao.ChargeDAO { *; }&lt;/option&gt; &lt;/options&gt; &lt;!--class 混淆后输出的jar包--&gt; &lt;outjar&gt;hx.jar&lt;/outjar&gt; &lt;!-- 添加依赖，这里你可以按你的需要修改，这里测试只需要一个JRE的Runtime包就行了 --&gt; &lt;libs&gt; &lt;lib&gt;${java.home}/lib/rt.jar&lt;/lib&gt; &lt;lib&gt;${java.home}/lib/jce.jar&lt;/lib&gt; &lt;/libs&gt; &lt;!-- 对什么东西进行加载，这里仅有classes成功，毕竟你也不可能对配置文件及JSP混淆吧--&gt; &lt;injar&gt;classes&lt;/injar&gt; &lt;!-- 输出目录--&gt; &lt;outputDirectory&gt;${project.build.directory}&lt;/outputDirectory&gt; &lt;/configuration&gt; &lt;/plugin&gt;   ]]></content></entry><entry><title>Hexo博客之Valine评论系统及邮件通知插件</title><url>/posts/blog/2020-02-22-hexo%E5%8D%9A%E5%AE%A2%E4%B9%8Bvaline%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F%E5%8F%8A%E9%82%AE%E4%BB%B6%E9%80%9A%E7%9F%A5%E6%8F%92%E4%BB%B6/</url><categories><category>blog</category></categories><tags><tag>blog</tag></tags><content type="html"> 在之前的文章中曾经提到过Valine的评论系统，今天来系统的介绍一下使用方法和添加邮件提醒功能。 首先要感谢 Valine 开发好用的项目和DesertsP开发的 Valine-Admin 插件。
启用Valine评论系统 1.注册 LeanCloud 2.进入控制台创建应用 3.点击应用-设置-安全中心-Web安全域名，填入你的域名 4.点击应用-设置-应用Keys找到AppID、AppKey 5.找到hexo目录内主题文件夹（每个人都不同，我的是next）的_config.yml文件找到Valine，大概在633行附近，修改对应值 6.hexo三连就可以在文章页面看到评论系统了。
启用启用Valine评论系统 原作者的教程很详细了，这里就不简单搬运了，记录一下我遇到的一下小问题吧。 这是链接 1.提前弄明白邮箱的STMP 2.设置好变量后部署，修改变量后要重启实例才可以</content></entry><entry><title>Mac、PC常用软件分享</title><url>/posts/%E6%8A%80%E5%B7%A7/2019-12-23-macpc%E5%B8%B8%E7%94%A8%E8%BD%AF%E4%BB%B6%E5%88%86%E4%BA%AB/</url><categories><category>技巧</category></categories><tags><tag>常用软件</tag></tags><content type="html"> 记录在PC和Mac平台下常用的软件自己常用的几款软件
Mac Beyong Compare | 文件及目录对比工具 PicGo | 图床软件 NotepadNext | Notepad++ 替代品 INNA | 视频播放器 Motrix | 配合油猴实现哔哩哔哩视频下载 Inspect | 键盘测试和屏幕测试工具 Kap | 屏幕录制工具 PasteNow 或者 Paste | 剪切板工具 Keka | zip、rar打包解压工具 Parallels Desktop | 虚拟机工具 Mos | mac鼠标优化工具 Github 主页 fliqlo | 时钟屏保工具 官网地址 MenubarX | 状态栏浏览器,方便使用chatgpt。配合快捷键可摸鱼！ 官网地址 PC 录屏软件 | Captura Github 主页 音乐软件 | Listen1 Github 主页 磁盘分区 | DiskGenius5.0 磁盘清理工具 | CCleaner_Pro 电脑文件图形化 | SpaceSniffer 解压缩软件 | winrar 文件批量改名王1.3 图标提取 | BeCyIconGrabber Xshell and WinSCP win10优化工具-Dism++ 官网链接 下载工具 | IDM</content></entry><entry><title>Python笔记之模拟键盘鼠标操作</title><url>/posts/python/2019-12-04-python%E7%AC%94%E8%AE%B0%E4%B9%8B%E6%A8%A1%E6%8B%9F%E9%94%AE%E7%9B%98%E9%BC%A0%E6%A0%87%E6%93%8D%E4%BD%9C/</url><categories><category>python</category></categories><tags><tag>python</tag></tags><content type="html"> 前言：因为手上有两张电话卡，一张是接收验证码用的，而短信转发用的软件是mysms，不巧的是这款软件在ios端无法批量删除短信，好在可以在PC上的web页面处理，可惜仍无法批量操作，所以就有了下面这个简单的小脚本 程序内容：
from pykeyboard import * from pymouse import * import time m=PyMouse() k=PyKeyboard() for i in range(50): m.click(254,642,2) time.sleep(1) m.click(304,728,1) time.sleep(1) k.tap_key(k.enter_key) time.sleep(4) 很简单的一段程序，但是可以批量的完成一些重复的工作。
脚本使用前提 安装pyhook https://www.lfd.uci.edu/~gohlke/pythonlibs/ 根据Python版本下载对于的whl文件 pyHook‑1.5.1‑cp37‑cp37m‑win_amd64.whl pip install pyHook‑1.5.1‑cp37‑cp37m‑win_amd64.whl
安装pyuserinput pip install pyuserinput
一些方法介绍（搬运） 鼠标操作： m.click(x,y,button,n) 鼠标点击 x,y 是坐标位置 buttong 1表示左键，2表示点击右键 n 点击次数，默认是1次，2表示双击
m.move(x,y) –鼠标移动到坐标(x,y) 坐标可以通过QQ截图获取，在左上角开始点击，然后移动到需要点击位置就可以获取了 x_dim, y_dim = m.screen_size() –获得屏幕尺寸
键盘操作： k.type_string(‘Hello, World!’) –模拟键盘输入字符串 k.press_key(‘H’) –模拟键盘按H键 k.release_key(‘H’) –模拟键盘松开H键 k.tap_key(“H”) –模拟点击H键 k.tap_key(‘H’,n=2,interval=5) –模拟点击H键，2次，每次间隔5秒 k.tap_key(k.function_keys[5]) –点击功能键F5 k.tap_key(k.numpad_keys[5],3) –点击小键盘5,3次
联合按键模拟 例如同时按alt+tab键盘 k.press_key(k.alt_key) –按住alt键 k.tap_key(k.tab_key) –点击tab键 k.release_key(k.alt_key) –松开alt键</content></entry><entry><title>华硕ZX50JX4200黑苹果DSDT/SSDT修补总结(持续更新)</title><url>/posts/hackintosh/2019-10-19-%E9%BB%91%E8%8B%B9%E6%9E%9C%E4%B9%8B%E5%8D%8E%E7%A1%95zx50jx4200%E9%BB%91%E8%8B%B9%E6%9E%9Cdsdt-ssdt%E4%BF%AE%E8%A1%A5%E6%80%BB%E7%BB%93/</url><categories><category>hackintosh</category></categories><tags><tag>DSDT</tag><tag>hackintosh</tag></tags><content type="html"><![CDATA[  提取 建议制作Ubuntu的U盘启动提取
反编译 使用iasl 联合反编译 将提取的原始 dsdt和ssdt文件重命名为xxx.aml（xxx为原始文件名）
一键改名命令 for i in *;do mv &quot;$i&quot; &quot;$i.aml&quot;;done
反编译命令 iasl -da -dl *.aml 删除所有aml文件，只保留dsl文件 rm *.aml
改错 不同设备或不同版本的bios可能提取的到文件反编译后错误不同，这里只总结了我遇到的错误
dsdt文件错误修复 1.PARSEOP_ZERO错误 使用Rehubman补丁源的“Fix PARSEOP_ZERO Error” 2.提示‘}&lsquo;错误 删除对应行的行Arg0 然后就没有错误了 但提示警告，不用理会
SSDT2错误修复 package (0x06) { 0x80000000, 0x80000000, 0x80000000, 0x80000000, 0x80000000, 0x80000000 } 这种错误使用派奇的补丁源的”SSDT_Package(){0x80000000}_Eror_Fix“修复 补丁地址
派奇 http://raw.github.com/Yuki-Judai/dxxs-DSDT-Patch/master SSDT3错误修复 cpupm变频文件 删除该dsl 使用脚本生成并代替该文件 脚本GitHub地址 https://github.com/Piker-Alpha/ssdtPRGen.sh SSDT9错误修复 PARSEOP_NAMESEG错误 使用[gfx0]Cleanup/Fix Errors(SSDT)修复
打补丁 除补充说明外，默认补丁源在RehubMan的笔记本补丁源
改名补丁(理论上需要所有的文件都要改名) 1.GFX0-&gt;IGPU 需要的文件（DSDT、SSDT5、SSDT6、SSDT9） 2.B0D3-&gt;HDAU 需要的文件（SSDT、SSDT5) 3._DSM-&gt;XDSM
显卡补丁 位于ssdt5 “[igpu]Haswell HD4400/HD4600/HD5000“
DSDT通用补丁 1.屏蔽独显 Disable fromm _REG(DSDT) Disable/Enable on _WAK/_PTS(DSDT)
2.修复睡眠 [sys]Fix _WAK Arg0 v2 [sys]Fix _WAK IAOE
3.电源管理 [sys]Haswell LPC
4.电量修复 [sys]Fix Mutex with non-zero Synclevel 派奇： [bat]ASUS N550/N551(JX JV)
5.USB内建 [usb]7-series/8-series USB
6.键盘灯(快捷键) 点击这里的 链接 7.其他修复 HPET fix IRQ fix RTC fix
  ]]></content></entry><entry><title>黑苹果之华硕笔记本键盘灯和Fn快捷键</title><url>/posts/hackintosh/2019-10-18-%E9%BB%91%E8%8B%B9%E6%9E%9C%E4%B9%8B%E5%8D%8E%E7%A1%95%E7%AC%94%E8%AE%B0%E6%9C%AC%E9%94%AE%E7%9B%98%E7%81%AF%E5%92%8Cfn%E5%BF%AB%E6%8D%B7%E9%94%AE/</url><categories><category>hackintosh</category></categories><tags><tag>hackintosh</tag></tags><content type="html"> 驱动华硕笔记本的键盘灯和快捷键需要两步
第一步：修改DSDT Haswell机型 打开反编译好的DSDT,搜索“Device (ATKD)”，在其定义下加入以下代码（包含关系）：
Name (BOFF, Zero) Method (SKBL, 1, NotSerialized) { If (Or (LEqual (Arg0, 0xED), LEqual (Arg0, 0xFD))) { If (And (LEqual (Arg0, 0xED), LEqual (BOFF, 0xEA))) { Store (Zero, Local0) Store (Arg0, BOFF) } Else { If (And (LEqual (Arg0, 0xFD), LEqual (BOFF, 0xFA))) { Store (Zero, Local0) Store (Arg0, BOFF) } Else { Return (BOFF) } } } Else { If (Or (LEqual (Arg0, 0xEA), LEqual (Arg0, 0xFA))) { Store (KBLV, Local0) Store (Arg0, BOFF) } Else { Store (Arg0, Local0) Store (Arg0, KBLV) } } Store (DerefOf (Index (PWKB, Local0)), Local1) ^^PCI0.LPCB.EC0.WRAM (0x04B1, Local1) // Haswell/Ivy ^^PCI0.LPCB.EC0.WRAM (0x044B, Local1) // Sandy/Ivy Return (Local0) } Method (GKBL, 1, NotSerialized) { If (LEqual (Arg0, 0xFF)) { Return (BOFF) } Return (KBLV) } Skylake机型 打开反编译好的DSDT,搜索“Method (SCDG, 1, NotSerialized)”，在这个method下方加入以下代码（注并列关系）：
Name (BOFF, Zero) Method (SKBL, 1, NotSerialized) { If (Or (LEqual (Arg0, 0xED), LEqual (Arg0, 0xFD))) { If (And (LEqual (Arg0, 0xED), LEqual (BOFF, 0xEA))) { Store (Zero, Local0) Store (Arg0, BOFF) } Else { If (And (LEqual (Arg0, 0xFD), LEqual (BOFF, 0xFA))) { Store (Zero, Local0) Store (Arg0, BOFF) } Else { Return (BOFF) } } } Else { If (Or (LEqual (Arg0, 0xEA), LEqual (Arg0, 0xFA))) { Store (KBLV, Local0) Store (Arg0, BOFF) } Else { Store (Arg0, Local0) Store (Arg0, KBLV) } } Store (DerefOf (Index (KBPW, Local0)), Local1) ^^PCI0.LPCB.EC0.WRAM (0x04B1, Local1) Return (Local0) } Name (KBPW, Buffer (0x10) { 0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99, 0xAA, 0xBB, 0xCC, 0xDD, 0xEE, 0xFF }) Method (GKBL, 1, NotSerialized) { If (LEqual (Arg0, 0xFF)) { Return (BOFF) } Return (KBLV) } 第二步 加载驱动 将AsusNBFnKeys.kext放到Clover/kexts/other内
重启即可</content></entry><entry><title>Git技巧总结(持续更新)</title><url>/posts/%E6%8A%80%E5%B7%A7/2019-10-17-git%E6%8A%80%E5%B7%A7%E6%80%BB%E7%BB%93%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0/</url><categories><category>技巧</category></categories><tags><tag>Git</tag></tags><content type="html"><![CDATA[  1.git设置快捷脚本 git config --global alias.bp &#39;!hexo clean;hexo g;gulp g;hexo d&#39; 然后使用 git bpush 就可以一键更新博客并发布了(cd 后面的目录为你的博客文件目录） 取消方式
git config --global --unset alias.bpush 2.git快速push(推荐使用方法二) 方法一 git config --global alias.fp &#39;!git add .;git commit -m &#34;快速push&#34;;git push&#39; 使用方式输入 git fp 就可以直接三连，但是无法手写commit信息
方法二 更新 2020年04月20日23:36:29
在win系统下可以 在项目目录添加一个批处理文件来实现一键推送，同时可以输入commit信息（推荐使用n++或者sublime工具编辑，并且将编码修改为ANSI) bat内容如下
git add . set /p m=输入更新内容 git commit -m %m% git push pause ####mac系统或则linux系统 添加一个shell脚本来实现同样的功能。 代码如下
git add . echo 输入更新内容 read m git commit -m $m git push 此时我们的项目目录就会多出我们添加的脚本文件，如何忽略它呢，其实很简单，只需要打开项目目录的 .gitignore 文件（隐藏文件，没有就新建一个）添加我们的脚本工具的文件名就可以。
3.让git显示颜色 git config --global color.ui true   ]]></content></entry><entry><title>黑苹果之仿冒白苹果鼠标</title><url>/posts/hackintosh/2019-10-17-%E9%BB%91%E8%8B%B9%E6%9E%9C%E4%B9%8B%E4%BB%BF%E5%86%92%E7%99%BD%E8%8B%B9%E6%9E%9C%E9%BC%A0%E6%A0%87/</url><categories><category>hackintosh</category></categories><tags><tag>hackintosh</tag></tags><content type="html"><![CDATA[  仿冒好处 如果你的鼠标有侧键，可以启用部分侧键的功能
需要工具 1.PlistEdit 2.Clover Configurator
正式过程 1.查看关于本机-硬件-USB 查找鼠标对应的产品ID(idProduct)和厂商ID(idVendor),记录下来并转为10进制 2.新建一个1.plist。 3.将下面内容复制到1.plist。并修改记录的10进制填入下面文本对应的地方（每个值对应2个地方,第22、24行和239、241行）。保存后鼠标右键点击1.plist，打开方式选择PlistEdit &lt;?xml version=&#34;1.0&#34; encoding=&#34;UTF-8&#34;?&gt; &lt;!DOCTYPE plist PUBLIC &#34;-//Apple//DTD PLIST 1.0//EN&#34; &#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd&#34;&gt; &lt;plist version=&#34;1.0&#34;&gt; &lt;dict&gt; &lt;key&gt;IOKitPersonalities&lt;/key&gt; &lt;dict&gt; &lt;key&gt;WiredMouse-1&lt;/key&gt; &lt;dict&gt; &lt;key&gt;CFBundleIdentifier&lt;/key&gt; &lt;string&gt;com.apple.driver.AppleUSBHIDMouse&lt;/string&gt; &lt;key&gt;HIDDefaultBehavior&lt;/key&gt; &lt;string&gt;Mouse&lt;/string&gt; &lt;key&gt;IOClass&lt;/key&gt; &lt;string&gt;AppleHIDMouse&lt;/string&gt; &lt;key&gt;IOProviderClass&lt;/key&gt; &lt;string&gt;IOUSBInterface&lt;/string&gt; &lt;key&gt;bConfigurationValue&lt;/key&gt; &lt;integer&gt;1&lt;/integer&gt; &lt;key&gt;bInterfaceNumber&lt;/key&gt; &lt;integer&gt;0&lt;/integer&gt; &lt;key&gt;idProduct&lt;/key&gt; &lt;integer&gt;100&lt;/integer&gt; &lt;key&gt;idVendor&lt;/key&gt; &lt;integer&gt;7847&lt;/integer&gt; &lt;/dict&gt; &lt;key&gt;WiredMouseAccel-1&lt;/key&gt; &lt;dict&gt; &lt;key&gt;AppleHIDMouseVersion&lt;/key&gt; &lt;integer&gt;256&lt;/integer&gt; &lt;key&gt;CFBundleIdentifier&lt;/key&gt; &lt;string&gt;com.apple.iokit.IOHIDFamily&lt;/string&gt; &lt;key&gt;HIDAccelCurves&lt;/key&gt; &lt;array&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;65536&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;0&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;524288&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;5243&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;70124&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;26214&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;8192&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;537395&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;1245184&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;6554&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;74711&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;36045&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;32768&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;543949&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;1179648&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;7864&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;79299&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;46531&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;45056&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;550502&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;1114112&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;9830&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;83886&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;57672&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;57344&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;557056&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;1048576&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;11796&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;88474&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;69468&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;65536&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;563610&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;983040&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;14418&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;93061&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;81920&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;98304&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;570163&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;917504&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;17695&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;97649&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;95027&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;131072&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;576717&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;851968&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;21627&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;102236&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;108790&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;163840&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;583270&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;786432&lt;/integer&gt; &lt;/dict&gt; &lt;dict&gt; &lt;key&gt;HIDAccelGainCubic&lt;/key&gt; &lt;integer&gt;26214&lt;/integer&gt; &lt;key&gt;HIDAccelGainLinear&lt;/key&gt; &lt;integer&gt;104858&lt;/integer&gt; &lt;key&gt;HIDAccelGainParabolic&lt;/key&gt; &lt;integer&gt;123208&lt;/integer&gt; &lt;key&gt;HIDAccelIndex&lt;/key&gt; &lt;integer&gt;196608&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedLinear&lt;/key&gt; &lt;integer&gt;589824&lt;/integer&gt; &lt;key&gt;HIDAccelTangentSpeedParabolicRoot&lt;/key&gt; &lt;integer&gt;786432&lt;/integer&gt; &lt;/dict&gt; &lt;/array&gt; &lt;key&gt;HIDDisallowRemappingOfPrimaryClick&lt;/key&gt; &lt;true/&gt; &lt;key&gt;HIDScrollAccelerationTable&lt;/key&gt; &lt;data&gt; AACAAFVTQioACAAAAAAAAQABAAAAAKAAAAAgAAARAACAAAABITgA APd3AAMEhQABkREABbM1AAIzMwAIjM8AAxmaAA0+ggAECIkAExyh AAT3dwAZ0VcABiIiACKz/AAHm7kAL60rAAkL5ABAlHUACubxAFm3 6AAMzfUAcQCiAA8nmwCKvFgAEdQ+AKNZoQAUyDoAwOAEABfUJwDY opEAG0+XAPCMwAAAUAAAEQAAgAAAAkgLAADu7wAFB4kAAWZmAAg2 +QACGZoADROXAALERAARml4AA5ERABciqAAEqqsAH4SMAAXVVQAp EtwAB1gvADlNsAAI+gEASsYnAArm8QBkfA4ADM31AH6QEgAPJ5sA m2JOABHUPgC2878AFQGcANyUtgAYFoAA+RU7ABtPlwENanAAAIAA ABEAAHd3AAP8iwAA5mYAB2dLAAFMzQALY9UAAczNAA+pRQACgAAA Fez7AANVVQAceZUABMzNACjcjQAGREQANfVWAAd3dwBC3IcACPd3 AFP6RgAK5vEAcIrxAAzN9QCNwBQADyebAK4HtAAR1D4AzOgJABUO wgD2msAAGCOmARWVwAAbT5cBLb7kAACwAAARAACIiQAHrbYAAPd3 AA0+ggABd3cAExyhAAIIiQAZUJYAAszNACGyegADzM0AKxXgAATu 7wA1pbIABhERAEDhMAAHme8AUcnXAAkQqwBjyIMACs/hAIEhmgAM zfUAnsKmAA8nmwDC6egAEgcEAOyw1QAVDsIBExtGABg8dQE2zfoA GwY+AUv0OgAA4AAAEQAAgAAACyXBAAD6sQAXwo4AAXgJACAlVgAC HyoAKTsFAALwEwAztn8AA/ixAD+XxgAFAVAAShNBAAYztgBV9IgA B1gvAGM7mgAI3d4AdvcJAAqzMwCV8gkADOQyALnh/gAPJ5sA2k2o ABHUPgEBCNoAFP1bASmGugAYJnkBUgSeABrppwFjp94AAQAAABEA ACqrAA2aKgAAbu8AG1SSAADd3gApDvoAAYiJADUF/QAClmEAQF4p AAOLXgBMUmQABKSmAFkyBgAF0BUAZSZBAAcx9AB2nuYACK+5AIkC 8QAKszMAp/BcAAzkMgDQMFAADyebAPR/7wAR1D4BH+D0ABT9WwFN OrwAGCZ5AXqUiAAa6acBjlWcAAGzMwARAAAqqwAPPAYAAG7vAB6c KQAA3d4ALfxLAAGIiQA7Yt4AApZhAEgXigADi14AVXsAAASkpgBj 5hsABdAVAHFJkQAHMfQAhNrtAAivuQCZc+8ACrMzALwXcQAM5DIA 6SvfAA8nmwER1vgAEdQ+AUJslgAU/VsBdTeKABgmeQGoAoQAGumn Ab4icg== &lt;/data&gt; &lt;key&gt;HIDScrollAccelerationTableX&lt;/key&gt; &lt;data&gt; AACAAFVTQioACAAAAAAAAQABAAAAAQAAAAAgAAARAACAAAACGcMA AQAAAAQq2wABd3cAB4BXAAIzMwAPfbMAAyqrABki6QAEEREAIeel AAUZmgAqYY4ABmZmADX7bgAHzM0AQ3pJAAlVVQBUNk8ACwAAAGel TQAM3d4AfcwjAA8zMwCaeMkAEd3eALqW3AAU5mYA23dyABfd3gD5 ZcEAGyIiARiOHAAAUAAADwAAgAAABDOHAAEAAAAKdCgAAgAAABkc CQADREQAKISDAASiIgA1EogABhERAER7AgAHzM0AVivaAAkZmgBm JmwACqIiAHqxuQAMZmYAkYVkAA73dwCw6G8AEZERANDdkgAVCIkA +D3nABgREQEXoPIAGxmaATakNgAAgAAADwAAgAAACBo6AAEIiQAU eswAAfd3ACNrCwADEREAM3TgAARMzQBC06EABcREAFQznQAHZmYA Zj6tAAk7vAB8TDEACxERAJRa8AANGZoArxX9AA87vADKfB4AEhER AO/oZAAVGZoBFVSqABgiIgE1aFIAGxmaAVS6UAAAsAAADwAAgAAA EDR1AAEIiQAeVxsAAczNAC2CqQAC1VUAPvS/AAP3dwBRKQMABYAA AGZl/AAHVVUAfel+AAk7vACW8VsACvd3AKzwggAM93cAyD7nAA9E RADl09UAEgiJAQyC5AAVEREBMzH0ABgIiQFTDWoAGxmaAXLQagAA 4AAADwAAgAAAGAHcAAEIiQAoNlEAAaqrADghJgACmZoAS9nEAAOz MwBhFr4ABTMzAHlcbQAG5mYAkyZ4AAiZmgCsLlQACoiJAMd8ugAM oiIA5RGoAA8REQEEKvAAEgAAASxeWgAVEREBUYkQABgzMwF0bTwA GxERAZDmhAABAAAADwAAgAAAIBwXAAEAAAA0Nz8AAZmaAEVwCwAC d3cAWkTbAAN3dwBvGasABPd3AIxrGwAGmZoAqPcIAAhu7wDHDfwA CkREAOLUZwAMZmYBAzviAA8ZmgEqlPoAEgiJAVUEHAAVGZoBfSK2 ABg7vAGke84AGwAAAcKK/AABszMAEAAAgAAAKB1XAAEAAABALvIA AXd3AFK8yQACEREAZBh0AAMZmgB/3fAABHd3AJ0zfQAFmZoAtISe AAbERADMlkwACCIiAObpowAJ1VUBBD8wAAwiIgErW+wADqqrAU92 cgARszMBfJeaABT3eAGpuMAAF+7vAdDVfAAbAAAB9C90 &lt;/data&gt; &lt;key&gt;HIDScrollResolution&lt;/key&gt; &lt;integer&gt;2818048&lt;/integer&gt; &lt;key&gt;HIDScrollResolutionX&lt;/key&gt; &lt;integer&gt;2818048&lt;/integer&gt; &lt;key&gt;IOClass&lt;/key&gt; &lt;string&gt;IOHIDEventDriver&lt;/string&gt; &lt;key&gt;IOHIDScrollReportRate&lt;/key&gt; &lt;integer&gt;8192000&lt;/integer&gt; &lt;key&gt;IOProviderClass&lt;/key&gt; &lt;string&gt;IOHIDInterface&lt;/string&gt; &lt;key&gt;ProductID&lt;/key&gt; &lt;integer&gt;100&lt;/integer&gt; &lt;key&gt;VendorID&lt;/key&gt; &lt;integer&gt;7847&lt;/integer&gt; &lt;/dict&gt; &lt;/dict&gt; &lt;/dict&gt; &lt;/plist&gt; 4.如下图所示，复制WiredMouse-1和WiredMouseAccel-1 5.如下图所示，用PlistEdit打开FakeSMC.kext，找到IOKitPersonalities，然后看下图提示 6.插入后应该是下图的样子 7.保存放入clover/kexts/other替换-重建缓存-重启即可 成功效果图   ]]></content></entry><entry><title>修改transmission配置，实现远程访问transmission</title><url>/posts/%E7%BE%A4%E6%99%96/2019-09-03-%E4%BF%AE%E6%94%B9transmission%E9%85%8D%E7%BD%AE%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E8%AE%BF%E9%97%AE/</url><categories><category>群晖</category></categories><tags><tag>transmission</tag><tag>远程</tag><tag>防痴呆</tag></tags><content type="html"><![CDATA[  前言 如果没有修改下面设置也是能打开transmission的web界面，但是你会发现一片空白，提示正在连接服务器。 transmission实现远程访问要开启rpc-authentication-required
设置方法 找到transmission安装目录内的settings.json文件 使用notepad++或者sublime等文本编辑软件打开 修改以下地方：（大约在第43行开始） 1.将rpc-authentication-required和rpc-enabled修改为true，启用认证功能 2.rpc-username后设置为你的登录用户名 3.rpc-password后设置为你的密码 4.其他的就按下面的配置修改即可
&#34;rpc-authentication-required&#34;: true, &#34;rpc-bind-address&#34;: &#34;0.0.0.0&#34;, &#34;rpc-enabled&#34;: true, &#34;rpc-host-whitelist&#34;: &#34;&#34;, &#34;rpc-host-whitelist-enabled&#34;: true, &#34;rpc-password&#34;: &#34;123456&#34;, &#34;rpc-port&#34;: 9091, &#34;rpc-url&#34;: &#34;/transmission/&#34;, &#34;rpc-username&#34;: &#34;admin&#34;, &#34;rpc-whitelist&#34;: &#34;&#34;, &#34;rpc-whitelist-enabled&#34;: false, 这个配置的用户名为admin 密码为123456 注：密码修改后重启transmission，然后打开settings.json文件，rpc-password会变成了一串加密密钥。
  ]]></content></entry><entry><title>CentOS更换国内yum源</title><url>/posts/linux/2019-08-28-centos%E6%9B%B4%E6%8D%A2%E5%9B%BD%E5%86%85yum%E6%BA%90/</url><categories><category>linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> 每次都去百度地址太费劲了，所以整理一下地址
更换方法 1.备份默认yum源
cd /etc/yum.repos.d mv CentOS-Base.repo CentOS-Base.repo.bak 2.下载更换国内yum源 阿里
wget http://mirrors.aliyun.com/repo/Centos-7.repo mv Centos-7.repo CentOS-Base.repo 网易
wget http://mirrors.163.com/.help/CentOS7-Base-163.repo mv CentOS7-Base-163.repo CentOS-Base.repo 3.清理缓存
yum clean all 4.重建缓存
yum makecache</content></entry><entry><title>清除Win10系统Windows Defender中病毒扫描记录</title><url>/posts/%E6%8A%80%E5%B7%A7/2019-06-23-%E6%B8%85%E9%99%A4win10%E7%B3%BB%E7%BB%9Fwindowsdefender%E4%B8%AD%E7%97%85%E6%AF%92%E6%89%AB%E6%8F%8F%E8%AE%B0%E5%BD%95/</url><categories><category>技巧</category></categories><tags><tag>防痴呆</tag></tags><content type="html"> 在使用一些小工具，小软件的时候 ⁨Windows Defender⁩经常提示木马或者病毒，而扫描到的病毒记录又没有清除按钮，让一些强迫症患者很难受。终于找到了扫描的历史记录位置，终于可以告别右下角的黄色叹号了。 文件位置： C:\ProgramData⁩\Microsoft⁩\Windows Defender⁩\Scans⁩\History⁩\Service⁩\DetectionHistory⁩ ProgramData⁩十个隐藏目录，查看隐藏目录也很简单，鼠标点两下就可以。</content></entry><entry><title>Centos配置本地yum源</title><url>/posts/linux/2019-06-19-centos%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0yum%E6%BA%90/</url><categories><category>linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> 一、挂载镜像文件
mkdir /mnt/cdrom mount /dev/cdrom /mnt/cdrom 二、修改yum源配置文件
cd /etc/yum.repo.d rm -rf *.repo vi /etc/yum.repo.d/Localyum.repo 内容为：
[localyum] name=localyum baseurl=file:///mnt/cdrom gpgcheck=0 enabled=1 三、清空并重建缓存
yum clean all yum makecache</content></entry><entry><title>Linux下LVM及磁盘配额管理</title><url>/posts/linux/2019-04-22-linux%E4%B8%8Blvm%E5%8F%8A%E7%A3%81%E7%9B%98%E9%85%8D%E9%A2%9D%E7%AE%A1%E7%90%86/</url><categories><category>linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> 一、实验目的 1.理解磁盘配额管理的概念和应用；掌握磁盘配额管理的命令； 2.理解LVM与普通磁盘分区的区别，掌握逻辑卷的创建、扩容等。
二、实验内容 1.LVM练习： （1） 新添加2块SCSI硬盘设备（每块8G），每块硬盘创建两个分区，每个分区4G（假设为sdb1,sdb2,sdc1,sdc2）； （2） 每个分区创建物理卷PV； （3） 创建卷组myvg,包含分区sdb1和sdc1； （4） 在卷组myvg上创建逻辑卷mylv（大小为4G），并基于该逻辑卷建立EXT4文件系统； （5） 扩充mylv逻辑卷到大小为6G，并查看该逻辑卷；
2.磁盘配额管理 （1） 将上题中的文件系统设置开机后自动挂载，并开启用户、组磁盘配额管理； （2） 添加用户组accp，以及该组中的用户jerry（密码为jerry） （3） 限制用户jerry最多只能使用50M磁盘空间， 当使用磁盘空间超过30M时，10天内给出警告；限制accp组的用户合计最多只能使用500M磁盘空间 （4） 使用dd命令创建文件验证用户jerry的配额限制； （5） 使用quota –u ……和repquota ….查看用户配额设置和磁盘使用情况。
##三、实验命令
LVM练习： 详情见 上一篇博客 每个分区创建物理卷PV； pvcreate /dev/sdb1 pvcreate /dev/sdb2 pvcreate /dev/sdc1 pvcreate /dev/sdc2 或者 pvcreate /dev/sdb1 /dev/sdb2 /dev/sdc1 /dev/sdc2 创建卷组myvg,包含分区sdb1和sdc1； vgcreate myvg /dev/sdb1 /dev/sdc1 在卷组myvg上创建逻辑卷mylv（大小为4G），并基于该逻辑卷建立EXT4文件系统； lvcreate -L 4G -n mylv myvg mkfs.ext4 /dev/myvg/mylv 扩充mylv逻辑卷到大小为6G，并查看该逻辑卷； lvextend -L +2G /dev/myvg/mylv lvscan 磁盘配额管理 将上题中的文件系统设置开机后自动挂载，并开启用户、组磁盘配额管理； mkdir /mnt/mylv vi /etc/fstab 在最后一行添加下面内容 /dev/myvg/mylv /mnt/mylv ext4 defaults,usrquota,grpquota 1 2 添加用户组accp，以及该组中的用户jerry（密码为jerry） groupadd accp useradd -g accp -p jerry jerry 限制用户jerry最多只能使用50M磁盘空间， 当使用磁盘空间超过30M时，10天内给出警告；限制accp组的用户合计最多只能使用500M磁盘空间 先创建磁盘配额管理文件 quotacheck -avug 本别编辑用户和用户组的磁盘配额管理文件 edquota -u jerry 修改soft下值为 30720 修改hard下值为 51200 edquota -g accp 修改hard下值为 512000 edquota -t 修改Block grace period下值为10days 使用dd命令创建文件验证用户jerry的配额限制； dd if=/dev/zero bs=1M count=33 of=/mnt/mylv/testfile1 使用quota –u和repquota查看用户配额设置和磁盘使用情况。 略</content></entry><entry><title>Hexo博客添加Live2D小宠物</title><url>/posts/blog/2019-04-18-hexo%E5%8D%9A%E5%AE%A2%E6%B7%BB%E5%8A%A0live2d%E5%B0%8F%E5%AE%A0%E7%89%A9/</url><categories><category>blog</category></categories><tags><tag>博客</tag><tag>hexo</tag></tags><content type="html"> 在博客搭建之初这个插件我就用上了，时间久了，难免有些视觉疲劳，所以打算换个宠物。
项目地址 预览地址 一、安装Live2D插件 npm install --save hexo-helper-live2d npm install xxxxx //xxxxx是包名 下面是提供安装的列表，
live2d-widget-model-chitose live2d-widget-model-epsilon2_1 live2d-widget-model-gf live2d-widget-model-haru/01 (use npm install --save live2d-widget-model-haru) live2d-widget-model-haru/02 (use npm install --save live2d-widget-model-haru) live2d-widget-model-haruto live2d-widget-model-hibiki live2d-widget-model-hijiki live2d-widget-model-izumi live2d-widget-model-koharu live2d-widget-model-miku live2d-widget-model-ni-j live2d-widget-model-nico live2d-widget-model-nietzsche live2d-widget-model-nipsilon live2d-widget-model-nito live2d-widget-model-shizuku live2d-widget-model-tororo live2d-widget-model-tsumiki live2d-widget-model-unitychan live2d-widget-model-wanko live2d-widget-model-z16 二、修改配置文件 在博客根目录的_config.yml配置文件中添加下面的内容
#Live2D动画 live2d: enable: true scriptFrom: local pluginRootPath: live2dw/ pluginJsPath: lib/ pluginModelPath: assets/ tagMode: false debug: false model: use: live2d-widget-model-shizuku display: position: right width: 150 height: 300 mobile: show: true 主要参数说明
enable //是否使用 model: use: live2d-widget-model-shizuku //要使用的模型名称 display: position: right //显示的位置 width: 150 //宽度 height: 150 //高度 mobile: show: true //移动端是否显示 ##三、重新编译静态页面 下面的步骤就是Hexo三连 hexo clean hexo g hexo d</content></entry><entry><title>Linux下磁盘分区格式化</title><url>/posts/linux/2019-04-15-linux%E4%B8%8B%E7%A3%81%E7%9B%98%E5%88%86%E5%8C%BA%E6%A0%BC%E5%BC%8F%E5%8C%96/</url><categories><category>linux</category></categories><tags><tag>Linux</tag></tags><content type="html"> 一、实验目的 了解linux系统支持的常用文件系统 掌握磁盘分区、格式化，以及磁盘分区挂载的相关命令和操作。 二、实验内容 背景：某公司中的Linux服务器中新增了一块硬盘/dev/sdb（大小6G），练习Linux系统下磁盘分区、文件系统的创建、挂载与卸载及自动挂载的实现。 在RHEL的虚拟机中添加一个新硬盘（6G大小），进行如下操作：
查看/dev目录下的磁盘文件情况； 使用fdisk命令新建/dev/sdb1主分区和/dev/sdb2扩展分区，并在扩展分区中新建逻辑分区/dev/sdb5和/dev/sdb6（每个分区大小为2G），分区完成后查看分区信息； 删除逻辑分区sdb6, 然后查看分区情况； 使用mkfs命令为sdb1主分区创建xfs文件系统，为sdb5创建ext4文件系统， 用fsck命令检查这两个文件系统； 用mount命令挂载sdb1到/mnt目录下的同名文件夹/mnt/sdb1中； 查看挂载情况，并卸载sdb1分区； 设置把这两个文件系统每次启动系统时自动挂载到/mnt中的同名文件夹/mnt/sdb1和/mnt/sdb5下。 三、实验步骤和实验过程(包含关键截图) 查看/dev目录下的磁盘文件情况 ls /dev 创建2G的主分区 fdisk /dev/sdb n p +2G //这里的命令是交互式的 注意屏幕的输出提示 创建拓展分区 n e +4G //这里的命令是交互式的 注意屏幕的输出提示 创建2个大小为2G的逻辑分区 n l +2G //这里的命令是交互式的 注意屏幕的输出提示 查看分区情况 p 删除sdb6 分区 d 6 //这里的命令是交互式的 注意屏幕的输出提示 格式化分区 mkfs -c type /dev/sdb1 mkfs.ext /dev/sdb1 //两者均可 检查分区 fsck /dev/sdb1 xfs_repair -f /dev/sdb1 //fsck不可检查xfs分区 挂载分区 mkdir /mnt/sdb1 mount /dev/sdb1 /mnt/sdb1 //要挂载到一个空文件夹 卸载分区 umount /dev/sdb1 umount /mnt/sdb1 配置开机自动挂载 vi /etc/fstab 添加 /dev/sdb1 /mnt/sdb1 xfs default 0 0</content></entry><entry><title>Docker神器之迅雷远程下载(群辉 Linux)</title><url>/posts/%E7%BE%A4%E6%99%96/2019-04-15-docker%E7%A5%9E%E5%99%A8%E4%B9%8B%E8%BF%85%E9%9B%B7%E8%BF%9C%E7%A8%8B%E4%B8%8B%E8%BD%BD%E7%BE%A4%E8%BE%89linux/</url><categories><category>群晖</category></categories><tags><tag>迅雷</tag><tag>Docker</tag><tag>经验</tag></tags><content type="html"> 镜像作者Docker 链接 2022年08月13日19:36:14 现在群晖已经有迅雷的官方客户端了&amp;hellip;
2019-10-16 19:45:58 更新 现在迅雷远程速度很慢，而且设备code也不一定能获取到了，所以不推荐使用了！
群辉下安装和使用 一、Docker下载迅雷远程镜像 注册表搜索 thunder-xware 并下载箭头指向的镜像:yinheli/docker-thunder-xware 二、安装镜像 勾选使用高权限执行容器 点击高级设置 在卷属性卡中点击添加文件，并选择你期望远程迅雷的下载位置（自定义） 装载路径为 /TDDOWNLOAD （不可更改！！！） 网络选择左下角的与Docker Host使用相同的网络 点击应用创建容器 点开Docker页面左侧的容器选项卡，点击刚创建的容器，然后点击左上角的详情 在弹出的页面中选择日志选项卡，找到最下面的THE ACTIVE CODE IS: aabbcc ,记录后面的代码 点击这个链接 http://yuancheng.xunlei.com) 登陆迅雷后输入刚才得到的代码即可。 Linux系统下安装和使用 一、安装Docker下载迅雷远程镜像 关于Docker的安装不在多说，请自行搜索安装教程 在终端中输入docker pull yinheli/docker-thunder-xware:latest 下载镜像
二、安装镜像 mkdir data 创建一个文件夹用于存放迅雷下载的资源
docker run -d --privileged=true \ --name=xware \ --net=host \ -v &amp;lt;自己选择要存放的位置&amp;gt;:/app/TDDOWNLOAD \ yinheli/docker-thunder-xware 注意这里命令中的data就是上面创建的文件夹，如果不同名记得修改命令中的地址 docker ps //查看当前运行的容器 docker logs xware //查看迅雷远程的日志 在日志的后几行会看到THE ACTIVE CODE IS: aabbcc这样一行代码，记录后面的代码。也就是设备CODE 点击这个链接 http://yuancheng.xunlei.com 登陆迅雷后输入刚才得到的代码即可。</content></entry><entry><title>Hexo博客个性化定制</title><url>/posts/blog/2019-04-13-hexo%E5%8D%9A%E5%AE%A2%E4%B8%AA%E6%80%A7%E5%8C%96%E5%AE%9A%E5%88%B6/</url><categories><category>blog</category></categories><tags><tag>博客</tag><tag>教程</tag></tags><content type="html"><![CDATA[  前言 前段时间给博客换了个域名同时更新了博客的Next主题，最新版的7.1，之前是5.x版本。改动太多就直接clone，然后对照之前的一点点修改吧。这里简单记录一下个性化的设置。
直接在配置文件修改的地方 网站图标 favicon: 将图片定位到/theme/next/source/images 文章版权 creative_commons: 修改post属性为true 备案 beian: 菜单定制 menu: 社交 social: 友链 links: 头像 avatar: 阅读全文按钮 auto_excerpt: read_more_btn: 字符统计信息 symbols_count_time: 需要安装 插件 npm install hexo-symbols-count-time --save 同时根目录配置文件 symbols_count_time: 10. 打赏
reward_settings: enable: true animation: true comment: 自定义显示的内容 下面位置放入你的二维码
reward: wechatpay: /images/wechatpay.jpg alipay: /images/alipay.jpg Valine评论系统 # Valine # You can get your appid and appkey from https://leancloud.cn # More info available at https://valine.js.org valine: 本地搜索 local_search:
代码复制按钮 codeblock:
阅读人数 busuanzi_count:
将每篇文章的下方的标签的#改为图标 themes\next_config.yml
tag_icon: true 文章加密 cnpm install --save hexo-blog-encrypt title: 博客标题 date: 2022-06-07 23:05:38 password: 123456 这些都是我自己用到了一下配置，主题配置文件还有很多地方，大家可以去仔细看看
站点根目录配置文件和其他的地方 汉化 language: zh-CN 之前版本是zh-Hans 新版本更新了 网站标题和描述 title: description: 新建博文时文件名添加当前时间 new_post_name: :year-:month-:day-:title.md 添加网站萌宠 https://github.com/xiazeyu/live2d-widget.js https://l2dwidget.js.org/docs/class/src/index.js~L2Dwidget.html#instance-method-init 修改全局背景 /theme/next/source/images目录放入你的背景图片命令为background.jpg 然后在/theme/next/source/css/_custom/custom.sty中添加下面代码 // Custom styles. @media screen and (min-width:1200px) { body { background-image:url(/images/background.jpg); background-repeat: no-repeat; background-attachment:fixed; background-position:50% 50%; background-size:cover } #footer a { color:#eee; } } 在底部增加运行时间 在 themes\next\layout_partials\footer.swig 中新增 &lt;!-- 在网页底部添加网站运行时间 --&gt; &lt;div&gt; &lt;span id=&#34;timeDate&#34;&gt;载入天数...&lt;/span&gt;&lt;span id=&#34;times&#34;&gt;载入时分秒...&lt;/span&gt; &lt;/div&gt; &lt;script&gt; var now = new Date(); function createtime() { var grt= new Date(&#34;10/21/2018 00:00:00&#34;);//此处修改你的建站时间或者网站上线时间 now.setTime(now.getTime()+250); days = (now - grt ) / 1000 / 60 / 60 / 24; dnum = Math.floor(days); hours = (now - grt ) / 1000 / 60 / 60 - (24 * dnum); hnum = Math.floor(hours); if(String(hnum).length ==1 ){hnum = &#34;0&#34; + hnum;} minutes = (now - grt ) / 1000 /60 - (24 * 60 * dnum) - (60 * hnum); mnum = Math.floor(minutes); if(String(mnum).length ==1 ){mnum = &#34;0&#34; + mnum;} seconds = (now - grt ) / 1000 - (24 * 60 * 60 * dnum) - (60 * 60 * hnum) - (60 * mnum); snum = Math.round(seconds); if(String(snum).length ==1 ){snum = &#34;0&#34; + snum;} document.getElementById(&#34;timeDate&#34;).innerHTML = &#34;Run for &#34;+dnum+&#34; Days &#34;; document.getElementById(&#34;times&#34;).innerHTML = hnum + &#34; Hours &#34; + mnum + &#34; m &#34; + snum + &#34; s&#34;; } setInterval(&#34;createtime()&#34;,250); &lt;/script&gt; 暂时就想起来这么多，以后会一点点完善的 关于搭建博客可以看我的另一篇文章 这是链接   ]]></content></entry><entry><title>FRP内网穿透访问家中的NAS和路由器后台</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-04-11-frp%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E8%AE%BF%E9%97%AE%E5%AE%B6%E4%B8%AD%E7%9A%84nas%E5%92%8C%E8%B7%AF%E7%94%B1%E5%99%A8%E5%90%8E%E5%8F%B0/</url><categories><category>软路由</category></categories><tags><tag>内网穿透</tag><tag>群晖</tag></tags><content type="html"> 前言 自从入手了蜗牛星际以后，一直在折腾，先是安装了软路由，现在换成了PVE下虚拟LEDE软路由和黑群晖。可以远程访问的NAS才是一个完整的NAS,由于在宿舍大家一块用一条网线，虽然有公网地址，但联通公司不给改桥接，后来想想也挺麻烦的，而且宿舍的网线也只有4芯，即使路由器拨号也无法多播，就放弃DDNS了。于是开始研究内网穿透。
为什么要用FRP 1.没钱购买花生壳的付费服务，免费的局限性太大 2.学习一些新的东西
对FRP的理解 感觉frp和远程代理很像，支持的底层协议也很丰富，配置相对简单，而且不需要安装。通过命令行方式启动，有一点Linux基础的用户就可以完美驾驭。 作者 github主页 根据作者的介绍，frp的基础功能是实现远程tcp访问和ssh链接。而用的更多的确实http协议带来的远程web链接，访问家中的NAS和路由器后台。
下载以及配置 直接在github页面下载即可(注意服务的与客户端的版本尽量相同) 配置过程 下载frp： wget https://github.com/fatedier/frp/releases/download/v0.26.0/frp_0.26.0_linux_amd64.tar.gz 解压： tar -zxvf frp_0.26.0_linux_amd64.tar.gz 进入解压后的文件夹： cd frp_0.26.0_linux_amd64.tar.gz 编辑服务端配置文件： vi frps.ini 输入i进入编辑模式 i
根据文章后面的内容进行具体配置 编辑完成后按一下键盘左上角esc键退出编辑 输入:wq保存并退出 启动frp服务端并保持后台运行 （第一次测试时不需要&amp;amp;amp;符号即可前台运行，ctrl+c即可退出） nohup ./frps -c ./frps.ini &amp;amp;amp;
客户端和服务端类似，不过将frps更换为frpc （这里的s就是server服务端，c就是client客户端） 下载frp： wget https://github.com/fatedier/frp/releases/download/v0.26.0/frp_0.26.0_linux_amd64.tar.gz 解压： tar -zxvf frp_0.26.0_linux_amd64.tar.gz 进入解压后的文件夹： cd …</content></entry><entry><title>蜗牛星际之安装PVE+LEDE+群辉</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-04-06-%E8%9C%97%E7%89%9B%E6%98%9F%E9%99%85%E4%B9%8B%E5%AE%89%E8%A3%85pvelede%E7%BE%A4%E8%BE%89/</url><categories><category>软路由</category></categories><tags><tag>软路由</tag><tag>虚拟机</tag><tag>LEDE</tag><tag>PVE</tag></tags><content type="html"> 前言 上次安装了LEDE软路由后，也挂载了一个500G的硬盘，但总感觉对于J1900+4G内存来说有点浪费，还有那么大哥机箱，如果不做NAS有点对不起他的体积，在加上本来就是个矿机就尽量多压榨一下他的性能。 这里只是简单些一下安装流程，不打算上传图片了，更加详细的教程可以看下面的链接 蜗牛矿渣装机教程 篇一：搞定PVE虚拟机 作者主页有更多的教程，一共四个系列。
一、准备 1.规划IP地址 按照自己的需求规划好IP地址，尽量用纸记下来，省的以后乱套。
建议将PVE地址规划为软路由lan口的子网地址 例如192.168.123.100
群辉地址也为lan口的子网地址 例如192.168.123.102(这里的102是PVE的虚拟机序号，默认是从100开始)
2.制作U盘启动 两个优盘，一个装PE，一个装PVE镜像
PE直接用老毛桃即可。
用win32磁盘映像工具将pve的iso镜像写入U盘
3.恢复bios默认设置 开机接键盘后按del进去bios，然后按F9恢复默认设置，然后F10保存并退出。
二、安装PVE 插入老毛桃优盘进入PE，进入后将内置16G的mSATA所有分区删除，然后建立一个新分区。NTFS格式，取消勾选ESP和EFI。
关机，拔出老毛桃U盘，插入刻录PVE镜像的优盘启动盘。
开机按F11选择UEFI开头的U盘，进入PVE安装界面
根据指示安装完成即可。(这里会提示设置PVE的IP地址、子网掩码和网关)
添加网卡桥接，默认只有一个桥接网卡，按照格式添加新的桥接网卡即可。建议备注好WAN和LAN口。因为蜗牛只有2个网卡，所以备注好WAN和LAN同时在机箱后备注好WAN和LAN。
三、安装LEDE 新建虚拟机，选择不适用任何介质，硬盘分配1G-2G即可(后面远程连接需要安装docker，所以分配够用即可)，合理配置内存与核心（1G+4cores），网卡选择E1000。
下载LEDE镜像并解压。
将img2kvm和解压后的镜像上传到PVE的root目录
root目录下指令下面命令(Linux系统当前用户目录显示为~)
chmod +x img2kvm ./img2kvm lede.img 101(虚拟机编号) lede-leader-disk(这里可以自定义的) 在虚拟机的硬件页面添加新建的磁盘文件，硬盘接口尽量选择sata
硬件添加一个新的网卡。
在选项页 …</content></entry><entry><title>Docker神器之百度云下载(群辉 LEDE)</title><url>/posts/%E7%BE%A4%E6%99%96/2019-03-30-docker%E7%A5%9E%E5%99%A8%E4%B9%8B%E7%99%BE%E5%BA%A6%E4%BA%91%E4%B8%8B%E8%BD%BD%E7%BE%A4%E8%BE%89lede/</url><categories><category>群晖</category></categories><tags><tag>Docker</tag><tag>下载</tag><tag>LEDE</tag></tags><content type="html"> 前言 入手了蜗牛星际，安装了lede以后发现酷软中心的aria2和tr都不能正常工作，可能是版本bug，无意间在论坛发现了利用docker这一神奇运行百度云第三方下载，尝试一番发现确实很好用，记录一下折腾的过程。 原贴： http://koolshare.cn/thread-154383-1-1.html 我没有使用原贴中的镜像 而是选择了另一位大神oldiy的镜像，下面是他的DockerHub主页和博客。 https://hub.docker.com/u/oldiy/ https://odcn.top/ LEDE软路由下使用 第一步 LEDE酷软中心安装Docker插件 这里不多解释，直接安装即可
第二步 配置Docker插件 按照下图的设置即可 第三步 下载相关镜像 在注册表页搜索相关镜像即可，如下图为百度云下载 第四步 创建容器 在镜像页选择已经下载的镜像创建即可。 在这里对容器进行相关配置，注意端口，和容器中给定的相同最好 下面这一张图就能看明白端口和目录的设置了 简单来说就是端口号正确且不与lede其他程序冲突就可以进入后台 地址正确才能保证文件下载到你指定的位置 然后点击创建即可
进入Web页面查看安装情况 启动成功后就可以通过下面的链接进入web页面了 http://你的路由器ip:5299 //这里的5299就是配置容器时的端口，尽量和dockerhub的相同。如果不同应该是进不去相关页面的 使用自己的百度账号登录即可，然后点击右上角的设置 注意这里的目录，不要修改使用默认即可 群辉下使用 （更新内容） 第一步 群辉套件中心安装Docker插件 不多解释
第二步 下载镜像 在注册表搜索baidu下载下图中的镜像 第三步 配置镜像 按照下图配置即可，配置完成后会自动启动容器 配置下载路径 配置端口 第四步 打开Web管理页面 浏览器输入 &amp;lt;你的IP&amp;gt;:5299 进入web页面
解决百度云限速 web的设置页面修改appid为
265486 默认工作目录修改为
/apps/baidu_shurufa 百度输入法不限速，所以修改为输入法的id 而默认工作目录就是登陆页面后所展现的目录 把要下载的文件移动到/apps/baidu_shurufa 下载即可 需要操作其他文件的时换回 266719 即可
结束 2019年03月30日15:02:07 更新 2019年04月18日23:24:00</content></entry><entry><title>软路由LEDE系统之samba局域网共享</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-03-29-%E8%BD%AF%E8%B7%AF%E7%94%B1lede%E7%B3%BB%E7%BB%9F%E4%B9%8Bsamba%E5%B1%80%E5%9F%9F%E7%BD%91%E5%85%B1%E4%BA%AB/</url><categories><category>软路由</category></categories><tags><tag>软路由</tag><tag>LEDE</tag><tag>samba</tag></tags><content type="html"> 前言 上周末看油管的时候发现了一款极具性价比的NAS-蜗牛星际。矿渣nas，三月初就开卖了，当时好像200包邮。我入手有点晚所以价格也高一些。290包邮。不过卖家给改好了双千兆网络。虽然是矿渣，但我这台内部没有多少灰尘。只有风扇上有灰。应该没运行多久。到手后由于没4有显示器和电源线。就去楼下电脑维修店买了根电源线，顺便借老板显示器装了系统。 很久之前就想入手软路由了，但是动不动就上千的售价实在是难以接受。看到这个性价比还不错的就入手了。之前用的是k2p。没有usb接口，局域网共享就很难实现，而且就算有U盘，24小时工作也承受不了。现在终于可以好好享受一下samba带来的便携了。后期应该还会安装黑群辉实现更多的功能。 如果你的软路由主板usb借了移动硬盘或者sata口连接了机械硬盘，这一步是不需要做的。 蜗牛星际主板上带了一个16G的固态硬盘。性能极差。和3.0的U盘速度差不多。装lede还勉强可以接受。现在没有硬盘也只能用这个来代替了。 我安装的是 koolshare论坛 的lede系统，酷软中心很多插件，还是挺好用的。 注：本文借鉴了koolshare论坛的两个帖子 这里简单做了一些总结，和一些自己的经验
http://koolshare.cn/thread-154153-1-1.html http://koolshare.cn/forum.php?mod=viewthread&amp;amp;tid=110543&amp;amp;highlight=samba 一、为安装盘剩余的空间创建新分区 如果你的软路由主板usb借了移动硬盘或者sata口连接了机械硬盘，这一步是不需要做的。
先运行分区工具 fdisk /dev/sda 输入p查看当前分区 ### 输入n创建新的分区 这里由于我已经创建 就不在截图了 直接连续三次回车键，会默认将剩余的空间创建为一个新的分区。 ### 输入w保存分区 完成后会退出分区工具 ### 使用mkfs命令格式化新建的分区 `mkfs.ext4 /dev/sda5` 说明 etx4是文件系统。如果是固态的话建议修改为f2fs。后面的sda5是新建的分区，分区名根据自己的修改即可。 `mkfs.f2fs /dev/sda5` （固态硬盘推荐使用） ### 赋予新添加的分区权限 `chmod -R a+rwx /mnt/sda5` ### 重启，使分区表生效（好像不重启 …</content></entry><entry><title>Hexo静态博客搭建总结</title><url>/posts/blog/2019-03-20-hexo%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%E6%80%BB%E7%BB%93/</url><categories><category>blog</category></categories><tags><tag>总结</tag><tag>博客</tag><tag>hexo</tag></tags><content type="html"><![CDATA[  第一次搭建博客大约是在18年6月份。当时是在腾讯云vps上安装宝塔，然后宝塔内部一键安装WordPress博客。在18年12月份发现Github+hexo这一神奇组合，果断尝试。然后又经历了期末考试和过年，博客也算是搁置了一段时间。前几天才重新捡起，然后又系统的自学了一下Git。所以打算写这个博客简单记录一下最基础的内容，可能有些小白看不懂，后期可能会慢慢完善的。
一、什么是Git、Github、Hexo？ 首先要知道这是完全不同的三个东西，但三者结合起来就会发生奇妙的反应。
什么是Git？ Git是一个的分布式版本控制系统。
什么是Github？ Github是一个提供免费服务的代码托管网站。
什么是Hexo？ Hexo 是一个快速、简洁且高效的博客框架。Hexo 使用 Markdown (或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。(摘抄自hexo官网)
如果对github和git的关系感兴趣，可以去这个网站简单了解一下 Git 二、安装Git、Node.js和hexo 在以下网址下载软件 Git官网下载地址 https://www.git-scm.com/download/ node.js官网下载地址 https://nodejs.org/en/ （建议下载LTS版本）
这两款软件选好安装目录使用默认设置即可
NodsJS 安装备注说明 安装后在用户目录下新建nodejs目录然后再创建node_global和node_cache目录,并用下面命令将其设置为默认安装和缓存位置
npm config set prefix &amp;#34;/Users/sxz799/nodejs/node_global&amp;#34; npm config set cache &amp;#34;/Users/sxz799/nodejs/node_cache&amp;#34; 国内环境使用淘宝镜像命令
npm config set registry=http://registry.npm.taobao.org hexo安装 安装好git和node.js后新建一个你要放置博客的文件夹，然后鼠标右键点击 Git bash here，在弹出的窗口输入下面的命令(实际上在任意文件夹下都可以 ，hexo安装的目录由node.js的配置决定)
npm install -g hexo-cli  …  ]]></content></entry><entry><title>VMware虚拟机体验koolshare论坛LEDE固件</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-03-17-vmware%E8%99%9A%E6%8B%9F%E6%9C%BA%E4%BD%93%E9%AA%8Ckoolshare%E8%AE%BA%E5%9D%9Blede%E5%9B%BA%E4%BB%B6/</url><categories><category>软路由</category></categories><tags><tag>虚拟机</tag><tag>路由器</tag><tag>LEDE</tag></tags><content type="html"> ​ 博主自用的是路由器是斐讯K2P A2版，性能足够满足大多数家庭的需要了，但还是听说koolshare论坛的lede固件功能丰富，是软路由很常用的固件。只是现在用不到，也没有条件使用（毕竟价格接近4位数）。但看论坛截图里丰富的功能有些手痒，就打算在虚拟机里装上过过瘾。
一、固件下载 链接：http://firmware.koolshare.cn/LEDE_X64_fw867/ ​链接是x64设备用的固件，有img格式和vmdk虚拟机专用的格式，这里选择虚拟机专用格式下载。
二、安装LEDE 和安装其他虚拟机没有什么区别，有几处需要注意的地方我已经在图中标记出来了。 安装到这里就差不多了。主要区别就是选择稍后安装操作系统，然后磁盘选择第一步中下载的文件和添加了一张网卡而已。 安装后不要启动！ 安装后不要启动！ 安装后不要启动！
三、虚拟机网卡配置 和上一篇文章类似，设置VMware虚拟网卡。这里设置桥接网卡为计算机的网卡。nat地址和上一篇文章一样。 然后设置lede系统的网卡 配置好以后启动虚拟机。启动完毕后鼠标点击虚拟机内部 然后输入 vi /etc/config/network 修改lan口的地址 然后取消勾选本地连接中的ipv4和ipv6协议。 重点！重点！重点！重点！
四、配置VMware Network Adapter VMnet8 和上篇文章不同的是，这里我们的目的是通过虚拟机路由器系统进行上网，所以要配置上网关 如下图 教程结束！ //2019年03月20日19:26:46 更新
转载注明出处 谢谢</content></entry><entry><title>虚拟机内系统通过NAT方式连接外网，同时与本机进行通信</title><url>/posts/%E8%BD%AF%E8%B7%AF%E7%94%B1/2019-03-13-%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%86%85%E7%B3%BB%E7%BB%9F%E9%80%9A%E8%BF%87nat%E6%96%B9%E5%BC%8F%E8%BF%9E%E6%8E%A5%E5%A4%96%E7%BD%91%E5%90%8C%E6%97%B6%E4%B8%8E%E6%9C%AC%E6%9C%BA%E8%BF%9B%E8%A1%8C%E9%80%9A%E4%BF%A1/</url><categories><category>软路由</category></categories><tags><tag>学习</tag></tags><content type="html"> 前言 就在今天下午上课的时候突然发现自己好久没有写blog了，可能最近学习太忙，也可能最近没啥好写的。今天上课的时候有同学问到我关于虚拟机系统连接外网的问题，所以打算写这么一篇blog，也算加深一下自己的印象吧。
自求学以来，实验课用到的虚拟机软件都是VMware，相信大部分人对这个软件也不陌生，除了这个就是win10自带的Hyper-V虚拟机了.这里就简单的写一下VMware用NAT方式连接外网。
第一步 配置VMware的虚拟网络编辑器 ① 在VMware的菜单栏中点击编辑，在弹出的菜单中选择虚拟网络编辑器，在弹出的窗口中点击更改设置，可能会提示需要管理员权限，确定即可。 ② 在新弹出的界面中点击VMware8 这是VMware默认的nat模式，可以用这个默认的网络，也可以新建一个，这里没有什么区别。选中该网络后修改配置为图中的配置。下方的子网网段可自己定义。没有什么影响，只要不和上面的网络冲突即可（建议使用默认的）。然后点击图中的NAT设置，网关可以修改，建议使用默认，并记住这个网关。 ③ 设置虚拟机网卡为VMware8 NAT模式，这个就很简单了，根据图中的步骤来即可。到这里VMware的设计就完成了。 第二步 修改虚拟机系统的网络连接设置 这一步非常简单，因为大家用的系统不一样，设置界面也不尽相同，这里以centos7系统为例，简单介绍一下。这里的IP地址不是固定的只要在同一网段内即可。但是网关地址一定是上一步中nat设置中的网关地址。完成这一步虚拟机应该就可以连接外网使用百度了。 三 建立虚拟机与宿主机的连接。 此时虚拟机虽然可以连接外网，但并不能和宿主机进行通信，也就是说此时的宿主机并不能ping通虚拟机的ip。想要建立连接也很简单。只需要设置一下网络适配器中的VMware Network Adapter VMnet8 网卡的ip和子网掩码即可。 注：如果是学校的机房，或者用过脚本优化的电脑可能开机后不会启动VMware的一些必要的服务，可以手动开启。详见下图 //2019年03月20日19:25:10 更新 转载注明出处 谢谢</content></entry></search>